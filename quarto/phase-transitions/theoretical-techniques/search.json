[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to PHYSM0071: Complex Disordered Matter!",
    "section": "",
    "text": "Lecturer: Prof. Nigel Wilding (nigel.wilding@bristol.ac.uk)\n\n\n\n\n\n\nComplex disordered matter is a central theme in soft matter physics, encompassing systems such as polymers, colloids, glasses, gels, and emulsions that lack long-range order but display intricate and often tunable behavior. Colloids—suspensions of microscopic particles in a fluid—serve as versatile model systems for studying disordered structures and phase behavior because their particle-scale dynamics are directly observable. Similarly, polymer systems and colloidal suspensions can form amorphous solids, or glasses, when densely packed or cooled, exhibiting solid-like rigidity despite their disordered, liquid-like microscopic structure. These materials frequently undergo equilibrium and non-equilibrium phase transitions such as demixing, crystallisation, gelation, vitrification, or jamming, and near these transitions, they may show critical phenomena where fluctuations and correlations span many length scales.\nIn soft matter systems, the interplay between disorder, softness, and phase behavior leads to rich physical phenomena, particularly near critical points where even small changes in external conditions can trigger large-scale reorganizations and universal behaviour. Glasses, for instance, exhibit slow relaxation and memory effects, while colloidal systems may crystallize, phase separate, or become jammed depending on particle interactions and concentration. Understanding such behaviors involves studying how microscopic interactions and thermal fluctuations influence macroscopic properties, especially in non-equilibrium conditions. Through techniques like scattering, microscopy, rheology, and simulation, one can explore how disordered soft materials respond to stress, age, or undergo transitions—insights that are vital for applications in materials design, biotechnology, and beyond.\nThis course is organized into three interconnected parts, each offering a distinct perspective on the study of complex disordered matter.\n\nPart 1: Unifying theoretical concepts (Nigel Wilding) introduces the theoretical framework for rationalising complex disordered matter which is grounded in statistical mechanics and thermodynamics. We emphasize the theory of phase transitions, critical phenomena, and stochastic dynamics—providing the essential tools needed to describe and predict the behavior of soft and disordered systems.\n\nPart 2: Complex disordered matter (Francesco Turci) explores the phenomenology of key examples of complex disordered soft matter systems, including colloids, polymers, liquid crystals, glasses, gels, and active matter. These systems will be analyzed using the theoretical concepts introduced in Part 1, highlighting how disorder, interactions, and fluctuations shape their macroscopic behavior.\n\nPart 3: Experimental techniques (Adrian Barnes) focuses on the methods of microscopy, and scattering via x-rays, neutrons and light that are used to study these complex disordered matter, offering insight into how their properties are measured and understood in real-world contexts.\n\nIn addition to theory and experiment, computer simulation plays a central role in soft matter research. This course includes a substantial coursework component consisting of two computational projects. These exercises will allow you to apply state-of-the-art simulation techniques to investigate the complex behavior of disordered systems, bridging theory and observation through hands-on exploration.\n\n\nDelivery and format\n\nDetailed e-notes (see Blackboard) can be viewed on a variety of devices. Pdf is also available.\nWe will give ‘traditional’ lectures (XXday, YYYday) in which we use slides to summarise and explain the lecture content. Questions are welcome (within reason…)\nTry to read ahead in the notes, then come to lectures, listen to the explanations and then reread the notes.\nRewriting the notes or slides to express your own thoughts and understanding, or annotating a pdf copy can help wire the material into your own way of thinking.\nThere are problem classes (XXXday) where you can try problem sheets and seek help. I will go over some problems with the class.\nThe navigation bar on the left will allow you to access the lecture notes and problem sets.\n\n\n\nQuestions and comments\nIf you have any questions about the course, please don’t hesitate to contact me, either by email (see above) or in a problems class.\nFinally, this is a new course for 2025/26, with the lecture notes written from scratch. If you find any errors or mistakes or something which isn’t clear, please let me know, or fill in this anonymous form:",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "nucleation-and-growth.html",
    "href": "nucleation-and-growth.html",
    "title": "Dynamics of first order phase transitions: nucleation and growth",
    "section": "",
    "text": "In previous discussions, we considered first-order phase transitions but deferred a detailed analysis of the dynamical mechanism by which a system evolves from one phase to another. We now address this question explicitly.\nConsider again the Ising model at a temperature \\(T &lt; T_c\\), where the system is initially prepared in the majority spin-up phase at zero external field, \\(H = 0\\). We now examine the system’s response to the application of a small negative external field \\(H &lt; 0\\), which lowers the free energy of the spin-down phase relative to the spin-up phase.\nDespite the global free energy favoring the spin-down phase, the system does not undergo an instantaneous transition. This delay is a consequence of the free energy barrier associated with nucleating a region of the stable phase within the metastable one, as introduced in Chapter 5. The dynamical pathway of the phase transition proceeds via nucleation of localized regions—referred to as droplets—of the stable (spin-down) phase embedded within the metastable (spin-up) background. Once nucleated, these droplets may grow over time and ultimately coalesce to transform the system to the stable phase.\nThe nucleation of a droplet of the stable phase of size \\(n\\) spins entails a competition between bulk and interfacial contributions to the free energy. The bulk free energy gain is linear in \\(n\\), given by \\(-nH\\), due to the alignment of spins with the external field. However, this gain is offset by an interfacial free energy cost arising from broken bonds at the boundary between phases. For the Ising model, each broken bond contributes an energy cost of \\(+2J\\), so the total interfacial energy scales with the perimeter (in 2D) or surface area (in 3D) of the droplet. This interfacial contribution is referred to as the surface tension, and constitutes a true free energy cost: it includes not only the energetic penalty from broken bonds but also an entropic contribution due to the configurational degrees of freedom associated with the droplet shape.\nThe resulting competition between the extensive free energy gain and the sub-extensive interfacial cost leads to a free energy barrier for droplet formation. Only fluctuations that produce a droplet larger than a critical size \\(n_c\\) will grow; smaller droplets will shrink. This framework is formalized in classical nucleation theory, which provides a quantitative description of the nucleation rate, critical droplet size, and the associated activation energy barrier.\n\n\n\nWe now present the framework of classical nucleation theory (CNT) for the case of homogeneous nucleation, in which the nucleation of the stable phase occurs spontaneously and uniformly throughout the bulk of the metastable phase, without the aid of impurities, defects, or surfaces.\nLet us consider a droplet of the stable (spin-down) phase of radius \\(R\\) embedded within the metastable (spin-up) background. The total change in free energy \\(\\Delta F(R)\\) associated with forming such a droplet consists of two competing contributions:\n\nBulk free energy gain: The interior of the droplet consists of \\(V \\sim R^d\\) spins aligned with the external field \\(H &lt; 0\\), leading to a volume free energy change\n\\[\n\\Delta F_{\\text{bulk}}(R) = -|\\Delta f| \\, R^d,\n\\]\nwhere \\(|\\Delta f| \\propto |H|\\) is the free energy density difference between the metastable and stable phases, and \\(d\\) is the spatial dimensionality of the system.\nInterfacial free energy cost: The boundary between the two phases has a surface area scaling as \\(R^{d-1}\\), and incurs a free energy cost proportional to the surface tension \\(\\sigma\\):\n\\[\n\\Delta F_{\\text{surface}}(R) = \\sigma \\, S_d \\, R^{d-1},\n\\]\nwhere \\(S_d\\) is a geometrical factor (e.g., \\(S_2 = 2\\pi\\) in 2D and \\(S_3 = 4\\pi\\) in 3D).\n\nThe total free energy change is therefore given by\n\\[\n\\Delta F(R) = \\sigma \\, S_d \\, R^{d-1} - |\\Delta f| \\, V_d \\, R^d,\n\\]\nwhere \\(V_d\\) is another dimension-dependent constant. This expression exhibits a characteristic maximum at a critical droplet radius \\(R_c\\), obtained by extremizing \\(\\Delta F(R)\\) with respect to \\(R\\):\n\\[\n\\frac{d \\Delta F}{dR} = 0 \\quad \\Rightarrow \\quad R_c = \\frac{(d-1)\\sigma S_d}{d |\\Delta f| V_d}.\n\\]\n\n\n\n\n\n\nFigure 1: Free energy barrier \\(\\Delta F(r)\\) for nucleation of a spherical droplet as a function of radius \\(R\\) (schematic)\n\n\n\nThe corresponding free energy barrier for nucleation is\n\\[\n\\Delta F_c = \\Delta F(R_c) = \\frac{(d-1)^{d-1}}{d^d} \\cdot \\frac{(S_d)^d \\, \\sigma^d}{(|\\Delta f|)^{d-1} \\, (V_d)^{d-1}}.\n\\]\nThis barrier must be surmounted by thermal fluctuations in order for a critical nucleus to form and grow. The nucleation rate per unit volume is given (in the Arrhenius approximation) by\n\\[\nI \\sim I_0 \\exp\\left( -\\frac{\\Delta F_c}{k_B T} \\right),\n\\]\nwhere \\(I_0\\) is a prefactor determined by microscopic kinetics, and \\(k_B\\) is Boltzmann’s constant.\n\n\nSeveral key features emerge from this analysis:\n\nBarrier scaling: The nucleation barrier \\(\\Delta F_c \\sim \\sigma^d / |\\Delta f|^{d-1}\\) diverges as \\(H \\to 0\\), reflecting the increasing stability of the metastable phase near the coexistence point.\nCritical radius: The critical droplet size \\(R_c \\sim \\sigma / |\\Delta f|\\) also diverges as \\(|\\Delta f| \\to 0\\), indicating that larger fluctuations are required to initiate nucleation close to the coexistence line.\nDimensional dependence: Both \\(\\Delta F_c\\) and \\(R_c\\) exhibit strong dependence on the spatial dimension \\(d\\), with nucleation becoming increasingly suppressed in higher dimensions due to the dominance of interfacial cost.\n\nIn summary, homogeneous nucleation in a first-order transition is governed by a delicate balance between surface tension and bulk free energy gain. Only droplets exceeding a critical size can overcome the barrier and initiate a transition. This sets an intrinsic timescale for the dynamics of phase transformation, which can become extremely long near coexistence due to the exponentially small nucleation rate.\n\n\n\n\nFollowing successful nucleation of a supercritical droplet, the system enters a regime where the global transformation is driven by the deterministic growth of domains of the stable phase. This phase of the dynamics is often referred to as coarsening or phase ordering dynamics.\nAt late times, the dynamics are controlled not by rare fluctuations, but by the energetically-driven evolution of domain structures. The nature of domain growth depends sensitively on whether the order parameter is conserved or not.\n\n\n\nIn systems with a non-conserved order parameter, such as the Ising model with single spin flip (so called Glauber) dynamics, the order parameter can relax locally without constraint. This leads to curvature-driven motion of interfaces.\nThe typical domain size \\(L(t)\\) grows algebraically with time:\n\\[\nL(t) \\sim t^{1/2},\n\\]\ncorresponding to a dynamic exponent \\(z = 2\\). The growth is driven by reduction of the total interfacial area—regions of high curvature (small domains) shrink and are absorbed by larger, flatter ones.\nLet is aassume that domain walls move with velocity proportional to curvature: \\[\n  v \\sim \\frac{1}{L}\n  \\] Then with the typical domain size being \\(L(t)\\) it follows that\n\\[\n  \\frac{dL}{dt} \\sim \\frac{1}{L}\n  \\]\nIntegrating both sides yields the \\(t^{1/2}\\) domain growth law.\nIt turns out that the detailed evolution of the coarse-grained order parameter field \\(\\phi(\\mathbf{r}, t)\\) is governed by the Allen–Cahn equation:\n\\[\n\\frac{\\partial \\phi}{\\partial t} = - \\frac{\\delta F[\\phi]}{\\delta \\phi},\n\\]\nwhere \\(F[\\phi]\\) is a coarse-grained Ginzburg–Landau free energy functional:\n\\[\nF[\\phi] = \\int d^d x \\left[ \\frac{1}{2} (\\nabla \\phi)^2 + V(\\phi) \\right],\n\\]\nwith \\(V(\\phi)\\) typically a double-well potential such as \\(V(\\phi) = \\frac{1}{4}(\\phi^2 - 1)^2\\).\n\n\n\n\nFor systems with a conserved order parameter, such as phase separation in binary alloys or the Ising model with spin-swap (so called ‘Kawasaki’) dynamics, the order parameter (e.g., composition or particle number) must be conserved locally. This imposes a diffusive constraint on the dynamics.\nThe domain size again grows algebraically, but with a different exponent:\n\\[\nL(t) \\sim t^{1/3},\n\\]\ncorresponding to a dynamic exponent \\(z = 3\\).\nA chemical potential difference drives diffusion and is given by \\[\n\\Delta \\mu \\sim \\frac{\\sigma}{L}\n\\] (again due to curvature, where \\(\\sigma\\) is surface tension)\nNow the flux is proportional to the chemical potential gradient (Fick’s law): \\[\n\\text{Flux} \\sim -\\nabla \\mu \\sim \\frac{\\Delta \\mu}{L} \\sim \\frac{\\sigma}{L^2}\n\\]\nand the rate of change of domain size is proportional to this flux: \\[\n\\frac{dL}{dt} \\sim \\frac{1}{L^2}\n\\quad\\Rightarrow\\quad\nL(t) \\sim t^{1/3}\n\\]\nIt turns out that the detailed dynamics are described by the Cahn–Hilliard equation, a continuity equation of the form:\n\\[\n\\frac{\\partial \\phi}{\\partial t} = \\nabla^2 \\left( \\frac{\\delta F[\\phi]}{\\delta \\phi} \\right),\n\\]\nreflecting that the order parameter can only evolve via diffusion of its conjugate chemical potential. This leads to the slow transport of material across domains and a more sluggish coarsening process compared to the non-conserved case.\n\n\n\nHere are schematic illustrations of domain growth for:\n\nNon-conserved dynamics (Model A): Domains coarsen rapidly, with smoother and larger regions due to free relaxation of the order parameter.\nConserved dynamics (Model B): Coarsening is slower and domains are more intricate, reflecting the constraint of local conservation.\n\n\n\n\n\n\n\n\n\nNon-Conserved Dynamics (Model A)\n\n\n\n\n\n\n\nConserved Dynamics (Model B)\n\n\n\n\n\n\nFigure 2: Schematic illustrations of domain morphology resulting from non-conserved and conserved dynamics.\n\n\n\n\n\n\nAt late times, both conserved and non-conserved systems exhibit dynamic scaling: the statistical properties of the domain morphology become self-similar under rescaling of lengths by \\(L(t)\\).\nFor example, the equal-time two-point correlation function satisfies\n\\[\nC(r, t) = f\\left( \\frac{r}{L(t)} \\right),\n\\]\nwhere \\(f(x)\\) is a time-independent scaling function. Plots of \\(C(r,t)\\) collapse when plotted as a function of \\(r/L(t)\\).The structure factor \\(S(k, t)\\) also obeys dynamic scaling:\n\\[\nS(k, t) = L(t)^d \\, g(k L(t)),\n\\]\nwith \\(g(x)\\) a universal scaling function dependent on the dynamical class and dimensionality.\n\n\n\n\n\n\n\n\n\n\n\n\n\nDynamics Type\nConservation\nEquation Type\nGrowth Law\nDynamic Exponent\n\n\n\n\nModel A (e.g. Glauber)\nNo\nAllen–Cahn\n\\(L(t) \\sim t^{1/2}\\)\n\\(z = 2\\)\n\n\nModel B (e.g. Kawasaki)\nYes\nCahn–Hilliard\n\\(L(t) \\sim t^{1/3}\\)\n\\(z = 3\\)\n\n\n\n\n\nRemarks: The domain growth exponents \\(1/z\\) are robust under many conditions, but can be modified in the presence of disorder, long-range interactions, or hydrodynamic effects.\n\n\nIn both the model A and model B cases, the system coarsens until it reaches equilibrium, characterized by a uniform macroscopic phase and the complete elimination of interfaces.\n\n\nThe approach to equilibrium is algebraically slow (described by power laws) due to the scale-free nature of domain dynamics.",
    "crumbs": [
      "Chapters",
      "13. Nucleation and domain growth"
    ]
  },
  {
    "objectID": "nucleation-and-growth.html#introduction-to-nucleation",
    "href": "nucleation-and-growth.html#introduction-to-nucleation",
    "title": "Dynamics of first order phase transitions: nucleation and growth",
    "section": "",
    "text": "In previous discussions, we considered first-order phase transitions but deferred a detailed analysis of the dynamical mechanism by which a system evolves from one phase to another. We now address this question explicitly.\nConsider again the Ising model at a temperature \\(T &lt; T_c\\), where the system is initially prepared in the majority spin-up phase at zero external field, \\(H = 0\\). We now examine the system’s response to the application of a small negative external field \\(H &lt; 0\\), which lowers the free energy of the spin-down phase relative to the spin-up phase.\nDespite the global free energy favoring the spin-down phase, the system does not undergo an instantaneous transition. This delay is a consequence of the free energy barrier associated with nucleating a region of the stable phase within the metastable one, as introduced in Chapter 5. The dynamical pathway of the phase transition proceeds via nucleation of localized regions—referred to as droplets—of the stable (spin-down) phase embedded within the metastable (spin-up) background. Once nucleated, these droplets may grow over time and ultimately coalesce to transform the system to the stable phase.\nThe nucleation of a droplet of the stable phase of size \\(n\\) spins entails a competition between bulk and interfacial contributions to the free energy. The bulk free energy gain is linear in \\(n\\), given by \\(-nH\\), due to the alignment of spins with the external field. However, this gain is offset by an interfacial free energy cost arising from broken bonds at the boundary between phases. For the Ising model, each broken bond contributes an energy cost of \\(+2J\\), so the total interfacial energy scales with the perimeter (in 2D) or surface area (in 3D) of the droplet. This interfacial contribution is referred to as the surface tension, and constitutes a true free energy cost: it includes not only the energetic penalty from broken bonds but also an entropic contribution due to the configurational degrees of freedom associated with the droplet shape.\nThe resulting competition between the extensive free energy gain and the sub-extensive interfacial cost leads to a free energy barrier for droplet formation. Only fluctuations that produce a droplet larger than a critical size \\(n_c\\) will grow; smaller droplets will shrink. This framework is formalized in classical nucleation theory, which provides a quantitative description of the nucleation rate, critical droplet size, and the associated activation energy barrier.",
    "crumbs": [
      "Chapters",
      "13. Nucleation and domain growth"
    ]
  },
  {
    "objectID": "nucleation-and-growth.html#classical-nucleation-theory-homogeneous-nucleation",
    "href": "nucleation-and-growth.html#classical-nucleation-theory-homogeneous-nucleation",
    "title": "Dynamics of first order phase transitions: nucleation and growth",
    "section": "",
    "text": "We now present the framework of classical nucleation theory (CNT) for the case of homogeneous nucleation, in which the nucleation of the stable phase occurs spontaneously and uniformly throughout the bulk of the metastable phase, without the aid of impurities, defects, or surfaces.\nLet us consider a droplet of the stable (spin-down) phase of radius \\(R\\) embedded within the metastable (spin-up) background. The total change in free energy \\(\\Delta F(R)\\) associated with forming such a droplet consists of two competing contributions:\n\nBulk free energy gain: The interior of the droplet consists of \\(V \\sim R^d\\) spins aligned with the external field \\(H &lt; 0\\), leading to a volume free energy change\n\\[\n\\Delta F_{\\text{bulk}}(R) = -|\\Delta f| \\, R^d,\n\\]\nwhere \\(|\\Delta f| \\propto |H|\\) is the free energy density difference between the metastable and stable phases, and \\(d\\) is the spatial dimensionality of the system.\nInterfacial free energy cost: The boundary between the two phases has a surface area scaling as \\(R^{d-1}\\), and incurs a free energy cost proportional to the surface tension \\(\\sigma\\):\n\\[\n\\Delta F_{\\text{surface}}(R) = \\sigma \\, S_d \\, R^{d-1},\n\\]\nwhere \\(S_d\\) is a geometrical factor (e.g., \\(S_2 = 2\\pi\\) in 2D and \\(S_3 = 4\\pi\\) in 3D).\n\nThe total free energy change is therefore given by\n\\[\n\\Delta F(R) = \\sigma \\, S_d \\, R^{d-1} - |\\Delta f| \\, V_d \\, R^d,\n\\]\nwhere \\(V_d\\) is another dimension-dependent constant. This expression exhibits a characteristic maximum at a critical droplet radius \\(R_c\\), obtained by extremizing \\(\\Delta F(R)\\) with respect to \\(R\\):\n\\[\n\\frac{d \\Delta F}{dR} = 0 \\quad \\Rightarrow \\quad R_c = \\frac{(d-1)\\sigma S_d}{d |\\Delta f| V_d}.\n\\]\n\n\n\n\n\n\nFigure 1: Free energy barrier \\(\\Delta F(r)\\) for nucleation of a spherical droplet as a function of radius \\(R\\) (schematic)\n\n\n\nThe corresponding free energy barrier for nucleation is\n\\[\n\\Delta F_c = \\Delta F(R_c) = \\frac{(d-1)^{d-1}}{d^d} \\cdot \\frac{(S_d)^d \\, \\sigma^d}{(|\\Delta f|)^{d-1} \\, (V_d)^{d-1}}.\n\\]\nThis barrier must be surmounted by thermal fluctuations in order for a critical nucleus to form and grow. The nucleation rate per unit volume is given (in the Arrhenius approximation) by\n\\[\nI \\sim I_0 \\exp\\left( -\\frac{\\Delta F_c}{k_B T} \\right),\n\\]\nwhere \\(I_0\\) is a prefactor determined by microscopic kinetics, and \\(k_B\\) is Boltzmann’s constant.\n\n\nSeveral key features emerge from this analysis:\n\nBarrier scaling: The nucleation barrier \\(\\Delta F_c \\sim \\sigma^d / |\\Delta f|^{d-1}\\) diverges as \\(H \\to 0\\), reflecting the increasing stability of the metastable phase near the coexistence point.\nCritical radius: The critical droplet size \\(R_c \\sim \\sigma / |\\Delta f|\\) also diverges as \\(|\\Delta f| \\to 0\\), indicating that larger fluctuations are required to initiate nucleation close to the coexistence line.\nDimensional dependence: Both \\(\\Delta F_c\\) and \\(R_c\\) exhibit strong dependence on the spatial dimension \\(d\\), with nucleation becoming increasingly suppressed in higher dimensions due to the dominance of interfacial cost.\n\nIn summary, homogeneous nucleation in a first-order transition is governed by a delicate balance between surface tension and bulk free energy gain. Only droplets exceeding a critical size can overcome the barrier and initiate a transition. This sets an intrinsic timescale for the dynamics of phase transformation, which can become extremely long near coexistence due to the exponentially small nucleation rate.",
    "crumbs": [
      "Chapters",
      "13. Nucleation and domain growth"
    ]
  },
  {
    "objectID": "nucleation-and-growth.html#late-time-dynamics-domain-growth-and-coarsening",
    "href": "nucleation-and-growth.html#late-time-dynamics-domain-growth-and-coarsening",
    "title": "Dynamics of first order phase transitions: nucleation and growth",
    "section": "",
    "text": "Following successful nucleation of a supercritical droplet, the system enters a regime where the global transformation is driven by the deterministic growth of domains of the stable phase. This phase of the dynamics is often referred to as coarsening or phase ordering dynamics.\nAt late times, the dynamics are controlled not by rare fluctuations, but by the energetically-driven evolution of domain structures. The nature of domain growth depends sensitively on whether the order parameter is conserved or not.\n\n\n\nIn systems with a non-conserved order parameter, such as the Ising model with single spin flip (so called Glauber) dynamics, the order parameter can relax locally without constraint. This leads to curvature-driven motion of interfaces.\nThe typical domain size \\(L(t)\\) grows algebraically with time:\n\\[\nL(t) \\sim t^{1/2},\n\\]\ncorresponding to a dynamic exponent \\(z = 2\\). The growth is driven by reduction of the total interfacial area—regions of high curvature (small domains) shrink and are absorbed by larger, flatter ones.\nLet is aassume that domain walls move with velocity proportional to curvature: \\[\n  v \\sim \\frac{1}{L}\n  \\] Then with the typical domain size being \\(L(t)\\) it follows that\n\\[\n  \\frac{dL}{dt} \\sim \\frac{1}{L}\n  \\]\nIntegrating both sides yields the \\(t^{1/2}\\) domain growth law.\nIt turns out that the detailed evolution of the coarse-grained order parameter field \\(\\phi(\\mathbf{r}, t)\\) is governed by the Allen–Cahn equation:\n\\[\n\\frac{\\partial \\phi}{\\partial t} = - \\frac{\\delta F[\\phi]}{\\delta \\phi},\n\\]\nwhere \\(F[\\phi]\\) is a coarse-grained Ginzburg–Landau free energy functional:\n\\[\nF[\\phi] = \\int d^d x \\left[ \\frac{1}{2} (\\nabla \\phi)^2 + V(\\phi) \\right],\n\\]\nwith \\(V(\\phi)\\) typically a double-well potential such as \\(V(\\phi) = \\frac{1}{4}(\\phi^2 - 1)^2\\).\n\n\n\n\nFor systems with a conserved order parameter, such as phase separation in binary alloys or the Ising model with spin-swap (so called ‘Kawasaki’) dynamics, the order parameter (e.g., composition or particle number) must be conserved locally. This imposes a diffusive constraint on the dynamics.\nThe domain size again grows algebraically, but with a different exponent:\n\\[\nL(t) \\sim t^{1/3},\n\\]\ncorresponding to a dynamic exponent \\(z = 3\\).\nA chemical potential difference drives diffusion and is given by \\[\n\\Delta \\mu \\sim \\frac{\\sigma}{L}\n\\] (again due to curvature, where \\(\\sigma\\) is surface tension)\nNow the flux is proportional to the chemical potential gradient (Fick’s law): \\[\n\\text{Flux} \\sim -\\nabla \\mu \\sim \\frac{\\Delta \\mu}{L} \\sim \\frac{\\sigma}{L^2}\n\\]\nand the rate of change of domain size is proportional to this flux: \\[\n\\frac{dL}{dt} \\sim \\frac{1}{L^2}\n\\quad\\Rightarrow\\quad\nL(t) \\sim t^{1/3}\n\\]\nIt turns out that the detailed dynamics are described by the Cahn–Hilliard equation, a continuity equation of the form:\n\\[\n\\frac{\\partial \\phi}{\\partial t} = \\nabla^2 \\left( \\frac{\\delta F[\\phi]}{\\delta \\phi} \\right),\n\\]\nreflecting that the order parameter can only evolve via diffusion of its conjugate chemical potential. This leads to the slow transport of material across domains and a more sluggish coarsening process compared to the non-conserved case.\n\n\n\nHere are schematic illustrations of domain growth for:\n\nNon-conserved dynamics (Model A): Domains coarsen rapidly, with smoother and larger regions due to free relaxation of the order parameter.\nConserved dynamics (Model B): Coarsening is slower and domains are more intricate, reflecting the constraint of local conservation.\n\n\n\n\n\n\n\n\n\nNon-Conserved Dynamics (Model A)\n\n\n\n\n\n\n\nConserved Dynamics (Model B)\n\n\n\n\n\n\nFigure 2: Schematic illustrations of domain morphology resulting from non-conserved and conserved dynamics.\n\n\n\n\n\n\nAt late times, both conserved and non-conserved systems exhibit dynamic scaling: the statistical properties of the domain morphology become self-similar under rescaling of lengths by \\(L(t)\\).\nFor example, the equal-time two-point correlation function satisfies\n\\[\nC(r, t) = f\\left( \\frac{r}{L(t)} \\right),\n\\]\nwhere \\(f(x)\\) is a time-independent scaling function. Plots of \\(C(r,t)\\) collapse when plotted as a function of \\(r/L(t)\\).The structure factor \\(S(k, t)\\) also obeys dynamic scaling:\n\\[\nS(k, t) = L(t)^d \\, g(k L(t)),\n\\]\nwith \\(g(x)\\) a universal scaling function dependent on the dynamical class and dimensionality.\n\n\n\n\n\n\n\n\n\n\n\n\n\nDynamics Type\nConservation\nEquation Type\nGrowth Law\nDynamic Exponent\n\n\n\n\nModel A (e.g. Glauber)\nNo\nAllen–Cahn\n\\(L(t) \\sim t^{1/2}\\)\n\\(z = 2\\)\n\n\nModel B (e.g. Kawasaki)\nYes\nCahn–Hilliard\n\\(L(t) \\sim t^{1/3}\\)\n\\(z = 3\\)\n\n\n\n\n\nRemarks: The domain growth exponents \\(1/z\\) are robust under many conditions, but can be modified in the presence of disorder, long-range interactions, or hydrodynamic effects.\n\n\nIn both the model A and model B cases, the system coarsens until it reaches equilibrium, characterized by a uniform macroscopic phase and the complete elimination of interfaces.\n\n\nThe approach to equilibrium is algebraically slow (described by power laws) due to the scale-free nature of domain dynamics.",
    "crumbs": [
      "Chapters",
      "13. Nucleation and domain growth"
    ]
  },
  {
    "objectID": "lattice-gas.html",
    "href": "lattice-gas.html",
    "title": "The Lattice Gas model",
    "section": "",
    "text": "A crude representation of a fluid is the lattice gas model. Here particles can occupy the sites of a hypercubic lattice. The occupancy of a site \\(i\\) is specified by the variable \\(c_i=1\\) (occupied) or \\(c_i=0\\) vacant. The complete list of these occupancies \\(\\{c\\}\\) specifies a microstate. The average particle number density (fraction of occupied sites) is given by\n\\[c=L^{-d}\\sum_i c_i \\]\nwhere \\(L\\) is the linear extent of the lattice and \\(d\\) its dimensionality.\nThe Hamiltonian of the lattice gas model is\n\\[{\\cal H}_{LG}=-\\epsilon\\sum_{&lt;i,j&gt;}c_ic_j - \\mu\\sum_ic_i\\]\nwhere \\(\\epsilon\\) is an attraction energy between a pair of particles on adjacent (nearest neighbouring) sites and \\(\\mu\\) is a field known as the chemical potential, which couples to the particle density which is assumed to fluctuate around a mean value controlled by the prescribed chemical potential. This representation of the model in which the overall density fluctuates is known as the Grand Canonical ensemble.",
    "crumbs": [
      "Chapters",
      "6. Lattice gas"
    ]
  },
  {
    "objectID": "lattice-gas.html#mapping-between-ising-model-and-lattice-gas",
    "href": "lattice-gas.html#mapping-between-ising-model-and-lattice-gas",
    "title": "The Lattice Gas model",
    "section": "Mapping between Ising model and lattice gas",
    "text": "Mapping between Ising model and lattice gas\nThe lattice gas model is interesting because whilst being a plausible model for a fluid, it maps onto the Ising model. This extends the applicability of the Ising model. To expose the mapping we write the grand partition function of the lattice gas:\n\\[ \\Xi=\\sum_\\textrm{ state}\\exp-\\beta{\\cal H}_{LG}=\\sum_{\\{c\\}}\\exp\\left[\\beta \\epsilon\\sum_{&lt;i,j&gt;}c_ic_j +\\beta\\mu\\sum_ic_i\\right] \\] where the sum is an unrestricted sum over the occupancies of the lattice sites. We now change variables to\n\\[c_i=(1+s_i)/2; ~~~~ J=\\frac{\\epsilon}{4} ~~~~\nh=\\frac{\\epsilon q+2\\mu}{4}\\] Hence\n\\[{\\cal H}_{LG}={\\cal H}_\\textrm{ I} + \\textrm{ constant}\\] Since the last term does not depend on the configuration, it feeds through as an additive constant in the free energy; and since all observables feature as derivatives of the free energy, the constant has no physical implications.",
    "crumbs": [
      "Chapters",
      "6. Lattice gas"
    ]
  },
  {
    "objectID": "lattice-gas.html#phase-diagram",
    "href": "lattice-gas.html#phase-diagram",
    "title": "The Lattice Gas model",
    "section": "Phase diagram",
    "text": "Phase diagram\nUsing these translation rules we can plot the phase diagram of the lattice gas in the \\(\\mu-T\\) plane.\n\n\n\n\n\n\nFigure 1: Phase diagram of the lattice gas model\n\n\n\nAgain there is a line of first order phase transitions terminating at a critical point. The first order line means that if \\(T&lt;T_c\\) we smoothly increase the chemical potential through the coexistence value of \\(\\mu\\), the density of particles on our lattice \\(c\\) jumps discontinuously from a low to a high value.\n\\[c_\\textrm{ gas}=\\frac{1-m^\\star}{2} \\to c_\\textrm{ liquid}=\\frac{1+m^\\star}{2}\\] These values merge at \\(T_c\\), the gas-liquid critical point. At higher temperatures, the distinction between the phases disappears.",
    "crumbs": [
      "Chapters",
      "6. Lattice gas"
    ]
  },
  {
    "objectID": "lattice-gas.html#real-fluids",
    "href": "lattice-gas.html#real-fluids",
    "title": "The Lattice Gas model",
    "section": "Real Fluids",
    "text": "Real Fluids\nYou may wish to compare this with the results of (say) van der Waals equation (see recommended textbooks for the required phase diagram). The main difference is that the lattice gas has “Particle-hole” symmetry, \\(c\\to 1-c\\) which is not present for an ordinary fluid. Accordingly, the phase diagram in a real fluid looks like a lopsided version of the above picture.",
    "crumbs": [
      "Chapters",
      "6. Lattice gas"
    ]
  },
  {
    "objectID": "approach-to-criticality.html",
    "href": "approach-to-criticality.html",
    "title": "The Approach to Criticality",
    "section": "",
    "text": "It is a matter of experimental fact that the approach to criticality in a given system is characterized by the divergence of various thermodynamic observables. Let us remain with the archetypal example of a critical system, the ferromagnet, whose critical temperature will be denoted as \\(T_c\\). For temperatures close to \\(T_c\\), the magnetic response functions (the magnetic susceptibility \\(\\chi\\) and the specific heat) are found to be singular functions, diverging as a power of the reduced (dimensionless) temperature \\(t \\equiv\n(T-T_c)/T_c\\):-\n\\[\\chi \\equiv \\frac{\\partial M}{\\partial H}\\propto t^{-\\gamma} ~~~~ (H=0)\n\\label{eq:chipow}\\]\n(where \\(M=mN\\)), \\[C_H \\equiv \\frac{\\partial E}{\\partial T}\\propto t^{-\\alpha} ~~~~ (H=\\textrm{ constant})\n\\label{eq:Cv}\\]\nAnother key quantity is the correlation length \\(\\xi\\), which measures the distance over which fluctuations of the magnetic moments are correlated. This is observed to diverge near the critical point with an exponent \\(\\nu\\).\n\\[\\xi \\propto t^{-\\nu} ~~~~ (T &gt; T_c,\\: H=0)\n\\label{eq:corr}\\]\nSimilar power law behaviour is found for the order parameter \\(Q\\) (in this case the magnetisation) which vanishes in a singular fashion (it has infinite gradient) as the critical point is is approached as a function of temperature:\n\\[m \\propto t^{\\beta} ~~~~ (T &lt; T_c,\\: H=0) \\label{eq:mag},\\] (here the symbol \\(\\beta\\), is not to be confused with \\(\\beta=1/k_BT\\)– this unfortunately is the standard notation.)\nFinally, as a function of magnetic field:\n\\[m \\propto h^{1/\\delta} ~~~~ (T = T_c,\\: H&gt;0) \\label{eq:field}.\\] with \\(h=(H-H_c)/H_c\\), the reduced magnetic field.\nAs examples, the behaviour of the magnetisation and correlation length are plotted in fig. 4 as a function of \\(t\\).\n\n\n\n\n\n\nFigure 1: Singular behaviour of the correlation length and order parameter in the vicinity of the critical point as a function of the reduced temperature \\(t\\).\n\n\n\nThe quantities \\(\\gamma, \\alpha, \\nu, \\beta\\) in the above equations are known as critical exponents. They serve to control the rate at which the various thermodynamic quantities change on the approach to criticality.\nRemarkably, the form of singular behaviour observed at criticality for the example ferromagnet also occurs in qualitatively quite different systems such as the fluid. All that is required to obtain the corresponding power law relationships for the fluid is to substitute the analogous thermodynamic quantities in to the above equations. Accordingly the magnetisation order parameter is replaced by the density difference \\(\\rho_{liq}-\\rho_{gas}\\) while the susceptibility is replaced by the isothermal compressibility and the specific heat capacity at constant field is replaced by the specific heat capacity at constant volume. The approach to criticality in a variety of qualitatively quite different systems can therefore be expressed in terms of a set of critical exponents describing the power law behaviour for that system (see the book by Yeomans for examples).\nEven more remarkable is the experimental observation that the values of the critical exponents for a whole range of fluids and magnets (and indeed many other systems with critical points) are identical. This is the phenomenon of universality. It implies a deep underlying physical similarity between ostensibly disparate critical systems. The principal aim of theories of critical point phenomena is to provide a sound theoretical basis for the existence of power law behaviour, the factors governing the observed values of critical exponents and the universality phenomenon. Ultimately this basis is provided by the Renormalisation Group (RG) theory, for which K.G. Wilson was awarded the Nobel Prize in Physics in 1982.",
    "crumbs": [
      "Chapters",
      "3. The approach to criticality"
    ]
  },
  {
    "objectID": "background.html",
    "href": "background.html",
    "title": "Background concepts",
    "section": "",
    "text": "Background concepts\nIn seeking to describe near-critical phenomena, it is useful to have a quantitative measure of the difference between the phases coalescing at the critical point: this is the role of the order parameter, \\(Q\\). In the case of the fluid, the order parameter is taken as the difference between the densities of the liquid and vapour phases. In the ferromagnet it is taken as the magnetisation. As its name suggest, the order parameter serves as a measure of the kind of orderliness that sets in when the temperature is cooled below a critical temperature.\nOur first task is to give some feeling for the principles which underlie the ordering process. The probability \\(p_a\\) that a physical system at temperature \\(T\\) will have a particular microscopic arrangement (configuration), labelled \\(a\\), of energy \\(E_a\\) is\n\\[p_a=\\frac{1}{Z}e^{-E_a/k_BT}\n\\tag{1}\\]\nThe prefactor \\(Z^{-1}\\) is the partition function: since the system must always have some specific arrangement, the sum of the probabilities \\(p_a\\) must be unity, implying that\n\\[Z=\\sum_ae^{-E_a/k_BT}\n\\tag{2}\\] where the sum extends over all possible microscopic arrangements.\nThese equations assume that physical system evolves rapidly (on the timescale of typical observations) amongst all its allowed arrangements, sampling them with the probabilities Equation 1 the expectation value of any physical observable \\(O\\) will thus be given by averaging \\(O\\) over all the arrangements \\(a\\), weighting each contribution by the appropriate probability:\n\\[\\bar {O}=\\frac{1}{Z}\\sum_a O_a e^{-E_a/k_BT}\n\\tag{3}\\]\nSums like Equation 3 are not easily evaluated. Nevertheless, some important insights follow painlessly. Consider the case where the observable of interest is the order parameter, or more specifically the magnetisation of a ferromagnet.\n\\[Q=\\frac{1}{Z}\\sum_a Q_a e^{-E_a/k_BT}\n\\tag{4}\\]\nIt is clear from Equation 1 that at very low temperature the system will be overwhelmingly likely to be found in its minimum energy arrangements (ground states). For the ferromagnet, these are the fully ordered spin arrangements having magnetisation \\(+1\\), or \\(-1\\).\nNow consider the high temperature limit. The enhanced weight that the fully ordered arrangement carries in the sum of Equation 4 by virtue of its low energy, is now no longer sufficient to offset the fact that arrangements in which \\(Q_a\\) has some intermediate value, though each carry a smaller weight, are vastly greater in number. A little thought shows that the arrangements which have essentially zero magnetisation (equal populations of up and down spins) are by far the most numerous. At high temperature, these disordered arrangements dominate the sum in Equation 4 and the order parameter is zero.\nThe competition between energy-of-arrangements weighting (or simply ‘energy’) and the ‘number of arrangements’ weighting (or ‘entropy’) is then the key principle at work here. The distinctive feature of a system with a critical point is that, in the course of this competition, the system is forced to choose amongst a number of macroscopically different sets of microscopic arrangements.\nFinally in this section, we note that the probabilistic (statistical mechanics) approach to thermal systems outlined above is completely compatible with classical thermodynamics. Specifically, the bridge between the two disciplines is provided by the following equation\n\\[F=-k_BT \\ln Z\n\\tag{5}\\]\nwhere \\(F\\) is the “Helmholtz free energy”. All thermodynamic observables, for example the order parameter \\(Q\\), and response functions such as the specific heat or magnetic susceptibility are obtainable as appropriate derivatives of the free energy. For instance, utilizing Equation 2, one can readily verify (try it as an exercise!) that the average internal energy is given by\n\\[\\bar{E}=-\\frac{\\partial \\ln Z}{\\partial \\beta},\\]\nwhere \\(\\beta=(k_BT)^{-1}\\).\nThe relationship between other thermodynamic quantities and derivatives of the free energy are given in fig. 3\n\n\n\nRelationships between the partition function and thermodynamic observables",
    "crumbs": [
      "Chapters",
      "2. Background concepts"
    ]
  },
  {
    "objectID": "Ising-model.html",
    "href": "Ising-model.html",
    "title": "The Ising model: the prototype model for a phase transition",
    "section": "",
    "text": "In order to probe the properties of the critical region, it is common to appeal to simplified model systems whose behaviour parallels that of real materials. The sophistication of any particular model depends on the properties of the system it is supposed to represent. The simplest model to exhibit critical phenomena is the two-dimensional Ising model of a ferromagnet. Actual physical realizations of 2-d magnetic systems do exist in the form of layered ferromagnets such as K\\(_2\\)CoF\\(_4\\), so the 2-d Ising model is of more than just technical relevance.\n\n\nThe 2-d spin-\\(\\frac{1}{2}\\) Ising model envisages a regular arrangement of magnetic moments or ‘spins’ on an infinite plane. Each spin can take two values, \\(+1\\) (‘up’ spins) or \\(-1\\) (‘down’ spins) and is assumed to interact with its nearest neighbours according to the Hamiltonian\n\\[{\\cal H}_I=-J\\sum_{&lt;ij&gt;}s_is_j - H\\sum_i s_i\n\\]{eq-ising}\nwhere \\(J&gt;0\\) measures the strength of the coupling between spins and the sum extends over nearest neighbour spins \\(s_i\\) and \\(s_j\\), i.e it is a sum of the bonds of the lattice. \\(H\\) is a magnetic field term which can be positive or negative (although for the time being we will set it equal to zero). The order parameter is simply the average magnetisation:\n\\[m=\\frac{1}{N} \\langle \\sum_i s_i \\rangle\\:,\\] where \\(\\langle\\cdot\\rangle\\) means an average over configurations.\nThe fact that the Ising model displays a phase transition was argued in ?@sec-background. Thus at low temperatures for which there is little thermal disorder, there is a preponderance of aligned spins and hence a net spontaneous magnetic moment (ie. the system is ferromagnetic). As the temperature is raised, thermal disorder increases until at a certain temperature \\(T_c\\), entropy drives the system through a continuous phase transition to a disordered spin arrangement with zero net magnetisation (ie. the system is paramagnetic). These trends are visible in configurational snapshots from computer simulations of the 2D Ising model (see Figure 1). Although each spin interacts only with its nearest neighbours, the phase transition occurs due to cooperative effects among a large number of spins. In the neighbourhood of the transition temperature these cooperative effects engender fluctuations that can extend over all length-scales from the lattice spacing up to the correlation length.\n\n\n\n\n\n\n\n\n\\(T=1.2T_c\\)\n\n\n\n\n\n\n\n\\(T=T_c\\)\n\n\n\n\n\n\n\n\\(T=0.95T_c\\)\n\n\n\n\n\n\nFigure 1: Configurations of the 2d Ising model. The patterns depict typical arrangements of the spins (white=+1, black=−1) generated in a computer simulation of the Ising model on a square lattice of \\(N=512\\) sites, at temperatures (from left to right) of \\(T= 1.2T_c\\), \\(T=T_c\\), and \\(T=0.95T_c\\). In each case only a portion of the system containing \\(128\\) sites in shown. The typical island size is a measure of the correlation length \\(\\xi\\): the excess of black over white (below \\(T_c\\) is a measure of the order parameter.\n\n\n\nAn interactive Monte Carlo simulation of the Ising model demonstrates the phenonomenology, By altering the temperature you will be able to observe for yourself how the spin arrangements change as one traverses the critical region. Pay particular attention to the configurations near the critical point. They have very interesting properties. We will return to them later!\nAlthough the 2-d Ising model may appear at first sight to be an excessively simplistic portrayal of a real magnetic system, critical point universality implies that many physical observables such as critical exponents are not materially influenced by the actual nature of the microscopic interactions. The Ising model therefore provides a simple, yet quantitatively accurate representation of the critical properties of a whole range of real magnetic (and indeed fluid) systems. This universal feature of the model is largely responsible for its ubiquity in the field of critical phenomena. We shall explore these ideas in more detail later in the course.\n\n\n\nOne might well ask why the 2D Ising model is the simplest model to exhibit a phase transition. What about the one-dimensional Ising model (ie. spins on a line)? In fact in one dimension, the Ising model can be solved exactly. It turns out that the system is paramagnetic for all \\(T&gt;0\\), so there is no phase transition at any finite temperature. To see this, consider the ground state of the system in zero external field. This will have all spins aligned the same way (say up), and hence be ferromagnetic. Now consider a configuration with a various “domain walls” dividing spin up and spin down regions:\n\n\n\n\n\n\nFigure 2: (a) Schematic of an Ising chain at \\(T=0\\). (b) At a small finite temperature the chain is split into domains of spins ordered in the same direction. Domains are separated by notional domain “walls”, which cost energy \\(\\Delta=2J\\). Periodic boundary conditions are assumed.\n\n\n\nInstead of considering the underlying spin configurations, we shall describe the system in terms of the statistics of its domain walls. The energy cost of a wall is \\(\\Delta = 2J\\), independent of position. Domain walls can occupy the bonds of the lattice, of which there are \\(N-1\\). Moreover, the walls are noninteracting, except that you cannot have two of them on the same bond. (Check through these ideas if you are unsure.)\nIn this representation, the partition function involves a count over all possible domain wall arrangements. Since the domain walls are non interacting (eg it doesn’t cost energy for one to move along the chain) we can calculate \\(Z\\) by considering the partition function associated with a single domain wall being present or absent on some given bond, and then simply raise to the power of the number of bonds:\n\\[Z=Z_1^{N-1}\\]\nwhere\n\\[Z_1=e^{\\beta J} + e^{\\beta (J-\\Delta)}=e^{\\beta J}(1+e^{-\\beta\\Delta})\\] is the domain wall partition function for a single bond and represent the sum over the two possible states: domain wall absent or present. Then the free energy per bond of the system is\n\\[\\beta f\\equiv \\beta F/(N-1)=-\\ln Z_1=-\\beta J-\\ln(1+e^{-\\beta\\Delta})\\]\nThe first term on the RHS is simply the energy per spin of the ferromagnetic (ordered) phase, while the second term arises from the free energy of domain walls. Clearly for any finite temperature (ie. for \\(\\beta&lt;\\infty\\)), this second term is finite and negative. Hence the free energy will always be lowered by having a finite concentration of domain walls in the system. Since these domain walls disorder the system, leading to a zero average magnetisation, the 1D system is paramagnetic for all finite temperatures. Exercise: Explain why this argument works only in 1D.\n\n\nGenerally speaking one-dimensional systems lend themselves to a degree of analytic tractability not found in most higher dimensional models. Indeed for the case of a 1-d assembly of \\(N\\) spins each having \\(m\\) discrete energy states, and in the presence of a magnetic field, it is possible to reduce the evaluation of the partition function to the calculation of the eigenvalues of a matrix–the so called transfer matrix.\nLet us start by assuming that the assembly has cyclic boundary conditions, then the total energy of configuration \\(\\{s\\}\\) is\n\\[\\begin{aligned}\nH(\\{s\\})=&-\\sum_{i=1}^N (Js_is_{i+1}+Hs_i)\\\\\n\\:=&-\\sum_{i=1}^N (Js_is_{i+1}+H(s_i+s_{i+1})/2)\\\\\n\\:=&\\sum_{i=1}^N E(s_i,s_{i+1})\n\\end{aligned}\\]\nwhere we have defined \\(E(s_i,s_{i+1})=-Js_is_{i+1}-H(s_i+s_{i+1})/2\\).\nNow the partition function may be written\n\\[\\begin{aligned}\n{eq-tm}\nZ_N =& \\sum_{\\{s\\}}\\exp\\left(-\\beta H(\\{s\\})\\right)\\nonumber \\\\\n=&\\sum_{\\{s\\}}\\exp\\left(-\\beta[E(s_1,s_2)+E(s_2,s_3)+....E(s_N,s_1)]\\right) \\nonumber\\\\\n=&\\sum_{\\{s\\}}\\exp\\left(-\\beta E(s_1,s_2)\\right)\\exp\\left(-\\beta E(s_2,s_3)\\right)....\\exp\\left(-\\beta E(s_N,s_1)\\right) \\nonumber\\\\\n=&\\sum_{i,j,...,l=1}^m V_{ij}V_{jk}...V_{li} {eq-Vs}\n\\end{aligned}\\]\nwhere the \\(V_{ij}=\\exp(-\\beta E_{ij})\\) are elements of an \\(m \\times m\\) matrix \\({\\bf V}\\), known as the transfer matrix (\\(i,j,k\\) etc are dummy indices that run over the matrix elements). You should see that the sum over the product of matrix elements picks up all the terms in the partition function and therefore Eq. [eq-Vs] is an alternative way of writing the partition function.\nThe reason it is useful to transform to a matrix representation is that it transpires that the sum over the product of matrix elements in equation ([eq-Vs]) is simply just the trace of \\({\\bf V}^N\\) (check this yourself for a short periodic chain), given by the sum of its eigenvalues:-\n\\[Z_N=\\lambda_1^N+\\lambda_2^N+...\\lambda_m^N\\] For very large \\(N\\), this expression simplifies further because the largest eigenvalue \\(\\lambda_1\\) dominates the behaviour since \\((\\lambda_2/\\lambda_1)^N\\) vanishes as \\(N\\rightarrow \\infty\\). Consequently in the thermodynamic limit one may put \\(Z_N=\\lambda_1^N\\) and the problem reduces to identifying the largest eigenvalue of the transfer matrix.\nSpecializing to the case of the simple Ising model in the presence of an applied field \\(H\\), the transfer matrix takes the form\n\\[{\\bf V}(H)=\\left(\n\\begin{array}{cc}\ne^{\\beta(J+H)} & e^{-\\beta J} \\\\\ne^{-\\beta J}   & e^{\\beta(J-H)}\n\\end{array} \\right)\\]\nThis matrix has two eigenvalues which can be readily calculated in the usual fashion as the roots of the characteristic polynomial \\(|{\\bf V}-\\lambda{\\bf I}|\\). They are\n\\[\\lambda_{\\pm}=e^{\\beta J}\\cosh(\\beta H) \\pm \\sqrt{e^{2\\beta J}\\sinh^2\\beta H+e^{-2\\beta J}}.\\]\nHence the free energy per spin \\(f=-k_BT\\ln \\lambda_+\\) is\n\\[f=-k_BT\\ln \\left[e^{\\beta J}\\cosh(\\beta H) + \\sqrt{e^{2\\beta J}\\sinh^2\\beta H+e^{-2\\beta J}}\\right].\\]\nThe Ising model in 2D can also be solved exactly, as was done by Lars Onsager in 1940. The solution is extremely complicated and is regarded as one of the pinnacles of statistical mechanics. In 3D no exact solution is known.",
    "crumbs": [
      "Chapters",
      "4. The Ising model"
    ]
  },
  {
    "objectID": "Ising-model.html#the-2d-ising-model",
    "href": "Ising-model.html#the-2d-ising-model",
    "title": "The Ising model: the prototype model for a phase transition",
    "section": "",
    "text": "The 2-d spin-\\(\\frac{1}{2}\\) Ising model envisages a regular arrangement of magnetic moments or ‘spins’ on an infinite plane. Each spin can take two values, \\(+1\\) (‘up’ spins) or \\(-1\\) (‘down’ spins) and is assumed to interact with its nearest neighbours according to the Hamiltonian\n\\[{\\cal H}_I=-J\\sum_{&lt;ij&gt;}s_is_j - H\\sum_i s_i\n\\]{eq-ising}\nwhere \\(J&gt;0\\) measures the strength of the coupling between spins and the sum extends over nearest neighbour spins \\(s_i\\) and \\(s_j\\), i.e it is a sum of the bonds of the lattice. \\(H\\) is a magnetic field term which can be positive or negative (although for the time being we will set it equal to zero). The order parameter is simply the average magnetisation:\n\\[m=\\frac{1}{N} \\langle \\sum_i s_i \\rangle\\:,\\] where \\(\\langle\\cdot\\rangle\\) means an average over configurations.\nThe fact that the Ising model displays a phase transition was argued in ?@sec-background. Thus at low temperatures for which there is little thermal disorder, there is a preponderance of aligned spins and hence a net spontaneous magnetic moment (ie. the system is ferromagnetic). As the temperature is raised, thermal disorder increases until at a certain temperature \\(T_c\\), entropy drives the system through a continuous phase transition to a disordered spin arrangement with zero net magnetisation (ie. the system is paramagnetic). These trends are visible in configurational snapshots from computer simulations of the 2D Ising model (see Figure 1). Although each spin interacts only with its nearest neighbours, the phase transition occurs due to cooperative effects among a large number of spins. In the neighbourhood of the transition temperature these cooperative effects engender fluctuations that can extend over all length-scales from the lattice spacing up to the correlation length.\n\n\n\n\n\n\n\n\n\\(T=1.2T_c\\)\n\n\n\n\n\n\n\n\\(T=T_c\\)\n\n\n\n\n\n\n\n\\(T=0.95T_c\\)\n\n\n\n\n\n\nFigure 1: Configurations of the 2d Ising model. The patterns depict typical arrangements of the spins (white=+1, black=−1) generated in a computer simulation of the Ising model on a square lattice of \\(N=512\\) sites, at temperatures (from left to right) of \\(T= 1.2T_c\\), \\(T=T_c\\), and \\(T=0.95T_c\\). In each case only a portion of the system containing \\(128\\) sites in shown. The typical island size is a measure of the correlation length \\(\\xi\\): the excess of black over white (below \\(T_c\\) is a measure of the order parameter.\n\n\n\nAn interactive Monte Carlo simulation of the Ising model demonstrates the phenonomenology, By altering the temperature you will be able to observe for yourself how the spin arrangements change as one traverses the critical region. Pay particular attention to the configurations near the critical point. They have very interesting properties. We will return to them later!\nAlthough the 2-d Ising model may appear at first sight to be an excessively simplistic portrayal of a real magnetic system, critical point universality implies that many physical observables such as critical exponents are not materially influenced by the actual nature of the microscopic interactions. The Ising model therefore provides a simple, yet quantitatively accurate representation of the critical properties of a whole range of real magnetic (and indeed fluid) systems. This universal feature of the model is largely responsible for its ubiquity in the field of critical phenomena. We shall explore these ideas in more detail later in the course.",
    "crumbs": [
      "Chapters",
      "4. The Ising model"
    ]
  },
  {
    "objectID": "Ising-model.html#exact-solutions-the-one-dimensional-ising-chain",
    "href": "Ising-model.html#exact-solutions-the-one-dimensional-ising-chain",
    "title": "The Ising model: the prototype model for a phase transition",
    "section": "",
    "text": "One might well ask why the 2D Ising model is the simplest model to exhibit a phase transition. What about the one-dimensional Ising model (ie. spins on a line)? In fact in one dimension, the Ising model can be solved exactly. It turns out that the system is paramagnetic for all \\(T&gt;0\\), so there is no phase transition at any finite temperature. To see this, consider the ground state of the system in zero external field. This will have all spins aligned the same way (say up), and hence be ferromagnetic. Now consider a configuration with a various “domain walls” dividing spin up and spin down regions:\n\n\n\n\n\n\nFigure 2: (a) Schematic of an Ising chain at \\(T=0\\). (b) At a small finite temperature the chain is split into domains of spins ordered in the same direction. Domains are separated by notional domain “walls”, which cost energy \\(\\Delta=2J\\). Periodic boundary conditions are assumed.\n\n\n\nInstead of considering the underlying spin configurations, we shall describe the system in terms of the statistics of its domain walls. The energy cost of a wall is \\(\\Delta = 2J\\), independent of position. Domain walls can occupy the bonds of the lattice, of which there are \\(N-1\\). Moreover, the walls are noninteracting, except that you cannot have two of them on the same bond. (Check through these ideas if you are unsure.)\nIn this representation, the partition function involves a count over all possible domain wall arrangements. Since the domain walls are non interacting (eg it doesn’t cost energy for one to move along the chain) we can calculate \\(Z\\) by considering the partition function associated with a single domain wall being present or absent on some given bond, and then simply raise to the power of the number of bonds:\n\\[Z=Z_1^{N-1}\\]\nwhere\n\\[Z_1=e^{\\beta J} + e^{\\beta (J-\\Delta)}=e^{\\beta J}(1+e^{-\\beta\\Delta})\\] is the domain wall partition function for a single bond and represent the sum over the two possible states: domain wall absent or present. Then the free energy per bond of the system is\n\\[\\beta f\\equiv \\beta F/(N-1)=-\\ln Z_1=-\\beta J-\\ln(1+e^{-\\beta\\Delta})\\]\nThe first term on the RHS is simply the energy per spin of the ferromagnetic (ordered) phase, while the second term arises from the free energy of domain walls. Clearly for any finite temperature (ie. for \\(\\beta&lt;\\infty\\)), this second term is finite and negative. Hence the free energy will always be lowered by having a finite concentration of domain walls in the system. Since these domain walls disorder the system, leading to a zero average magnetisation, the 1D system is paramagnetic for all finite temperatures. Exercise: Explain why this argument works only in 1D.\n\n\nGenerally speaking one-dimensional systems lend themselves to a degree of analytic tractability not found in most higher dimensional models. Indeed for the case of a 1-d assembly of \\(N\\) spins each having \\(m\\) discrete energy states, and in the presence of a magnetic field, it is possible to reduce the evaluation of the partition function to the calculation of the eigenvalues of a matrix–the so called transfer matrix.\nLet us start by assuming that the assembly has cyclic boundary conditions, then the total energy of configuration \\(\\{s\\}\\) is\n\\[\\begin{aligned}\nH(\\{s\\})=&-\\sum_{i=1}^N (Js_is_{i+1}+Hs_i)\\\\\n\\:=&-\\sum_{i=1}^N (Js_is_{i+1}+H(s_i+s_{i+1})/2)\\\\\n\\:=&\\sum_{i=1}^N E(s_i,s_{i+1})\n\\end{aligned}\\]\nwhere we have defined \\(E(s_i,s_{i+1})=-Js_is_{i+1}-H(s_i+s_{i+1})/2\\).\nNow the partition function may be written\n\\[\\begin{aligned}\n{eq-tm}\nZ_N =& \\sum_{\\{s\\}}\\exp\\left(-\\beta H(\\{s\\})\\right)\\nonumber \\\\\n=&\\sum_{\\{s\\}}\\exp\\left(-\\beta[E(s_1,s_2)+E(s_2,s_3)+....E(s_N,s_1)]\\right) \\nonumber\\\\\n=&\\sum_{\\{s\\}}\\exp\\left(-\\beta E(s_1,s_2)\\right)\\exp\\left(-\\beta E(s_2,s_3)\\right)....\\exp\\left(-\\beta E(s_N,s_1)\\right) \\nonumber\\\\\n=&\\sum_{i,j,...,l=1}^m V_{ij}V_{jk}...V_{li} {eq-Vs}\n\\end{aligned}\\]\nwhere the \\(V_{ij}=\\exp(-\\beta E_{ij})\\) are elements of an \\(m \\times m\\) matrix \\({\\bf V}\\), known as the transfer matrix (\\(i,j,k\\) etc are dummy indices that run over the matrix elements). You should see that the sum over the product of matrix elements picks up all the terms in the partition function and therefore Eq. [eq-Vs] is an alternative way of writing the partition function.\nThe reason it is useful to transform to a matrix representation is that it transpires that the sum over the product of matrix elements in equation ([eq-Vs]) is simply just the trace of \\({\\bf V}^N\\) (check this yourself for a short periodic chain), given by the sum of its eigenvalues:-\n\\[Z_N=\\lambda_1^N+\\lambda_2^N+...\\lambda_m^N\\] For very large \\(N\\), this expression simplifies further because the largest eigenvalue \\(\\lambda_1\\) dominates the behaviour since \\((\\lambda_2/\\lambda_1)^N\\) vanishes as \\(N\\rightarrow \\infty\\). Consequently in the thermodynamic limit one may put \\(Z_N=\\lambda_1^N\\) and the problem reduces to identifying the largest eigenvalue of the transfer matrix.\nSpecializing to the case of the simple Ising model in the presence of an applied field \\(H\\), the transfer matrix takes the form\n\\[{\\bf V}(H)=\\left(\n\\begin{array}{cc}\ne^{\\beta(J+H)} & e^{-\\beta J} \\\\\ne^{-\\beta J}   & e^{\\beta(J-H)}\n\\end{array} \\right)\\]\nThis matrix has two eigenvalues which can be readily calculated in the usual fashion as the roots of the characteristic polynomial \\(|{\\bf V}-\\lambda{\\bf I}|\\). They are\n\\[\\lambda_{\\pm}=e^{\\beta J}\\cosh(\\beta H) \\pm \\sqrt{e^{2\\beta J}\\sinh^2\\beta H+e^{-2\\beta J}}.\\]\nHence the free energy per spin \\(f=-k_BT\\ln \\lambda_+\\) is\n\\[f=-k_BT\\ln \\left[e^{\\beta J}\\cosh(\\beta H) + \\sqrt{e^{2\\beta J}\\sinh^2\\beta H+e^{-2\\beta J}}\\right].\\]\nThe Ising model in 2D can also be solved exactly, as was done by Lars Onsager in 1940. The solution is extremely complicated and is regarded as one of the pinnacles of statistical mechanics. In 3D no exact solution is known.",
    "crumbs": [
      "Chapters",
      "4. The Ising model"
    ]
  },
  {
    "objectID": "Brownian-and-Langevin-dynamics.html",
    "href": "Brownian-and-Langevin-dynamics.html",
    "title": "The Langevin Approach",
    "section": "",
    "text": "The concept of a random walk and its continuum limit — diffusion — introduced in the previous chapter, expresses the time evolution of the probability distribution \\(p(x, t)\\) for a particle’s position \\(x\\) is described by the diffusion equation:\n\\[\n\\frac{\\partial p}{\\partial t} = D \\frac{\\partial^2 p}{\\partial x^2},\n\\]\nwhich is a standard example of a so called Fokker-Planck equation, which is second-order in space and first-order in time.\nIn contrast, the Langevin equation provides a stochastic differential equation for the particle’s trajectory \\(x(t)\\). To understand it, consider the motion over a small time increment \\(\\Delta t\\):\n\\[\nx(t + \\Delta t) = x(t) + \\Delta x(t)\n\\]\nHere, \\(\\Delta x(t)\\) is a random displacement. If the lattice spacing is \\(a\\), we define the step statistics as:\n\\[\n\\Delta x(t) =\n\\begin{cases}\n+a & \\text{with probability } \\nu \\Delta t \\\\\n-a & \\text{with probability } \\nu \\Delta t \\\\\n0 & \\text{with probability } 1 - 2\\nu \\Delta t\n\\end{cases}\n\\]\nThis defines a discrete-time, discrete-space random walk. The average and variance of the step are:\n\nMean: \\(\\langle \\Delta x \\rangle = 0\\)\nVariance: \\(\\langle (\\Delta x)^2 \\rangle = 2 a^2 \\nu \\Delta t = 2D \\Delta t\\)\n\nThe steps \\(\\Delta x(t)\\) are uncorrelated across time.\nTo take the continuum limit, we let both \\(a \\to 0\\) and \\(\\Delta t \\to 0\\) in such a way that:\n\\[\na \\propto \\sqrt{\\Delta t}\n\\]\nIn this limit, we obtain the Langevin equation:\n\\[\n\\dot{x}(t) = \\eta(t)\n\\]\nwhere \\(\\eta(t)\\) is a stochastic force (noise) satisfying:\n\\[\n\\langle \\eta(t) \\rangle = 0\n\\]\n\\[\n\\langle \\eta(t) \\eta(t') \\rangle = \\Gamma \\delta(t - t')\n\\]\nThis \\(\\eta(t)\\) is known as white noise — it has zero mean and is uncorrelated at different times.\nThe Langevin equation tells us that the velocity \\(\\dot{x}(t)\\) is purely driven by noise. We can formally integrate it:\n\\[\nx(t) - x_0 = \\int_0^t \\eta(t')\\, dt'\n\\]\nTaking ensemble averages:\n\nMean displacement: \\[\n\\langle x(t) - x_0 \\rangle = 0\n\\]\nMean square displacement: \\[\n\\langle [x(t) - x_0]^2 \\rangle = \\int_0^t \\int_0^t \\langle \\eta(t') \\eta(t'') \\rangle\\, dt'\\, dt'' = \\Gamma \\int_0^t dt' = \\Gamma t\n\\]\n\nComparing this with the diffusion equation result, we identify:\n\\[\n\\Gamma = 2D\n\\]\nHence, the Langevin description yields the same physical behavior — not just the mean-square displacement but also the full probability distribution \\(p(x, t)\\) — as the diffusion (Fokker-Planck) equation. This equivalence arises from the fact that the integral of many small, independent random steps leads to a Gaussian distribution, in agreement with the solution of the diffusion equation.\nFor more details, see: Stochastic Processes in Physics and Chemistry by N.G. van Kampen (North Holland, 1981).\n\n\n\nLet us now examine Brownian motion, originally observed as the erratic motion of colloidal particles suspended in a fluid. These particles undergo constant collisions with surrounding (smaller) fluid molecules, which results in seemingly random movement.\nFrom a coarse-grained perspective — where we do not track each individual collision — this appears as motion under random forces. This statistical treatment introduces irreversibility at the macroscopic level, even though the underlying molecular dynamics are reversible.\nThe Langevin equation provides a way to model this behavior. For a particle of mass \\(m\\) in one dimension, Langevin proposed the equation:\n\\[\nm \\ddot{x} = -\\gamma \\dot{x} + f(t)\n\\]\nHere:\n\n\\(-\\gamma \\dot{x}\\) is a frictional damping force, where \\(\\gamma\\) is the damping coefficient.\n\\(f(t)\\) is a random force due to molecular collisions.\n\n\nOften, the mobility is defined as \\(\\mu = 1/\\gamma\\) — note that this is unrelated to chemical potential.\n\n\n\n\nIn principle the random forces are in time since the molecular collisions which cause them are correlated and have some definite duration.\nLet us assume that there is some correlation time \\(t_c\\) over which \\(\\langle f(t_1) f(t_2) \\rangle = g(t_1 - t_2)\\) decays rapidly as shown in the sketch:\n\n\n\n\n\n\nFigure 1: Sketch of \\(g(t1− t2)\\) against \\(|t1− t2|\\)\n\n\n\nThen as long as we consider timescales \\(\\gg t_c\\) we can safely replace \\(g(t_1 - t_2)\\) by a delta function. Thus we can approximate the noise by\n\\[\n\\langle f(t) \\rangle = 0\n\\]\n\\[\n\\langle f(t_1) f(t_2) \\rangle = \\Gamma \\delta(t_1 - t_2)\n\\]\n\n\n\n\nLet’s set \\(m = 1\\) for simplicity and solve the equation:\n\\[\n\\dot{v} + \\gamma v = f(t)\n\\]\nWe apply an integrating factor:\n\\[\n\\frac{d}{dt} \\left[ v e^{\\gamma t} \\right] = e^{\\gamma t} f(t)\n\\]\nIntegrating both sides:\n\\[\nv(t) = v_0 e^{-\\gamma t} + \\int_0^t e^{-\\gamma (t - t')} f(t')\\, dt'\n\\]\nTaking the average:\n\\[\n\\langle v(t) \\rangle = v_0 e^{-\\gamma t}\n\\]\nThus:\n\nAt short times: (\\(\\gamma t \\ll 1\\)): \\(\\langle v \\rangle \\approx v_0\\) ie. friction is negligible.\nAt long times: (\\(\\gamma t \\gg 1\\)): \\(\\langle v \\rangle \\to 0\\) ie. the system loses memory of the initial velocity.\n\n\n\n\n\nWe now compute:\n\\[\n\\langle v(t)^2 \\rangle = v_0^2 e^{-2\\gamma t} + \\Gamma \\int_0^t e^{-2\\gamma (t - t')} dt' = v_0^2 e^{-2\\gamma t} + \\frac{\\Gamma}{2\\gamma} \\left(1 - e^{-2\\gamma t} \\right)\n\\]\nImplying that at\n\nShort times: \\(\\langle v^2 \\rangle \\approx v_0^2\\)\nLong times: \\(\\langle v^2 \\rangle \\to \\Gamma / (2\\gamma)\\)\n\nAt equilibrium, the equipartition theorem gives:\n\\[\n\\frac{1}{2} m \\langle v^2 \\rangle = \\frac{1}{2} k_B T\n\\]\nUsing this to identify \\(\\Gamma\\):\n\\[\n\\Gamma = 2 \\gamma k_B T\n\\]\nThis important result relates the noise strength to the damping and temperature — they have the same microscopic origin (molecular collisions).\n\n\n\n\nWe now integrate \\(v(t)\\) again to get position \\(x(t)\\) (with \\(m = 1\\)):\nUsing the result above and substituting \\(\\Gamma = 2\\gamma k_B T\\), we find:\n\\[\n\\langle [x(t) - x_0]^2 \\rangle = \\frac{(v_0^2 - k_B T)}{\\gamma^2} (1 - e^{-\\gamma t})^2 + \\frac{2 k_B T}{\\gamma} \\left[ t - \\frac{1 - e^{-\\gamma t}}{\\gamma} \\right]\n\\]\nLimiting behaviors:\n\nShort times: (\\(\\gamma t \\ll 1\\)):\n\\[\n\\langle [x(t) - x_0]^2 \\rangle \\approx v_0^2 t^2\n\\]\n(correspinding to ballistic motion)\nLong time (\\(\\gamma t \\gg 1\\)):\n\\[\n\\langle [x(t) - x_0]^2 \\rangle \\approx \\frac{2 k_B T}{\\gamma} t\n\\]\n(corresponding to diffusive motion)\n\nThe effective diffusion constant is:\n\\[\nD = \\frac{k_B T}{\\gamma}\n\\]\nThis is the Einstein relation, connecting the rate of diffusion to temperature and damping. It is useful as it allows an explicit expression for the diffusion constant if one knows \\(\\gamma\\). A famous example is a sphere: the equation for fluid flow past a moving sphere may be solved and yields \\(\\gamma=6\\pi\\eta a\\) where \\(a\\) is the radius of the sphere and here \\(\\eta\\) is the fluid viscosity. This gives\n\\[\nD=\\frac{6\\pi\\eta a}{kT}\n\\] which is the Stokes-Einstein formula for the diffusion constant of a colloidal particle.\n\n\n\n\nNow consider a charged particle with charge \\(q\\) under an external electric field \\(E\\). The Langevin equation becomes:\n\\[\nm \\dot{v} = -\\gamma v + qE\n\\]\nAt long times, the particle reaches a steady drift velocity:\n\\[\n\\langle v \\rangle = \\frac{qE}{\\gamma} = \\frac{qED}{k_B T}\n\\]\nDefining the mobility \\(\\mu\\) by \\(\\langle v \\rangle = \\mu qE\\), we get the Nernst-Einstein relation:\n\\[\n\\mu = \\frac{D}{k_B T}\n\\]\nThis relation connects the response of a system to an external perturbation (mobility) with its internal fluctuations (diffusivity).",
    "crumbs": [
      "Chapters",
      "11. Brownian and Langevin dynamics"
    ]
  },
  {
    "objectID": "Brownian-and-Langevin-dynamics.html#the-random-walk-and-the-langevin-equation",
    "href": "Brownian-and-Langevin-dynamics.html#the-random-walk-and-the-langevin-equation",
    "title": "The Langevin Approach",
    "section": "",
    "text": "The concept of a random walk and its continuum limit — diffusion — introduced in the previous chapter, expresses the time evolution of the probability distribution \\(p(x, t)\\) for a particle’s position \\(x\\) is described by the diffusion equation:\n\\[\n\\frac{\\partial p}{\\partial t} = D \\frac{\\partial^2 p}{\\partial x^2},\n\\]\nwhich is a standard example of a so called Fokker-Planck equation, which is second-order in space and first-order in time.\nIn contrast, the Langevin equation provides a stochastic differential equation for the particle’s trajectory \\(x(t)\\). To understand it, consider the motion over a small time increment \\(\\Delta t\\):\n\\[\nx(t + \\Delta t) = x(t) + \\Delta x(t)\n\\]\nHere, \\(\\Delta x(t)\\) is a random displacement. If the lattice spacing is \\(a\\), we define the step statistics as:\n\\[\n\\Delta x(t) =\n\\begin{cases}\n+a & \\text{with probability } \\nu \\Delta t \\\\\n-a & \\text{with probability } \\nu \\Delta t \\\\\n0 & \\text{with probability } 1 - 2\\nu \\Delta t\n\\end{cases}\n\\]\nThis defines a discrete-time, discrete-space random walk. The average and variance of the step are:\n\nMean: \\(\\langle \\Delta x \\rangle = 0\\)\nVariance: \\(\\langle (\\Delta x)^2 \\rangle = 2 a^2 \\nu \\Delta t = 2D \\Delta t\\)\n\nThe steps \\(\\Delta x(t)\\) are uncorrelated across time.\nTo take the continuum limit, we let both \\(a \\to 0\\) and \\(\\Delta t \\to 0\\) in such a way that:\n\\[\na \\propto \\sqrt{\\Delta t}\n\\]\nIn this limit, we obtain the Langevin equation:\n\\[\n\\dot{x}(t) = \\eta(t)\n\\]\nwhere \\(\\eta(t)\\) is a stochastic force (noise) satisfying:\n\\[\n\\langle \\eta(t) \\rangle = 0\n\\]\n\\[\n\\langle \\eta(t) \\eta(t') \\rangle = \\Gamma \\delta(t - t')\n\\]\nThis \\(\\eta(t)\\) is known as white noise — it has zero mean and is uncorrelated at different times.\nThe Langevin equation tells us that the velocity \\(\\dot{x}(t)\\) is purely driven by noise. We can formally integrate it:\n\\[\nx(t) - x_0 = \\int_0^t \\eta(t')\\, dt'\n\\]\nTaking ensemble averages:\n\nMean displacement: \\[\n\\langle x(t) - x_0 \\rangle = 0\n\\]\nMean square displacement: \\[\n\\langle [x(t) - x_0]^2 \\rangle = \\int_0^t \\int_0^t \\langle \\eta(t') \\eta(t'') \\rangle\\, dt'\\, dt'' = \\Gamma \\int_0^t dt' = \\Gamma t\n\\]\n\nComparing this with the diffusion equation result, we identify:\n\\[\n\\Gamma = 2D\n\\]\nHence, the Langevin description yields the same physical behavior — not just the mean-square displacement but also the full probability distribution \\(p(x, t)\\) — as the diffusion (Fokker-Planck) equation. This equivalence arises from the fact that the integral of many small, independent random steps leads to a Gaussian distribution, in agreement with the solution of the diffusion equation.\nFor more details, see: Stochastic Processes in Physics and Chemistry by N.G. van Kampen (North Holland, 1981).",
    "crumbs": [
      "Chapters",
      "11. Brownian and Langevin dynamics"
    ]
  },
  {
    "objectID": "Brownian-and-Langevin-dynamics.html#brownian-motion",
    "href": "Brownian-and-Langevin-dynamics.html#brownian-motion",
    "title": "The Langevin Approach",
    "section": "",
    "text": "Let us now examine Brownian motion, originally observed as the erratic motion of colloidal particles suspended in a fluid. These particles undergo constant collisions with surrounding (smaller) fluid molecules, which results in seemingly random movement.\nFrom a coarse-grained perspective — where we do not track each individual collision — this appears as motion under random forces. This statistical treatment introduces irreversibility at the macroscopic level, even though the underlying molecular dynamics are reversible.\nThe Langevin equation provides a way to model this behavior. For a particle of mass \\(m\\) in one dimension, Langevin proposed the equation:\n\\[\nm \\ddot{x} = -\\gamma \\dot{x} + f(t)\n\\]\nHere:\n\n\\(-\\gamma \\dot{x}\\) is a frictional damping force, where \\(\\gamma\\) is the damping coefficient.\n\\(f(t)\\) is a random force due to molecular collisions.\n\n\nOften, the mobility is defined as \\(\\mu = 1/\\gamma\\) — note that this is unrelated to chemical potential.\n\n\n\n\nIn principle the random forces are in time since the molecular collisions which cause them are correlated and have some definite duration.\nLet us assume that there is some correlation time \\(t_c\\) over which \\(\\langle f(t_1) f(t_2) \\rangle = g(t_1 - t_2)\\) decays rapidly as shown in the sketch:\n\n\n\n\n\n\nFigure 1: Sketch of \\(g(t1− t2)\\) against \\(|t1− t2|\\)\n\n\n\nThen as long as we consider timescales \\(\\gg t_c\\) we can safely replace \\(g(t_1 - t_2)\\) by a delta function. Thus we can approximate the noise by\n\\[\n\\langle f(t) \\rangle = 0\n\\]\n\\[\n\\langle f(t_1) f(t_2) \\rangle = \\Gamma \\delta(t_1 - t_2)\n\\]\n\n\n\n\nLet’s set \\(m = 1\\) for simplicity and solve the equation:\n\\[\n\\dot{v} + \\gamma v = f(t)\n\\]\nWe apply an integrating factor:\n\\[\n\\frac{d}{dt} \\left[ v e^{\\gamma t} \\right] = e^{\\gamma t} f(t)\n\\]\nIntegrating both sides:\n\\[\nv(t) = v_0 e^{-\\gamma t} + \\int_0^t e^{-\\gamma (t - t')} f(t')\\, dt'\n\\]\nTaking the average:\n\\[\n\\langle v(t) \\rangle = v_0 e^{-\\gamma t}\n\\]\nThus:\n\nAt short times: (\\(\\gamma t \\ll 1\\)): \\(\\langle v \\rangle \\approx v_0\\) ie. friction is negligible.\nAt long times: (\\(\\gamma t \\gg 1\\)): \\(\\langle v \\rangle \\to 0\\) ie. the system loses memory of the initial velocity.\n\n\n\n\n\nWe now compute:\n\\[\n\\langle v(t)^2 \\rangle = v_0^2 e^{-2\\gamma t} + \\Gamma \\int_0^t e^{-2\\gamma (t - t')} dt' = v_0^2 e^{-2\\gamma t} + \\frac{\\Gamma}{2\\gamma} \\left(1 - e^{-2\\gamma t} \\right)\n\\]\nImplying that at\n\nShort times: \\(\\langle v^2 \\rangle \\approx v_0^2\\)\nLong times: \\(\\langle v^2 \\rangle \\to \\Gamma / (2\\gamma)\\)\n\nAt equilibrium, the equipartition theorem gives:\n\\[\n\\frac{1}{2} m \\langle v^2 \\rangle = \\frac{1}{2} k_B T\n\\]\nUsing this to identify \\(\\Gamma\\):\n\\[\n\\Gamma = 2 \\gamma k_B T\n\\]\nThis important result relates the noise strength to the damping and temperature — they have the same microscopic origin (molecular collisions).\n\n\n\n\nWe now integrate \\(v(t)\\) again to get position \\(x(t)\\) (with \\(m = 1\\)):\nUsing the result above and substituting \\(\\Gamma = 2\\gamma k_B T\\), we find:\n\\[\n\\langle [x(t) - x_0]^2 \\rangle = \\frac{(v_0^2 - k_B T)}{\\gamma^2} (1 - e^{-\\gamma t})^2 + \\frac{2 k_B T}{\\gamma} \\left[ t - \\frac{1 - e^{-\\gamma t}}{\\gamma} \\right]\n\\]\nLimiting behaviors:\n\nShort times: (\\(\\gamma t \\ll 1\\)):\n\\[\n\\langle [x(t) - x_0]^2 \\rangle \\approx v_0^2 t^2\n\\]\n(correspinding to ballistic motion)\nLong time (\\(\\gamma t \\gg 1\\)):\n\\[\n\\langle [x(t) - x_0]^2 \\rangle \\approx \\frac{2 k_B T}{\\gamma} t\n\\]\n(corresponding to diffusive motion)\n\nThe effective diffusion constant is:\n\\[\nD = \\frac{k_B T}{\\gamma}\n\\]\nThis is the Einstein relation, connecting the rate of diffusion to temperature and damping. It is useful as it allows an explicit expression for the diffusion constant if one knows \\(\\gamma\\). A famous example is a sphere: the equation for fluid flow past a moving sphere may be solved and yields \\(\\gamma=6\\pi\\eta a\\) where \\(a\\) is the radius of the sphere and here \\(\\eta\\) is the fluid viscosity. This gives\n\\[\nD=\\frac{6\\pi\\eta a}{kT}\n\\] which is the Stokes-Einstein formula for the diffusion constant of a colloidal particle.\n\n\n\n\nNow consider a charged particle with charge \\(q\\) under an external electric field \\(E\\). The Langevin equation becomes:\n\\[\nm \\dot{v} = -\\gamma v + qE\n\\]\nAt long times, the particle reaches a steady drift velocity:\n\\[\n\\langle v \\rangle = \\frac{qE}{\\gamma} = \\frac{qED}{k_B T}\n\\]\nDefining the mobility \\(\\mu\\) by \\(\\langle v \\rangle = \\mu qE\\), we get the Nernst-Einstein relation:\n\\[\n\\mu = \\frac{D}{k_B T}\n\\]\nThis relation connects the response of a system to an external perturbation (mobility) with its internal fluctuations (diffusivity).",
    "crumbs": [
      "Chapters",
      "11. Brownian and Langevin dynamics"
    ]
  },
  {
    "objectID": "problems.html",
    "href": "problems.html",
    "title": "Unifying theoretical concepts: Problems",
    "section": "",
    "text": "Unifying theoretical concepts: Problems\nAlthough you should try all of these questions, some of them are deliberately quite challenging. If you don’t get very far with some, don’t worry. We’ll be going over them in problems classes, so you can just regard them as worked examples.\n\nExistence of a phase transition in \\(d=2\\).\n(Straightforward) In lectures it was argued that no long ranged order occurs at finite-temperatures in a one dimensional system because of the presence of domain walls. Were macroscopic domain walls to exist in two dimensions at finite temperature, they would similarly destroy long ranged order and prevent a phase transition. By calculating the free energy of a 2D domain wall for an Ising lattice, show that domain walls do not in fact exist for sufficiently low \\(T\\).\n(Hint: Model the domain wall as a non-reversing \\(N\\)-step random walk on the lattice and find an expression for its energy and -from the number of random walk configurations- its entropy.)\n\n\n\nCorrelation Length\n(Challenging) For a 1D Ising model, show that the correlation between the spins at sites \\(i\\) and \\(j\\), is\n\\[\\langle s_i s_j\\rangle =\\sum_m p_m(-1)^m\\] where \\(m\\) is the number of domain walls between \\(i\\) and \\(j\\) and \\(p_m\\) is the probability of finding \\(m\\) domain walls between them.\nHence show that when \\(R_{ij}=|i-j|a\\) is large (with \\(a\\) the lattice spacing) and the temperature is small, that\n\\[\\langle s_i s_j\\rangle =\\exp(-R_{ij}/\\xi)\\] with \\(\\xi=a/2p\\) and \\(p\\) the probability of finding a domain wall on a bond.\nHint: In the second part note that \\(p_m\\) is given by a binomial distribution because there is a probability \\(p\\) of each bond containing a domain wall and \\((1-p)\\) that it doesn’t. What special type of distribution does \\(p_m\\) tend to when \\(p\\) is small (as occurs at low \\(T\\))?\n\n\n\nA model fluid\n(Straightforward) The van der Waals (vdW) equation of state (recall PH10002) is essentially a mean field theory for fluids. It relates the pressure and the volume of a fluid to the temperature:\n\\[\\left(P+\\frac{a}{V^2}\\right)(V-b)=N_Ak_BT\\] where \\(a\\) and \\(b\\) are constants and \\(N_A\\) is Avogadro’s number.\nThe critical point of a fluid corresponds to the point at which the isothermal compressibility diverges, that is\n\\[\\left(\\frac{\\partial P}{\\partial V}\\right)_T=0\\] Additionally, one finds that isotherms of \\(P\\) versus \\(V\\) exhibit a point of inflection at the critical point, that is\n\\[\\left(\\frac{\\partial^2 P}{\\partial V^2}\\right)_T=0\\]\n\nUse these two requirements to show that the critical point of the vdW fluid is located at\n\\[V_c=3b, ~~~ P_c=\\frac{a}{27b^2},~~~ N_AK_BT_c=\\frac{8a}{27b}\\]\nHence show that when written in terms of reduced variables\n\\[p=\\frac{P}{P_c}, ~~~~ v=\\frac{V}{V_c} ~~~~ t=\\frac{T}{T_c}\\]\nthe equation takes the form\n\\[\\left(p+\\frac{3}{v^2}\\right)(v-\\frac{1}{3})=\\frac{8t}{3}\\]\nUse a graph-plotting program such as “Excel” to plot a selection of isotherms close to the critical temperature (you will need to choose suitable units for your axes). Plot also the gradient and second derivative of P vs V on the critical isotherm and confirm numerically that it exhibits a point of inflection at the critical pressure and temperature.\nObtain the value of the critical exponent \\(\\gamma\\) of the vdW model and confirm that it takes a mean-field value.\n\n\n\n\nMean field theory of the Ising model heat capacity\n(Straightforward) Using results derived in lectures, obtain an expression for the mean energy \\(\\langle E\\rangle\\) of the Ising model in zero field, within the simplest mean field approximation \\(\\langle\n  s_is_j\\rangle=\\langle s_i\\rangle\\langle s_j\\rangle=m^2\\). Hence show that for \\(H=0\\) the heat capacity \\(\\partial \\langle\n  E\\rangle/\\partial T\\) has the behaviour\n\\[\\begin{aligned}\nC_H=& 0 ~~~~ T&gt;T_c\\\\\nC_H=& 3Nk_B/2 ~~~~ T\\le T_c\n\\end{aligned}\\]\n\n\n\nMagnetisation and fluctuations\n(Slightly tricky) A system of spins on a lattice, has, in the absence of an applied field, a Hamiltonian \\({\\cal H}\\). In the presence of a field \\(h\\) the Hamiltonian becomes \\[\\tilde {\\cal H}={\\cal H}-hM\\] where \\(M\\) is the total magnetisation and \\(h\\) is the magnetic field. By considering the partition function \\(Z(T,h)\\) and its relationship to the free energy \\(F\\) show that in general\n\\[\\langle M \\rangle=-\\left(\\frac{\\partial F}{\\partial h}\\right)_T\\]\nShow also that the variance of the magnetisation fluctuations is\n\\[\\langle M^2\\rangle-\\langle M\\rangle^2=-k_BT\\left(\\frac{\\partial^2 F}{\\partial h^2}\\right)_T\\]\n(Hint: This is an important standard derivation found in many text books on Statistical Mechanics. You will need to differentiate \\(F\\) (twice) and use the product and chain rules.)\n\n\n\nSpin-1 Ising model\n(Straightforward) A set of spins on a lattice of coordination number \\(q\\) can take values \\((-1,0,1)\\), as opposed to just \\((-1,1)\\) as in the spin-1/2 Ising model. The Hamiltonian is\n\\[{\\cal H}=-J\\sum_{&lt;ij&gt;}s_is_j + h\\sum_i s_i\\]\nFind the partition function and hence show that in the mean field approximation, the magnetisation per site obeys\n\\[m=\\frac{2\\sinh[\\beta(Jqm+h)]}{2\\cosh[\\beta(Jqm+h)]+1}\\]\nand find the critical temperature \\(T_c\\) at which the net magnetisation vanishes.\n\n\n\nTransfer Matrix.\n(Straightforward strategy but some lengthy algebra required)\nVerify the calculation of the free energy of the 1D periodic chain Ising model in a field outlined in lectures using the Transfer Matrix method.\nUse your results to show that the spontaneous magnetisation is:\n\\[m=\\frac{\\sinh \\beta H}{\\sqrt{\\sinh^2\\beta H+\\exp{-4\\beta J}}}\\] Comment on the value of \\(m\\) in zero field.\n(Hint: Follow the prescription given in lectures. Depending on your approach you may need to use the trigonometrical identities \\(\\cosh^2x-\\sinh^2x=1\\), \\(\\cosh(2x)=2\\cosh^2x-1\\).)\n\n\n\nLattice gas model (Straightforward). Check the claim, made in lectures that the “Hamiltonian” of the Lattice Gas model in the grand canonical ensemble\n\\[{\\cal H}_{LG}=-\\epsilon\\sum_{&lt;i,j&gt;}c_ic_j -\\mu\\sum_ic_i\\]\nis transformed to that of the Ising model by means of the change of variable\n\\[s_i=2c_i-1;~~~~ J=\\frac{\\epsilon}{4}~~~~\nh=\\frac{\\epsilon q+2\\mu}{4}\\]\n(Hint: Note that when doing sums over bonds \\(\\sum_{\\langle\n    i,j\\rangle}\\) for a lattice of coordination \\(q\\) there are \\(q/2\\) bonds per site since each bond is shared between two sites.)\n\n\n\nLandau theory\nCheck and complete the Landau theory calculations, given in lectures, for the critical exponents \\(\\gamma=1\\) and \\(\\alpha=0\\) of the Ising model. For the latter, you should first prove the result\n\\[C_H =-T\\frac{\\partial^2 F}{\\partial T^2}\\] starting from the classical theormodynamics expression for changes in the free energy of a magnet \\(dF=-SdT-MdH\\).\n(Hint: If you get stuck with the proof see standard thermodynamics text books. To get the susceptibility exponent in Landau theory add a term \\(-Hm\\) to the Hamiltonian.)\n\n\n\nScaling laws\n(Straightforward.)Using the generalised homogeneous form for the free energy given in lectures, take appropriate derivatives to find the relationships to the critical exponents:\n\\[\\beta=\\frac{1-b}{a}; ~~ \\gamma=\\frac{2b-1}{a};~~ \\delta= \\frac{b}{1-b}; ~~~ \\alpha=2-\\frac{1}{a}.\\]\nHence derive the scaling laws among the critical exponents:\n\\[\\begin{aligned}\n\\alpha+\\beta(\\delta+1)=2 \\\\\n\\alpha+2\\beta+\\gamma=2\\\\\n%\\gamma=\\beta(\\delta-1)\n\\end{aligned}\\]\n(Hint: For the heat capacity exponent \\(\\alpha\\) use the result from problem 9: \\(C_H=-T\\left(\\frac{\\partial^2F}{\\partial T^2}\\right)_{h=0}\\))\n\n\n\nRenormalization Group transformation for the 1D Ising model\n(Challenging.) Consider a 1D Ising model of \\(N\\) spins in zero field given by the Hamiltonian\n\\[{\\cal H}_I/k_BT=-K\\sum_{&lt;ij&gt;}s_is_j -\\sum_iC\\] where a background term is included because even if set zero initially, it will be generated by an RG transformation.\n\nA renormalisation is to be implemented with a scale factor \\(b=2\\). By partially performing the sum in the partition function over the spins on the even numbered lattice sites, show that the partially summed partition function can be written\n\\[Z=\\sum_{s_1,s_3,s_5...}\\prod_{i=2,4,6...} [\\exp\n[K(s_{i-1}+s_{i+1})+2C] + \\exp[-K(s_{i-1}+s_{i+1})+2C]\\]\nNext, relabel the remaining (odd numbered) spins so that they are numbered consecutively eg by an index \\(j\\) (this is a matter of convenience only). Then cast this partially summed partition function in a form that makes it look the same as that for an Ising model with \\(N/2\\) spins. i.e. require that \\(Z^\\prime\\) has the form\n\\[Z=\\sum_{\\{s\\}}\\prod_{j=1}^{N/2}\\exp[K^\\prime s_js_{j+1}+C^\\prime]\\:,\\] for all \\(s_j,s_{j+1}=\\pm 1\\).\nHence show that the effective coupling \\(K^\\prime\\), and background constant \\(C^\\prime\\) of the renormalised system are related to those of the underlying Hamiltonian by\n\\[\\begin{aligned}\n\\exp(K^\\prime+C^\\prime) &=& \\exp(2C)[\\exp(2K)+\\exp(-2K)] \\\\\n\\exp(-K^\\prime+C^\\prime) &=& 2\\exp(2C)\n\\end{aligned}\\]\nUse these results to show that the effective coupling flows under the renormalization according to:\n\\[K^\\prime = (1/2)\\ln (\\cosh 2K)\\]\nDoes this flow drive the effective coupling to the low or high temperature fixed point?\nFinally show that the partition function transforms under the RG as\n\\[Z(K,N)=2^{N/2}\\exp(NK^\\prime/2)Z(K^\\prime,N/2)\\]\n\nNote. The above is a hard question, which we’ll go over this in detail in a problems class. So if you don’t make much progress, don’t worry, just treat it as a worked example.\n\n\n\nRG flow of the free energy\n(Straightforward) An alternative RG equation for the effective coupling in the 1D Ising model is\n\\[K = (1/2)\\cosh^{-1}(\\exp 2K^\\prime)\\] which is the inverse of the transformation found in the previous question. This transformation thus drives the system from small effective coupling (high temperature) to high effective coupling (low temperature).\nUnder the transformation, the free energy density transforms like\n\\[\\beta f(K)=(1/2)\\beta f(K^\\prime)-(1/2)\\ln 2-K^\\prime/2\\:.\\]\n\nUse these findings to iteratively calculate the free energy density of the Ising model at low temperatures, starting from the high temperature limit.\nHint: Start with a very low coupling eg. \\(K^\\prime=0.01\\), and show that because interactions between spins are negligible, \\(\\beta f(K^\\prime)\\approx\n-\\ln 2\\). Then iterate the RG equations above \\(8\\) or so times to generate a sequence of \\(K\\) and \\(\\beta f(K)\\) values.\nCompare your results for each iteration with the exact results for the free energy density of the 1D Ising model obtained in lectures.\n\n\n\n\nColloidal diffusion\n\nA large colloidal particle of mass \\(M\\) moves in a fluid under the influence of a random force \\(F(t)\\) and a coefficient of Stokes friction drag \\(\\gamma\\), both per unit mass. If the solution of the corresponding Langevin equation for the velocity of the colloidal particle is given by\n\\[\nu = u_0 e^{-\\gamma t} + e^{-\\gamma t} \\int_0^t dt' \\, e^{\\gamma t'} F(t'),\n\\]\nwhere \\(u_0\\) is the velocity at \\(t = 0\\), show that for long times the velocity of the particle satisfies the relation\n\\[\n\\langle u^2 \\rangle = \\frac{kT}{M} + \\left( u_0^2 - \\frac{kT}{M} \\right) e^{-2\\gamma t},\n\\]\nwhere \\(k\\) is the Boltzmann constant and \\(T\\) is the absolute temperature.\nState clearly any assumptions that you make.\n\n\nEinstein’s expression for the diffusion coefficient\n\nIn 1905, Einstein showed that the friction coefficient \\(\\gamma\\) (per unit mass) of a colloidal particle must be related to the diffusion coefficient \\(D\\) of the particle by\n\\[\nD = \\frac{kT}{\\gamma}.\n\\]\nIf a marked particle covers a distance \\(X\\) in a given time \\(t\\) (assuming a one-dimensional random walk), the diffusion coefficient is defined to be\n\\[\nD = \\lim_{t \\to \\infty} \\frac{1}{2t} \\langle \\{ X(t) - X(0) \\}^2 \\rangle,\n\\]\nwhere the average \\(\\langle \\cdot \\rangle\\) is taken over an ensemble in thermal equilibrium.\nShow that the Einstein relation may be written as\n\\[\n\\gamma = \\frac{1}{\\mu} = \\frac{D}{kT} = \\frac{1}{kT} \\int_0^\\infty \\langle u(t_0) u(t_0 + t) \\rangle \\, dt,\n\\]\nwhere \\(\\mu\\) is known as the mobility of the particle and \\(t_0\\) is any arbitrarily chosen time.\n\n\nLife in one dimension\n\nA particle lives on the sites of a one-dimensional lattice. At any instant it has probability \\(\\alpha\\) per unit time that it will hop to the site on its right and probability \\(\\alpha\\) per unit time of hopping to the site on its left.\nWrite down the master equation for the set of probabilities \\(p_n(t)\\) of finding the particle at the \\(n^{\\text{th}}\\) site, where \\(-\\infty &lt; n &lt; \\infty\\).\nSolve the master equation for the \\(p_n\\), subject to the initial condition that the particle was at the site \\(n = 0\\) at time \\(t = 0\\). Hence obtain the mean position \\(\\langle n \\rangle\\) and root mean square deviation from the mean, both as functions of time.\nHint: The second part of the question is most easily done by introducing the generating function\n\\[\nF(z, t) = \\sum_{n=-\\infty}^{\\infty} p_n(t) z^n.\n\\]\n\n\nMaster equation\n\nA system of \\(N\\) atoms, each having two energy levels \\(E = \\pm \\epsilon\\), is brought into contact with a heat bath at temperature \\(T\\). The atoms do not interact with each other, but each atom interacts with the heat bath to have a probability \\(\\lambda_{-\\to+}(T)\\) per unit time of transition from lower to higher level, and a probability \\(\\lambda_{+\\to-}(T)\\) per unit time of the reverse transition.\nIf at any time \\(t\\) there are \\(n_+(t)\\) atoms at the higher level and \\(n_-(t)\\) at the lower level, then \\(n(t) = n_-(t) - n_+(t)\\) is a convenient measure of the non-equilibrium state.\nObtain the master equation for \\(n(t)\\) and hence the relaxation time \\(\\tau\\) which characterizes the exponential approach of the system to equilibrium.\n\n\nDetailed balance\n\n(a) Starting from the principle of detailed balance for an isolated system, show that for two groups of states within it, \\(A\\) and \\(B\\), the overall rate of transitions from group \\(A\\) to group \\(B\\) is balanced, in equilibrium, by those from \\(B\\) to \\(A\\):\n\\[\n\\lambda_{A \\to B} p^{\\text{eq}}_A = \\lambda_{B \\to A} p^{\\text{eq}}_B\n\\]\n(b) Deduce that the principle applies to microstates in the canonical ensemble, and hence that the jump rates between states of a subsystem (of fixed number of particles) connected to a heat bath must obey\n\\[\n\\frac{\\lambda_{i \\to j}}{\\lambda_{j \\to i}} = e^{-(E_j - E_i)/kT}.\n\\]\n\n\nJump processes\n\nAn isolated system can occupy three possible states of the same energy. The kinetics are such that it can jump from state 1 to 2 and 2 to 3 but not directly from 1 to 3. Per unit time, there is a probability \\(\\lambda_0\\) that the system makes a jump, from the state it is in, into (each of) the other state(s) it can reach.\n(a) Show that the occupancy probabilities \\(p = (p_1, p_2, p_3)\\) of the three states obey the master equation\n\\[\n\\dot{p} = M \\cdot p\n\\]\nwhere the transition matrix is\n\\[\nM = \\lambda_0 \\begin{bmatrix}\n-1 & 1 & 0 \\\\\n1 & -2 & 1 \\\\\n0 & 1 & -1\n\\end{bmatrix}\n\\]\n(b) Confirm that an equilibrium state is \\(p = (1, 1, 1)/3\\).\n(c) Prove this equilibrium state is unique.\nHint: For part (c), consider the eigenvalues of \\(M\\).",
    "crumbs": [
      "Problems",
      "Theoretical techniques: problems"
    ]
  },
  {
    "objectID": "literature.html",
    "href": "literature.html",
    "title": "Literature",
    "section": "",
    "text": "Literature\nOne motivation for supplying you with detailed notes for this course is the absence of a wholly ideal text book. However, it should be stressed that while these notes approach (in places) the detail of a book, the notes are not fully comprehensive and should be regarded as the ‘bare bones’ of the course, to be fleshed out via your own reading and supplementary note taking. To this end perhaps the most appropriate textbooks are:\nA good book at the right level for the phase transitions and critical phenomena part of the course is\n\nJ.M. Yeomans: Statistical Mechanics of Phase Transitions\n\nA good book covering all aspects of this part of the course including non-equilibrium systems is\n\nD. Chandler: Introduction to Modern Statistical Mechanics\n\nYou might also wish to dip into the introductory chapters of the following more advanced texts\n\nN Goldenfeld: Lectures on Phase Transitions and the Renormalization Group\nJ.J. Binney, N.J. Dowrick, A.J.Fisher and M.E.J. Newman: The Theory of Critical Phenomena\n\nFor revision on thermodynamics and statistical mechanics\n\nF. Mandl: Statistical Physics.\n\nFor Stochastic dynamics\n\nN.G. van Kampen: Stochastic processess in Physics and Chemistry",
    "crumbs": [
      "Course texts"
    ]
  }
]