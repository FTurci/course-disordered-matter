[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to the Complex Disordered Matter course!",
    "section": "",
    "text": "Welcome to the Complex Disordered Matter course!",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Welcome to the Complex Disordered Matter course!",
    "section": "Overview",
    "text": "Overview\nThis course introduces your to the theoretical, computational and experimental aspects of the physics of complex disordered matter.\n\nComplex disordered matter is the study of wide range of systems like polymers, colloids, glasses, gels, and emulsions, which lack long-range order but exhibit intricate behaviour. Colloids, suspensions of microscopic particles in a fluid, are useful for studying disordered structures due to their observable dynamics. Similarly, polymer systems can form amorphous solids or glasses when densely packed or cooled, showing solid-like rigidity despite their disordered structure. These materials often undergo phase transitions, such as demixing and crystallisation, and near these transitions, they can display critical phenomena with extensive fluctuations and correlations.\nThese various systems are examples of soft matter systems. In such systems, the interplay between disorder, softness, and phase behavior leads to rich physical phenomena, particularly near critical points where even small changes in external conditions can trigger large-scale reorganisations and universal behaviour. Glasses, for instance, exhibit slow relaxation and memory effects, while colloidal systems may crystallize, phase separate, or become jammed depending on particle interactions and concentration. Understanding such behaviors involves studying how microscopic interactions and thermal fluctuations influence macroscopic properties, especially in non-equilibrium conditions. Through techniques like scattering, microscopy, rheology, and simulation, one can explore how disordered soft materials respond to stress, age, or undergo transitions—insights that are vital for applications in materials design, biotechnology, and beyond.\nThis course is organized into three interconnected parts, each offering a distinct perspective on the study of complex disordered matter.\n\nPart 1: Unifying concepts (Nigel Wilding) introduces the theoretical framework for rationalising complex disordered matter which is grounded in statistical mechanics and thermodynamics. We emphasize the theory of phase transitions, thermal fluctuations, critical phenomena, and stochastic dynamics—providing the essential theoretical tools needed to describe and predict the behavior of soft and disordered systems.\n\nPart 2: Complex disordered matter (Francesco Turci) explores the phenomenology of key examples of complex disordered soft matter systems, including colloids, polymers, liquid crystals, glasses, gels, and active matter. These systems will be analyzed using the theoretical concepts introduced in Part 1, highlighting how disorder, interactions, and fluctuations shape their macroscopic behavior.\n\nPart 3: Experimental techniques (Adrian Barnes) focuses on the methods of microscopy, and scattering via x-rays, neutrons and light that are used to study complex disordered matter, offering insight into how their properties are measured and understood in real-world contexts.\n\nIn addition to theory and experiment, computer simulation plays a central role in soft matter research. This course includes a substantial coursework component consisting of a computational project. This exercise will allow you to apply state-of-the-art simulation techniques to investigate the complex behavior of disordered systems, bridging theory and observation through hands-on exploration.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#delivery-and-format",
    "href": "index.html#delivery-and-format",
    "title": "Welcome to the Complex Disordered Matter course!",
    "section": "Delivery and format",
    "text": "Delivery and format\n\nDetailed e-notes (accessible via Blackboard) can be viewed on a variety of devices. Pdf is also available.\nWe will give ‘traditional’ lectures (Tuesdays, Wednesdays, Fridays) in which we use slides to summarise and explain the lecture content. Questions are welcome (within reason…)\nTry to read ahead in the notes, then come to lectures, listen to the explanations and then reread the notes.\nRewriting the notes or slides to express your own thoughts and understanding, or annotating a pdf copy can help wire the material into your own way of thinking.\nThere are problem classes (Thursdays) where you can try problem sheets and seek help. Lecturers may go over some problems with the class.\nThe navigation bar on the left will allow you to access the lecture notes and problem sets.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#intended-learning-outcomes",
    "href": "index.html#intended-learning-outcomes",
    "title": "Welcome to the Complex Disordered Matter course!",
    "section": "Intended learning outcomes",
    "text": "Intended learning outcomes\nThe course will\n\nIntroduce you to the qualitative features of a range of complex and disordered systems and the experimental techniques used to study them.\nIntroduce you to a range of model systems and theoretical techniques used to elucidate the physics of complex disordered matter.\nProvide you with elementary computational tools to model complex disordered systems numerically and predict their properties.\nAllow you to apply your physics background to understand a variety of systems of inter-disciplinary relevance.\nConnect with the most recent advances in the research on complex disordered matter.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#contact-details",
    "href": "index.html#contact-details",
    "title": "Welcome to the Complex Disordered Matter course!",
    "section": "Contact details",
    "text": "Contact details\nThe course will be taught by\n\nProf Nigel B. Wilding (unit director): nigel.wilding@bristol.ac.uk\nDr Francesco Turci: F.Turci@bristol.ac.uk\nDr Adrian Barnes: a.c.barnes@bristol.ac.uk",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#questions-and-comments",
    "href": "index.html#questions-and-comments",
    "title": "Welcome to the Complex Disordered Matter course!",
    "section": "Questions and comments",
    "text": "Questions and comments\nIf you have any questions about the course, please don’t hesitate to contact the relevant lecturer, either by email (see above) or in a problems class.\nFinally, this is a new course for 2025/26. If you find any errors or mistakes or something which isn’t clear, please let us know by email, or fill in this anonymous form:\n\n\n\n\n\n\nSubmit an error/mistake/query",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "reading.html",
    "href": "reading.html",
    "title": "Recommended texts and literature",
    "section": "",
    "text": "One motivation for supplying you with detailed notes for this course course is the absence of a single wholly ideal text book. However, it should be stressed that while these notes approach (in places) the detail of a book, the notes are not fully comprehensive and should be regarded as the ‘bare bones’ of the course, to be fleshed out via your own reading and supplementary note taking.\n\nRevision on thermodynamics and statistical mechanics\nSee your year two Thermal Physics notes. Also\n\nF. Mandl: Statistical Physics\n\n\n\nPhase transitions and critical phenomena\nA good book at the right level for the phase transitions and critical phenomena part of the course is\n\nJ.M. Yeomans: Statistical Mechanics of Phase Transitions\n\nA good book covering all aspects of this part of the course including non-equilibrium systems is\n\nD. Chandler: Introduction to Modern Statistical Mechanics\n\nYou might also wish to dip into the introductory chapters of the following more advanced texts\n\nN Goldenfeld: Lectures on Phase Transitions and the Renormalization Group\nJ.J. Binney, N.J. Dowrick, A.J.Fisher and M.E.J. Newman: The Theory of Critical Phenomena\n\n\n\nStochastic dynamics\n\nN.G. van Kampen: Stochastic processess in Physics and Chemistry\n\n\n\nSoft matter and glasses\nThe best overall text for part 2 of the course is:\n\nR.A.L Jones, Soft Condensed Matter.\n\nAdditionally, the following more specialised texts (which include information on experimental techniques) might be useful.\n\nColloids\n\nD.F.Evans, H.Wennerström: The Colloidal Domain - Where Physics, Chemistry, Biology, and Technology Meet\nR.J.Hunter: Introduction to Modern Colloid Science\nW.B.Russel, D.A.Saville, W.R.Schowalter: Colloidal Dispersions\nD.H.Everett: Basic Principles of Colloid Science\n\n\n\nPolymers and surfactants\n\nR.J. Young and P.A. Lovell: Introduction to polymers\nM. Doi: Introduction to polymer physics\nJ.Israelachvili, Intermolecular and Surface Forces\n\n\n\nGlasses\n\nJ. Zarzycki; Glasses and the vitreous state",
    "crumbs": [
      "Recommended texts"
    ]
  },
  {
    "objectID": "phase-transitions/introduction.html",
    "href": "phase-transitions/introduction.html",
    "title": "1  Introduction to phase behaviour and enhanced fluctuations",
    "section": "",
    "text": "A phase transition can be defined as a macroscopic rearrangment of the internal constituents of a system in response to a change in the thermodynamic conditions to which they are subject. A wide variety of physical systems undergo such transitions. Understanding the properties of phase transitions is fundamental to the study of soft and complex matter, as these systems often exhibit rich and subtle transformations between different states of organization. Whether in colloidal suspensions, polymer blends, liquid crystals, or biological materials, phase transitions underpin a wide range of physical behaviours, from self-assembly and pattern formation to critical phenomena and dynamical arrest. By analysing how macroscopic phases emerge from microscopic interactions and external conditions, one gains crucial insight into the principles that govern structure, stability, and functionality in these intricate systems. As such, an understanding of phase transitions not only enriches theoretical understanding but also informs practical applications across materials science, biophysics, and nanotechnology. For these reasons we will devote a large proportion of this course to the study of phase transitions.\nTwo classic examples of systems displaying phase transitions are the ferromagnet and fluid systems. For the magnet, a key observable is the magnetisation defined as the magnetic moment per spin, given by \\(m=M/N\\), with \\(N\\) the number of spins. \\(m\\) can be positive or negative, dependent on whether the spins are aligned ‘up’ or ‘down’. As the temperature of a ferromagnet is increased, its net magnetisation \\(|m|\\) is observed to decrease smoothly, until at a certain temperature known as the critical temperature, \\(T_c\\), it vanishes altogether (see left part of Figure 1.1). We define the magnetisation to be the order parameter of this phase transition.\nOne can also envisage applying a magnetic field \\(H\\) to the system which, depending on its sign (i.e. whether it is aligned (positive) or anti-aligned (negative) relative to the magnetisation axis), favours up or down spin states respectively, as shown schematically in Figure 1.1 (right part). Changing the sign of the magnetic field \\(H\\) for \\(T&lt;T_c\\) leads to a phase transition chacterised by a discontinuous jump in \\(m\\). We shall explore this behaviour in more detail in section 5.\n\n\n\n\n\n\nFigure 1.1: Phase diagram of a simple magnet (schematic). Left: magnetisation as a function of temperature for zero applied magnetic field, \\(H=0\\). Right: Applying a magnetic field that is aligned or antialigned with the direction of the magnetisation leads to a phase transition. The \\(H=0\\) axis at \\(T&lt;T_c\\) is the coexistence curve for which positive and negative magnetisations are equally likely.\n\n\n\nSimilarly, a change of state from liquid to gas can be induced in a fluid system (though not in an ideal gas) simply by raising the temperature. Typically the liquid-vapour transition is abrupt, reflecting the large number density difference between the states either side of the transition. However the abruptness of this transition can be reduced by applying pressure. At one particular pressure and temperature the discontinuity in the density difference between the two states vanishes and the two phases coalesce. These conditions of pressure and temperature serve to locate the critical point for the fluid. We define the density difference \\(\\rho_{liq}-\\rho_{vap}\\) to be the order parameter for the liquid-gas phase transition. We shall meet order parameters for other, more complex, systems in section 5,\n\n\n\n\n\n\nFigure 1.2: Phase diagram of a simple fluid (schematic)\n\n\n\nIn the vicinity of a critical point, a system displays a host of remarkable behaviors known as critical phenomena. Chief among these is the divergence of thermal response functions—such as specific heat, compressibility, or magnetic susceptibility—which signal an enhanced sensitivity to external perturbations. These singularities arise from the emergence of large-scale cooperative interactions among the system’s microscopic constituents, as measured by a diverging correlation length (see Chapter 2). One visually striking manifestation of this is critical opalescence, particularly observed in fluids like CO\\(_2\\). As carbon dioxide nears its critical temperature and pressure, the distinction between its liquid and gas phases vanishes, giving rise to huge fluctuations in density. These fluctuations scatter visible light, rendering the fluid milky or opalescent. This scattering effect directly reflects the long-range correlations developing within the fluid. The movie below illustrates the effect as the critical temperature of CO\\(_2\\) is approached from above. Note the appearence of a liquid-vapour interface (meniscus) as the system enters the two-phase region.\n\nThe recalcitrant problem posed by the critical region is how best to incorporate such collective effects within the framework of a rigorous mathematical theory that affords both physical insight and quantitative explanation of the observed phenomena. This matter has been (and still is!) the subject of intense theoretical activity.\nThe importance of the critical point stems largely from the fact that many of the phenomena observed in its vicinity are believed to be common to a whole range of apparently quite disparate physical systems. Systems such as liquid mixtures, superconductors, liquid crystals, ferromagnets, antiferromagnets and molecular crystals may display identical behaviour near criticality. This observation implies a profound underlying similarity among physical systems at criticality, regardless of many aspects of their distinctive microscopic nature. These ideas have found formal expression in the so-called ‘universality hypothesis’ which, since its inception in the 1970s, has enjoyed considerable success.\nIn the next few lectures, principal aspects of the contemporary theoretical viewpoint of phase transitions and critical phenomena will be reviewed. Mean field theories of phase transitions will be discussed and their inadequacies in the critical region will be exposed. The phenomenology of the critical region will we described including power laws, critical exponents and their relationship to scaling phenomena. These will be set within the context of the powerful renormalisation group technique. The notion of universality as a phenomenological hypothesis will be introduced and its implications for real and model systems will be explored. Finally, the utility of finite-size scaling methods for computer studies of critical phenomena will be discussed, culminating in the introduction of a specific technique suitable for exposing universality in model systems. Thereafter we will consider some foundational concepts in the dynamics of complex disordered matter. We shall look at the processes by which one phase transform into another and introduce differential equations that allow us to deal with the inherent stochasticity of thermal systems. The wider applicability of these unifying concepts to complex disordered systems such as colloids, polymers, liquid crystals and glasses will be covered in part 2 of the course.",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to phase behaviour</span>"
    ]
  },
  {
    "objectID": "phase-transitions/background.html",
    "href": "phase-transitions/background.html",
    "title": "2  Key concepts for phase transitions",
    "section": "",
    "text": "2.1 Observables and expectation values\nIn seeking to describe phase transition and critical phenomena, it is useful to have a quantitative measure of the difference between the phases: this is the role of the order parameter, \\(Q\\). In the case of the fluid, the order parameter is taken as the difference between the densities of the liquid and vapour phases. In the ferromagnet it is taken as the magnetisation. As its name suggest, the order parameter serves as a measure of the kind of orderliness that sets in when the temperature is cooled below a critical temperature.\nOur first task is to give some feeling for the principles which underlie the ordering process. Referring back to Section 1.2, the probability \\(p_a\\) that a physical system at temperature \\(T\\) will have a particular microscopic arrangement (alternatively referred to as a ‘configuration’ or ‘state’), labelled \\(a\\), of energy \\(E_a\\) is\n\\[\np_a=\\frac{1}{Z}e^{-E_a/k_BT}\n\\tag{2.1}\\]\nThe prefactor \\(Z^{-1}\\) is the partition function: since the system must always have some specific arrangement, the sum of the probabilities \\(p_a\\) must be unity, implying that\n\\[\nZ=\\sum_ae^{-E_a/k_BT}\n\\tag{2.2}\\] where the sum extends over all possible microscopic arrangements.\nThese equations assume that physical system evolves rapidly (on the timescale of typical observations) amongst all its allowed arrangements, sampling them with the probabilities Equation 2.1 the expectation value of any physical observable \\(O\\) will thus be given by averaging \\(O\\) over all the arrangements \\(a\\), weighting each contribution by the appropriate probability:\n\\[\\overline {O}=\\frac{1}{Z}\\sum_a O_a e^{-E_a/k_BT}\n\\tag{2.3}\\]\nSums like Equation 2.3 are not easily evaluated because the number of terms grows exponentially in the system size. Nevertheless, some important insights follow painlessly. Consider the case where the observable of interest is the order parameter, or more specifically the magnetisation of a ferromagnet.\n\\[\nQ=\\frac{1}{Z}\\sum_a Q_a e^{-E_a/k_BT}\n\\tag{2.4}\\]\nIt is clear from Equation 2.1 that at very low temperature the system will be overwhelmingly likely to be found in its minimum energy arrangements (ground states). For the ferromagnet, these are the fully ordered spin arrangements having magnetisation \\(+1\\), or \\(-1\\).\nNow consider the high temperature limit. The enhanced weight that the fully ordered arrangement carries in the sum of Equation 2.4 by virtue of its low energy, is now no longer sufficient to offset the fact that arrangements in which \\(Q_a\\) has some intermediate value, though each carry a smaller weight, are vastly greater in number. A little thought shows that the arrangements which have essentially zero magnetisation (equal populations of up and down spins) are by far the most numerous. At high temperature, these disordered arrangements dominate the sum in Equation 2.4 and the order parameter is zero.\nThe competition between energy-of-arrangements weighting (or simply ‘energy’) and the ‘number of arrangements’ weighting (or ‘entropy’) is then the key principle at work here. The distinctive feature of a system with a critical point is that, in the course of this competition, the system is forced to choose amongst a number of macroscopically different sets of microscopic arrangements.\nFinally in this section, we note that the probabilistic (statistical mechanics) approach to thermal systems outlined above is completely compatible with classical thermodynamics. Specifically, the bridge between the two disciplines is provided by the following equation\n\\[\nF=-k_BT \\ln Z\n\\tag{2.5}\\]\nwhere \\(F\\) is the “Helmholtz free energy”. All thermodynamic observables, for example the order parameter \\(Q\\), and response functions such as the specific heat or magnetic susceptibility are obtainable as appropriate derivatives of the free energy. For instance, utilizing Equation 2.2, one can readily verify (try it as an exercise!) that the average internal energy is given by\n\\[\\overline{E}=-\\frac{\\partial \\ln Z}{\\partial \\beta},\\]\nwhere \\(\\beta=(k_BT)^{-1}\\).\nThe relationship between other thermodynamic quantities and derivatives of the free energy are given in fig. Figure 2.1",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Background concepts</span>"
    ]
  },
  {
    "objectID": "phase-transitions/background.html#observables-and-expectation-values",
    "href": "phase-transitions/background.html#observables-and-expectation-values",
    "title": "2  Key concepts for phase transitions",
    "section": "",
    "text": "Figure 2.1: Relationships between the partition function and thermodynamic observables",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Background concepts</span>"
    ]
  },
  {
    "objectID": "phase-transitions/background.html#sec-correlations",
    "href": "phase-transitions/background.html#sec-correlations",
    "title": "2  Key concepts for phase transitions",
    "section": "2.2 Correlations",
    "text": "2.2 Correlations\n\n2.2.1 Spatial correlations\nThe two-point connected correlation function measures how fluctuations at two spatial points are statistically related. For a scalar field \\(\\phi(\\vec{R})\\), which could represent eg. the local magnetisation \\(m\\) in a magnet at position vector \\(\\vec{R}\\), or the local particle number density \\(\\rho\\) in a fluid, it is defined as:\n\\[\nC(r) = \\langle \\phi(\\vec{R}) \\phi(\\vec{R} + \\vec{r}) \\rangle - \\langle \\phi(\\vec{R}) \\rangle^2,\n\\]\nwhere \\(\\langle \\cdot \\rangle\\) denotes an ensemble or spatial average over all \\(\\vec{R}\\), and \\(r = |\\vec{r}|\\) is the spatial separation between the two points.\n\\(C(r)\\) quantifies the spatial extent over which field values are correlated and in homogeneous and isotropic systems, it depends only on the separation \\(r\\).\nIf \\(C(r)\\) decays quickly, we say that correlations are short-ranged. Typically this occurs well away from criticality and takes the form of exponential decay\n\\[\n  C(r) \\sim e^{-r/\\xi}\n  \\] where the correlation length \\(\\xi\\) is the characteristic scale over which correlations decay.\nNear a critical point \\(C(r)\\) decays more slowly - in a power-law fashion - and correlations are long-ranged.\n\\[\n  C(r) \\sim r^{-(d - 2 + \\eta)}\n  \\] where \\(d\\) is the spatial dimension and \\(\\eta\\) is a critical exponent.\nIn isotropic fluids and particle systems, a closely related and more directly measurable quantity (particularly in simulations) is the radial distribution function \\(g(r)\\), which describes how particle density varies as a function of distance from a reference particle. For such systems, the two-point correlation function of the number density field \\(\\rho(\\vec{r})\\) is related to \\(g(r)\\) as follows:\n\\[\ng(r) = 1+\\frac{C(r)}{\\rho^2},\n\\] where \\(\\rho\\) is the average number density. This relation shows that \\(g(r)\\) encodes the same spatial correlations as \\(C(r)\\), but in a form that is more natural for discrete particle systems. Note that by definition \\(g(r)\\to 1\\) in the absence of correlations ie. when \\(C(r)=0\\). This is typically the case for \\(r\\gg\\xi\\).\nExperimentally one doesn’t typically have direct access to \\(C(r)\\), but rather its Fourier transform known as the structure factor\n\\[\nS(k) = \\int d^d r \\, e^{-i \\vec{k} \\cdot \\vec{r}} \\, C(r),\n\\] where \\(k\\) is the scattering wavevector and \\(d^dr\\) refers to the elemental volume (eg. \\(d^3r\\) in three dimensions).\nIn equilibrium:\n\nFor short-range correlations (finite \\(\\xi\\)), \\(S(k)\\) typically has a Lorentzian form: \\[\nS(k) \\sim \\frac{1}{k^2 + \\xi^{-2}}.\n\\]\nAt criticality (where \\(\\xi \\to \\infty\\)), \\(S(k)\\) follows a power law: \\[\nS(k) \\sim k^{-2 + \\eta}.\n\\]\n\nThis relation enables the extraction of \\(\\xi\\) from experimental or simulation data, especially via scattering techniques.\n\n\n2.2.2 Temporal correlations\nConsider a thermodynamic variable \\(x\\) with zero mean that fluctuates over time. Examples include the local magnetization in a magnetic system or the local density in a fluid. Here, \\(x\\) represents a deviation from the average value — a fluctuation.\nWe’re interested in how such fluctuations are correlated over time when the system is in thermal equilibrium. For instance, if \\(x\\) is positive at some time \\(t\\), it’s more likely to remain positive shortly after.\nThese temporal correlations are characterized by the two-time correlation function (also known as an auto-correlation function):\n\\[\n\\langle x(\\tau) x(\\tau + t) \\rangle\n\\]\nIn equilibrium, the correlation function must be independent of the starting time \\(\\tau\\). Therefore, we define:\n\\[\n\\langle x(\\tau) x(\\tau + t) \\rangle = M_{xx}(t)\n\\]\nThat is, \\(M_{xx}(t)\\) depends only on the time difference \\(t\\).\nWe typically expect \\(M_{xx}(t)\\) to decay exponentially over a characteristic correlation time \\(t_c\\):\n\\[\nM_{xx}(t) \\sim \\exp(-t / t_c)\n\\]\n\n\n\n\n\n\nFigure 2.2: Sketch of \\(M_{xx}(t)\\) against \\(t\\)\n\n\n\nThis exponential decay reflects how the memory of fluctuations fades with time.\nNow consider two different fluctuating variables, \\(x\\) and \\(y\\) (e.g., local magnetizations at different positions). Their cross-correlation function is defined as:\n\\[\n\\langle x(\\tau) y(\\tau + t) \\rangle = M_{xy}(t)\n\\]\nThis defines the elements of a dynamic correlation matrix, of which \\(M_{xx}(t)\\) is the diagonal.",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Background concepts</span>"
    ]
  },
  {
    "objectID": "phase-transitions/approach-to-criticality.html",
    "href": "phase-transitions/approach-to-criticality.html",
    "title": "3  The approach to criticality",
    "section": "",
    "text": "It is a matter of experimental fact that the approach to criticality in a given system is characterized by the divergence of various thermodynamic observables. Let us remain with the archetypal example of a critical system, the ferromagnet, whose critical temperature will be denoted as \\(T_c\\). For temperatures close to \\(T_c\\), the magnetic response functions (the magnetic susceptibility \\(\\chi\\) and the specific heat) are found to be singular functions, diverging as a power of the reduced (dimensionless) temperature \\(t \\equiv\n(T-T_c)/T_c\\):-\n\\[\n\\chi \\equiv \\frac{\\partial M}{\\partial H}\\propto t^{-\\gamma} ~~~~ (H=0)\n\\tag{3.1}\\]\n(where \\(M=mN\\)), \\[\nC_H \\equiv \\frac{\\partial E}{\\partial T}\\propto t^{-\\alpha} ~~~~ (H=\\textrm{ constant})\n\\tag{3.2}\\]\nAnother key quantity is the correlation length \\(\\xi\\), which measures the distance over which fluctuations of the magnetic moments are correlated. This is observed to diverge near the critical point with an exponent \\(\\nu\\).\n\\[\n\\xi \\propto t^{-\\nu} ~~~~ (T &gt; T_c,\\: H=0)\n\\tag{3.3}\\]\nSimilar power law behaviour is found for the order parameter \\(Q\\) (in this case the magnetisation) which vanishes in a singular fashion (it has infinite gradient) as the critical point is is approached as a function of temperature:\n\\[\nm \\propto t^{\\beta} ~~~~ (T &lt; T_c,\\: H=0)\n\\tag{3.4}\\] (here the symbol \\(\\beta\\), is not to be confused with \\(\\beta=1/k_BT\\)– this unfortunately is the standard notation.)\nFinally, as a function of magnetic field:\n\\[m \\propto h^{1/\\delta} ~~~~ (T = T_c,\\: |H|&gt;0) . \\tag{3.5}\\] with \\(h=(H-H_c)/H_c\\), the reduced magnetic field.\nAs examples, the behaviour of the magnetisation and correlation length are plotted in Figure 3.1 as a function of \\(t\\).\n\n\n\n\n\n\nFigure 3.1: Singular behaviour of the correlation length and order parameter in the vicinity of the critical point as a function of the reduced temperature \\(t\\).\n\n\n\nThe quantities \\(\\gamma, \\alpha, \\nu, \\beta\\) in the above equations are known as critical exponents. They serve to control the rate at which the various thermodynamic quantities change on the approach to criticality.\nRemarkably, the form of singular behaviour observed at criticality for the example ferromagnet also occurs in qualitatively quite different systems such as the fluid. All that is required to obtain the corresponding power law relationships for the fluid is to substitute the analogous thermodynamic quantities in to the above equations. Accordingly the magnetisation order parameter is replaced by the density difference \\(\\rho_{liq}-\\rho_{gas}\\) while the susceptibility is replaced by the isothermal compressibility and the specific heat capacity at constant field is replaced by the specific heat capacity at constant volume. The approach to criticality in a variety of qualitatively quite different systems can therefore be expressed in terms of a set of critical exponents describing the power law behaviour for that system (see the book by Yeomans for examples).\nEven more remarkable is the experimental observation that the values of the critical exponents for a whole range of fluids and magnets (and indeed many other systems with critical points) are identical. This is the phenomenon of universality. It implies a deep underlying physical similarity between ostensibly disparate critical systems. The principal aim of theories of critical point phenomena is to provide a sound theoretical basis for the existence of power law behaviour, the factors governing the observed values of critical exponents and the universality phenomenon. Ultimately this basis is provided by the Renormalisation Group (RG) theory, for which K.G. Wilson was awarded the Nobel Prize in Physics in 1982.\nMore about the scientists mentioned in this chapter:\nKenneth Wilson",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The approach to criticality</span>"
    ]
  },
  {
    "objectID": "phase-transitions/Ising-model.html",
    "href": "phase-transitions/Ising-model.html",
    "title": "4  The Ising model: the prototype model for a phase transition",
    "section": "",
    "text": "4.1 The 2D Ising model\nIn order to probe the properties of the critical region, it is common to appeal to simplified model systems whose behaviour parallels that of real materials. The sophistication of any particular model depends on the properties of the system it is supposed to represent. The simplest model to exhibit critical phenomena is the two-dimensional Ising model of a ferromagnet. Actual physical realizations of 2-d magnetic systems do exist in the form of layered ferromagnets such as K\\(_2\\)CoF\\(_4\\), so the 2-d Ising model is of more than just technical relevance.\nThe 2-d spin-\\(\\frac{1}{2}\\) Ising model envisages a regular arrangement of magnetic moments or ‘spins’ on an infinite plane. Each spin can take two values, \\(+1\\) (‘up’ spins) or \\(-1\\) (‘down’ spins) and is assumed to interact with its nearest neighbours according to the Hamiltonian\n\\[\n{\\cal H}_I=-J\\sum_{&lt;ij&gt;}s_is_j - H\\sum_i s_i\n\\tag{4.1}\\]\nwhere \\(J&gt;0\\) measures the strength of the coupling between spins and the sum extends over nearest neighbour spins \\(s_i\\) and \\(s_j\\), i.e it is a sum of the bonds of the lattice. \\(H\\) is a magnetic field term which can be positive or negative (although for the time being we will set it equal to zero). The order parameter is simply the average magnetisation:\n\\[m=\\frac{1}{N} \\langle \\sum_i s_i \\rangle\\:,\\] where \\(\\langle\\cdot\\rangle\\) means an average over typical configurations corresponding to the prescribed value of \\(J/k_BT\\).\nThe fact that the Ising model displays a phase transition was argued in Chapter 2. Thus at low temperatures for which there is little thermal disorder, there is a preponderance of aligned spins and hence a net spontaneous magnetic moment (ie. the system is ferromagnetic). As the temperature is raised, thermal disorder increases until at a certain temperature \\(T_c\\), entropy drives the system through a continuous phase transition to a disordered spin arrangement with zero net magnetisation (ie. the system is paramagnetic). These trends are visible in configurational snapshots from computer simulations of the 2D Ising model (see Figure 4.1). Although each spin interacts only with its nearest neighbours, the phase transition occurs due to cooperative effects among a large number of spins.\nAn interactive Monte Carlo simulation of the Ising model demonstrates the phenomenology, By altering the temperature you will be able to observe for yourself how the typical spin arrangements change as one traverses the critical region. Pay particular attention to the configurations near the critical point. They have very interesting properties. We will return to them later!\nAlthough the 2-d Ising model may appear at first sight to be an excessively simplistic portrayal of a real magnetic system, critical point universality implies that many physical observables such as critical exponents are not materially influenced by the actual nature of the microscopic interactions. The Ising model therefore provides a simple, yet quantitatively accurate representation of the critical properties of a whole range of real magnetic (and indeed fluid) systems. This universal feature of the model is largely responsible for its ubiquity in the field of critical phenomena. We shall explore these ideas in more detail later in the course.",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Ising model</span>"
    ]
  },
  {
    "objectID": "phase-transitions/Ising-model.html#the-2d-ising-model",
    "href": "phase-transitions/Ising-model.html#the-2d-ising-model",
    "title": "4  The Ising model: the prototype model for a phase transition",
    "section": "",
    "text": "(a) \\(T=1.2T_c\\)\n\n\n\n\n\n\n\n\n\n\n\n(b) \\(T=T_c\\)\n\n\n\n\n\n\n\n\n\n\n\n(c) \\(T=0.95T_c\\)\n\n\n\n\n\n\n\nFigure 4.1: Configurations of the 2d Ising model. The patterns depict typical arrangements of the spins (white=+1, black=−1) generated in a computer simulation of the Ising model on a square lattice of \\(N=512\\) sites, at temperatures (from left to right) of \\(T= 1.2T_c\\), \\(T=T_c\\), and \\(T=0.95T_c\\). In each case only a portion of the system containing \\(128\\) sites in shown. The typical island size is a measure of the correlation length \\(\\xi\\): the excess of black over white (below \\(T_c\\) is a measure of the order parameter.",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Ising model</span>"
    ]
  },
  {
    "objectID": "phase-transitions/Ising-model.html#exact-solutions-the-one-dimensional-ising-chain",
    "href": "phase-transitions/Ising-model.html#exact-solutions-the-one-dimensional-ising-chain",
    "title": "4  The Ising model: the prototype model for a phase transition",
    "section": "4.2 Exact solutions: the one dimensional Ising chain",
    "text": "4.2 Exact solutions: the one dimensional Ising chain\nOne might well ask why the 2D Ising model is the simplest model to exhibit a phase transition. What about the one-dimensional Ising model (ie. spins on a line)? In fact in one dimension, the Ising model can be solved exactly. It turns out that the system is paramagnetic for all \\(T&gt;0\\), so there is no phase transition at any finite temperature. To see this, consider the ground state of the system in zero external field. This will have all spins aligned the same way (say up), and hence be ferromagnetic. Now consider a configuration with a various “domain walls” dividing spin up and spin down regions:\n\n\n\n\n\n\nFigure 4.2: (a) Schematic of an Ising chain at \\(T=0\\). (b) At a small finite temperature the chain is split into domains of spins ordered in the same direction. Domains are separated by notional domain “walls”, which cost energy \\(\\Delta=2J\\). Periodic boundary conditions are assumed.\n\n\n\nInstead of considering the underlying spin configurations, we shall describe the system in terms of the statistics of its domain walls. The energy cost of a wall is \\(\\Delta = 2J\\), independent of position. Domain walls can occupy the bonds of the lattice, of which there are \\(N-1\\). Moreover, the walls are noninteracting, except that you cannot have two of them on the same bond. (Check through these ideas if you are unsure.)\nIn this representation, the partition function involves a count over all possible domain wall arrangements. Since the domain walls are non interacting (eg it doesn’t cost energy for one to move along the chain) they can be treated as independent. Independent contributions to the partition function simply multiply. So we can calculate \\(Z\\) by considering the partition function associated with a single domain wall being present or absent on some given bond, and then simply raise to the power of the number of bonds:\n\\[Z=Z_1^{N-1}\\]\nwhere\n\\[Z_1=e^{\\beta J} + e^{\\beta (J-\\Delta)}=e^{\\beta J}(1+e^{-\\beta\\Delta})\\] is the domain wall partition function for a single bond and represent the sum over the two possible states: domain wall absent or present. Then the free energy per bond of the system is\n\\[\\beta f\\equiv \\beta F/(N-1)=-\\ln Z_1=-\\beta J-\\ln(1+e^{-\\beta\\Delta})\\]\nThe first term on the RHS is simply the energy per spin of the ferromagnetic (ordered) phase, while the second term arises from the free energy of domain walls. Clearly for any finite temperature (ie. for \\(\\beta&lt;\\infty\\)), this second term is finite and negative. Hence the free energy will always be lowered by having a finite concentration of domain walls in the system. Since these domain walls disorder the system, leading to a zero average magnetisation, the 1D system is paramagnetic for all finite temperatures. Exercise: Explain why this argument works only in 1D.\nThe animation below lets you see qualitatively how the typical number of domain walls varies with temperature. If you’d lke to explore more quantitatively, a python code performing a Monte Carlo simulation is available. You will learn about Monte Carlo simulation in the coursework and in later parts of the course.\n\n\nShow python code\n#Monte Carlo simulation of the 1d Ising chain with periodic bounary conditions\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.animation import FuncAnimation\nfrom matplotlib.widgets import Slider\n\n# Number of spins\nN = 20 \n\n# Initialize spins (+1 or -1)\nspins = np.random.choice([-1, 1], size=N)\n\n# Initial temperature\nT = 2.0\n\n# Set up figure and axis for the spins\nfig, ax = plt.subplots(figsize=(10, 2))\nplt.subplots_adjust(bottom=0.25)  # make room for slider\nax.set_xlim(-0.5, N - 0.5)\nax.set_ylim(-1, 1)\nax.axis('off')\n\n# Create text objects for each spin\ntexts = []\nfor i in range(N):\n    arrow = '↑' if spins[i] == 1 else '↓'\n    t = ax.text(i, 0, arrow, fontsize=24, ha='center', va='center')\n    texts.append(t)\n\ndef update(frame):\n    \"\"\"Perform Metropolis updates over all spins, then refresh display.\"\"\"\n    global spins, T\n    for _ in range(N):\n        i = np.random.randint(N)\n        left = spins[(i - 1) % N]\n        right = spins[(i + 1) % N]\n        deltaE = 2 * spins[i] * (left + right)\n        # Metropolis criterion ensures configurations appear with the correct Boltzmann probability\n        if deltaE &lt; 0 or np.random.rand() &lt; np.exp(-deltaE / T):\n            spins[i] *= -1\n    # Update arrows on screen\n    for idx, t in enumerate(texts):\n        t.set_text('↑' if spins[idx] == 1 else '↓')\n    return texts\n\n# Create the animation with caching disabled and blit turned off\nani = FuncAnimation(\n    fig,\n    update,\n    interval=200,\n    blit=False,\n    cache_frame_data=False\n)\n\n# Add a temperature slider\nax_T = plt.axes([0.2, 0.1, 0.6, 0.03], facecolor='lightgray')\nslider_T = Slider(ax_T, 'Temperature T', 0.1, 5.0, valinit=T)\n\ndef on_T_change(val):\n    \"\"\"Callback to update T when the slider changes.\"\"\"\n    global T\n    T = val\n\nslider_T.on_changed(on_T_change)\n\n# Show the plot (ani is kept in scope so it won't be deleted)\nplt.show()\n\n\n\n\n\n Temperature T =\n\n2.0\n\n \n\n\n4.2.1 More general 1D spins systems: transfer matrix method\nGenerally speaking one-dimensional systems lend themselves to a degree of analytic tractability not found in most higher dimensional models. Indeed for the case of a 1-d assembly of \\(N\\) spins each having \\(m\\) discrete energy states, and in the presence of a magnetic field, it is possible to reduce the evaluation of the partition function to the calculation of the eigenvalues of a matrix–the so called transfer matrix.\nLet us start by assuming that the assembly has cyclic boundary conditions, then the total energy of configuration \\(\\{s\\}\\) is \\[\n\\begin{aligned}\n{\\cal H}(\\{s\\})=&-\\sum_{i=1}^N (J s_i s_{i+1}+Hs_i)\\\\\n\\:=&-\\sum_{i=1}^N (J s_i s_{i+1}+H(s_i+s_{i+1})/2)\\\\\n\\:=&\\sum_{i=1}^N E(s_i,s_{i+1})\n\\end{aligned}\n\\]\nwhere we have defined \\(E(s_i,s_{i+1})=-J s_i s_{i+1}-H(s_i+s_{i+1})/2\\).\nNow the partition function may be written\n\\[\\begin{aligned}\nZ_N =& \\sum_{\\{s\\}}\\exp\\left(-\\beta {\\cal H}(\\{s\\})\\right)\\nonumber \\\\\n=&\\sum_{\\{s\\}}\\exp\\left(-\\beta[E(s_1,s_2)+E(s_2,s_3)+....E(s_N,s_1)]\\right) \\nonumber\\\\\n=&\\sum_{\\{s\\}}\\exp\\left(-\\beta E(s_1,s_2)\\right)\\exp\\left(-\\beta E(s_2,s_3)\\right)....\\exp\\left(-\\beta E(s_N,s_1)\\right) \\nonumber\\\\\n=&\\sum_{i,j,...,l=1}^m V_{ij}V_{jk}...V_{li}\n\\end{aligned} \\tag{4.2}\\]\nwhere the \\(V_{ij}=\\exp(-\\beta E_{ij})\\) are elements of an \\(m \\times m\\) matrix \\(\\mathbf{V}\\), known as the transfer matrix (\\(i,j,k\\) etc are dummy indices that run over the matrix elements). You should see that the sum over the product of matrix elements picks up all the terms in the partition function and therefore Equation 4.2 is an alternative way of writing the partition function.\nThe reason it is useful to transform to a matrix representation is that it transpires that the sum over the product of matrix elements in Equation 4.2 is simply just the trace of \\(\\mathbf{V}^N\\) (check this yourself for a short periodic chain), given by the sum of its eigenvalues:-\n\n\n\n\n\n\nProof (non examinable)\n\n\n\n\n\nLet \\(V\\) be an \\(n \\times n\\) matrix, and let \\(\\lambda_1, \\dots, \\lambda_n\\) denote its eigenvalues.\nEvery square matrix \\(V\\) can be written as \\[\nV = Q T Q^\\dagger,\n\\] where \\(Q\\) is a unitary matrix (\\(Q^\\dagger Q = I\\)), and \\(T\\) is upper triangular with the eigenvalues of \\(V\\) on its diagonal: \\[\nT = \\begin{pmatrix}\n\\lambda_1 & * & \\cdots & * \\\\\n0 & \\lambda_2 & \\cdots & * \\\\\n\\vdots & & \\ddots & \\vdots \\\\\n0 & \\cdots & 0 & \\lambda_n\n\\end{pmatrix}.\n\\]\nRaising both sides to the \\(N\\)th power gives \\[\nV^N = (Q T Q^\\dagger)^N = Q \\, T^N \\, Q^\\dagger.\n\\] The trace (ie. the sum of diagonal elements) is invariant under similarity transformations: \\[\n\\mathrm{Tr}(V^N) = \\mathrm{Tr}(T^N).\n\\]\nSince \\(T\\) is upper triangular, so is \\(T^N\\). The diagonal elements of \\(T^N\\) are simply the \\(N\\)th powers of the diagonal elements of \\(T\\), i.e. \\[\n(T^N)_{ii} = (T_{ii})^N = \\lambda_i^N.\n\\]\nTherefore, \\[\n\\mathrm{Tr}(T^N) = \\sum_{i=1}^n (T^N)_{ii} = \\sum_{i=1}^n \\lambda_i^N.\n\\]\n\n\n\n\\[Z_N=\\lambda_1^N+\\lambda_2^N+...\\lambda_m^N\\] For very large \\(N\\), this expression simplifies further because the largest eigenvalue \\(\\lambda_1\\) dominates the behaviour since \\((\\lambda_2/\\lambda_1)^N\\) vanishes as \\(N\\rightarrow \\infty\\). Consequently in the thermodynamic limit one may put \\(Z_N=\\lambda_1^N\\) and the problem reduces to identifying the largest eigenvalue of the transfer matrix.\nSpecializing to the case of the simple Ising model in the presence of an applied field \\(H\\), the transfer matrix takes the form\n\\[\\mathbf{V}(H)=\\left(\n\\begin{array}{cc}\ne^{\\beta(J+H)} & e^{-\\beta J} \\\\\ne^{-\\beta J}   & e^{\\beta(J-H)}\n\\end{array} \\right)\\]\nThis matrix has two eigenvalues which can be readily calculated in the usual fashion as the roots of the characteristic polynomial \\(|\\mathbf{V}-\\lambda\\mathbf{I}|\\). They are\n\\[\\lambda_{\\pm}=e^{\\beta J}\\cosh(\\beta H) \\pm \\sqrt{e^{2\\beta J}\\sinh^2\\beta H+e^{-2\\beta J}}.\\]\nHence the free energy per spin \\(f=-k_BT\\ln \\lambda_+\\) is\n\\[f=-k_BT\\ln \\left[e^{\\beta J}\\cosh(\\beta H) + \\sqrt{e^{2\\beta J}\\sinh^2\\beta H+e^{-2\\beta J}}\\right].\\]\nThe Ising model in 2D can also be solved exactly, as was done by Lars Onsager in 1940. The solution is extremely complicated and is regarded as one of the pinnacles of statistical mechanics. In 3D no exact solution is known.",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Ising model</span>"
    ]
  },
  {
    "objectID": "phase-transitions/mean-field-theory.html",
    "href": "phase-transitions/mean-field-theory.html",
    "title": "5  Mean field theory and perturbation schemes",
    "section": "",
    "text": "5.1 Mean field solution of the Ising model\nOf the wide variety of models of interest to the critical point theorist, the majority have shown themselves intractable to direct analytic (pen and paper) assault. In a very limited number of instances models have been solved exactly, yielding the phase coexistence parameters, critical exponents and the critical temperature. The 2-d spin-\\(\\frac{1}{2}\\) Ising model is certainly the most celebrated such example, its principal critical exponents are found to be \\(\\beta=\\frac{1}{8}, \\nu=1, \\gamma=\\frac{7}{4}\\). Its critical temperature is \\(-2J/\\ln(\\sqrt{2}-1)\\approx 2.269J\\). Unfortunately such solutions rarely afford deep insight to the general framework of criticality although they do act as an invaluable test-bed for new and existing theories.\nThe inability to solve many models exactly often means that one must resort to approximations. One such approximation scheme is mean field theory.\nLet us look for a mean field expression for the free energy of the Ising model whose Hamiltonian is given in Equation 4.1 . Write\n\\[s_i=\\langle s_i\\rangle+(s_i-\\langle s_i\\rangle)=m+(s_i-m)=m+\\delta s_i\\]\nThen \\[\\begin{aligned}\n{\\cal H}_I=&-J\\sum_{&lt;i,j&gt;}[m+(s_i-m)][m+(s_j-m)]-H\\sum_i s_i\\nonumber\\\\\n=&-J\\sum_{&lt;i,j&gt;}[m^2+m(s_i-m)+m(s_j-m)+\\delta s_i\\delta s_j]-H\\sum_i s_i\\nonumber\\\\\n=&-J\\sum_{i}(qms_i-qm^2/2)-H\\sum_i s_i-J\\sum_{&lt;i,j&gt;}\\delta s_i\\delta s_j\n\\end{aligned} \\tag{5.1}\\] where in the last line we trnsformed from a sum over bonds to a sum over sites. Doing so makes use of the fact that when for each site \\(i\\) we perform the sum \\(\\sum_{&lt;i,j&gt;}\\) over bonds of a quantity which is independent of \\(s_j\\), then the result is just the number of bonds per site times that quantity. Since the number of bonds on a lattice of \\(N\\) sites of coordination \\(q\\) is \\(Nq/2\\) (because each bond is shared between two sites), there are therefore \\(q/2\\) bonds per site.\nNow the mean field approximation is to ignore the last term in the last line of Equation 5.1 giving the configurational energy as\n\\[\n{\\cal H}_{mf}=-\\sum_{i}H_{mf}s_i+NqJm^2/2\n\\] with \\(H_{mf}\\equiv qJm+ H\\) the “mean field” seen by spin \\(s_i\\). As all the spins are decoupled (independent) in this approximation we can write down the partition function, which follows by taking the partition function for a single spin (by summing the Boltzmann factor for \\(s_i=\\pm 1\\)) and raising to the power \\(N\\) to find\n\\[\nZ=e^{-\\beta qJm^2N/2}[2\\cosh(\\beta(qJm+H))]^N\n\\]\nThe free energy follows as\n\\[F(m)=NJqm^2/2-Nk_BT\\ln[2\\cosh(\\beta (qJm+H)]\\:.\\]\nand the magnetisation as\n\\[\nm=-\\frac{1}{N}\\frac{\\partial F}{\\partial H}=\\tanh(\\beta(qJm+H)),\n\\] where the first term drops out because we treat \\(m\\) as an independent variable when differentiating w.r.t. \\(H\\).\nThis is a self consistent equation because \\(m\\) appears on both the left and the right hand sides. To find \\(m(H,T)\\), we must numerically solve this last equation-self consistently. You will meet such an equation again later when you learn about mean field theories for liquid crystals.\nNote that we can obtain \\(m\\) in a different way. Consider some arbitary spin, \\(s_i\\) say. Then this spin has an energy \\({\\cal H}_{mf}(s_i)\\). Considering this energy for both cases \\(s_i=\\pm 1\\) and the probability \\(p(s_i)=e^{-\\beta{\\cal H}_{mf}(s_i)}/Z\\) of each, we have that\n\\[\\langle s_i\\rangle=\\sum_{s_i=\\pm 1}s_ip(s_i)\\] but for consistancy, \\(\\langle s_i\\rangle=m\\). Thus\n\\[\n\\begin{aligned}\nm & = \\sum_{s_i=\\pm 1}s_ip(s_i)\\nonumber\\\\\n\\: & = \\frac{e^{\\beta(qJm+H)}-e^{-\\beta(qJm+H)}} {e^{\\beta(qJm+H)}+e^{-\\beta(qJm+H)}}\\nonumber\\\\\n\\: & = \\tanh(\\beta(qJm+H))\n\\end{aligned} \\tag{5.2}\\] as before.",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Mean field theory</span>"
    ]
  },
  {
    "objectID": "phase-transitions/mean-field-theory.html#sec-mfising",
    "href": "phase-transitions/mean-field-theory.html#sec-mfising",
    "title": "5  Mean field theory and perturbation schemes",
    "section": "",
    "text": "Why self-consistent?\n\n\n\n\n\nIn mean-field theory, the many-body interaction is replaced by an effective one-body problem in which each degree of freedom experiences an average field generated by all the others. The quantity that characterises the ordered phase—the order parameter—is precisely this average. Because the effective (mean-field) Hamiltonian is constructed using a presumed value of that average, internal consistency requires that the order parameter obtained by solving the effective problem match the value assumed to define it. Enforcing this equality yields a self-consistency condition for the order parameter. In practice: choose the effective field determined by the putative order parameter, compute the corresponding thermal average, and require that the two coincide.",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Mean field theory</span>"
    ]
  },
  {
    "objectID": "phase-transitions/mean-field-theory.html#sec-breaking",
    "href": "phase-transitions/mean-field-theory.html#sec-breaking",
    "title": "5  Mean field theory and perturbation schemes",
    "section": "5.2 Spontaneous symmetry breaking",
    "text": "5.2 Spontaneous symmetry breaking\n\n\n\n\n\n\nFigure 5.1: Schematic of the form of the free energy for a critical, subcritical and supercritical temperature\n\n\n\nThis mean field analysis reveals what is happening in the Ising model near the critical temperature \\(T_c\\). Figure 5.1 shows sketches for \\(\\beta F(m)/N\\) as a function of temperature, where for f simplicity we restrict attention to \\(H=0\\). In this case \\(F(m)\\) is symmetric in \\(m\\), Moreover, at high \\(T\\), the entropy dominates and there is a single minimum in \\(F(m)\\) at \\(m=0\\). As \\(T\\) is lowered, there comes a point (\\(T=T_c=qJ/k_B\\)) where the curvature of \\(F(m)\\) at the origin changes sign; precisely at this point\n\\[\\frac{\\partial^2 F}{\\partial m^2}=0.\\] At lower temperature, there are instead two minima at nonzero \\(m=\\pm m^\\star\\), where the equilibrium magnetisation \\(m^\\star\\) is the positive root (calculated explicitly below) of\n\\[m^\\star=\\tanh(\\beta Jqm^\\star)= \\tanh(\\frac{m^\\star T_c}{T})\\] The point \\(m=0\\) which remains a root of this equation, is clearly an unstable point for \\(T&lt;T_c\\) (since \\(F\\) has a maximum there).\nThis is an example of spontaneous symmetry breaking. In the absence of an external field, the Hamiltonian (and therefore the free energy) is symmetric under \\(m\\to -m\\). Accordingly, one might expect the actual state of the system to also show this symmetry. This is true at high temperature, but spontaneously breaks down at low ones. Instead there are a pair of ferromagnetic states (spins mostly up, or spins mostly down) which – by symmetry– have the same free energy, lower than the unmagnetized state.",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Mean field theory</span>"
    ]
  },
  {
    "objectID": "phase-transitions/mean-field-theory.html#phase-diagram",
    "href": "phase-transitions/mean-field-theory.html#phase-diagram",
    "title": "5  Mean field theory and perturbation schemes",
    "section": "5.3 Phase diagram",
    "text": "5.3 Phase diagram\nThe resulting zero-field magnetisation curve \\(m(T,H=0)\\) looks like Figure 5.2.\n\n\n\n\n\n\nFigure 5.2: Phase diagram of a simple magnet in the \\(m\\)-\\(T\\) plane.\n\n\n\nThis shows the sudden change of behaviour at \\(T_c\\) (phase transition). For \\(T&lt;T_c\\) it is arbitrary which of the two roots \\(\\pm m^\\star\\) is chosen; typically it will be different in different parts of the sample (giving macroscopic “magnetic domains”). But this behaviour with temperature is qualitatively modified by the presence of a field \\(H\\), however small. In that case, there is always a slight magnetization, even far above \\(T_c\\) and the curves becomes smoothed out, as shown. There is no doubt which root will be chosen, and no sudden change of the behaviour (no phase transition). Spontaneous symmetry breaking does not occur, because the symmetry is already broken by \\(H\\). (The curve \\(F(m)\\) is lopsided, rather than symmetrical about \\(m=0\\).)\nOn the other hand, if we sit below \\(T_c\\) in a positive field (say) and gradually reduce \\(H\\) through zero so that it becomes negative, there is a very sudden change of behaviour at \\(h=0\\): the equilibrium state jumps discontinuously from \\(m=m^\\star\\) to \\(m=-m^\\star\\).\n\n\n\n\n\n\nFigure 5.3: Phase diagram of a simple magnet in the \\(H\\)-\\(T\\) plane.\n\n\n\nThis is called a first order phase transition as opposed to the “second order” or continuous transition that occurs at \\(T_c\\) in zero field. The definitions are:\nFirst order transition: magnetisation (or similar order parameter) depends discontinuously on a field variable (such as \\(h\\) or \\(T\\)).\nContinuous transition (criticality): Change of functional form, but no discontinuity in \\(m\\); typically, however, \\((\\partial m/\\partial T)_h\\) (or similar) is either discontinuous, or diverges with an integrable singularity.\nIn this terminology, we can say that the phase diagram of the magnet in the \\(H,T\\) plane shows a line of first order phase transitions, terminating at a continuous transition, which is the critical point.\n\n\n\n\n\n\nAside on Quantum Criticality\n\n\n\n\n\nIn some magnetic systems such as \\(CePd_2Si_2\\), one can, by applying pressure or altering the chemical composition, depress the critical temperature all the way to abolute zero! This may seem counterintuitive, after all at \\(T=0\\) one should expect perfect ordering, not the large fluctuations that accompany criticality. It turns out that the source of the fluctuations that drive the system critical is zero point motion associated with the Heisenberg uncertainty principle. Quantum criticality is a matter of ongoing active research, and open questions concern the nature of the phase diagrams and the relationship to superconductivity. Although the subject goes beyond the scope of this course, there is an accessible article here if you want to learn more.",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Mean field theory</span>"
    ]
  },
  {
    "objectID": "phase-transitions/mean-field-theory.html#a-closer-look-critical-exponents",
    "href": "phase-transitions/mean-field-theory.html#a-closer-look-critical-exponents",
    "title": "5  Mean field theory and perturbation schemes",
    "section": "5.4 A closer look: critical exponents",
    "text": "5.4 A closer look: critical exponents\nLet us now see how we can calculate critical exponents within the mean field approximation.\n\n5.4.1 Zero H solution and the order parameter exponent\nIn zero field\n\\[m=\\tanh(\\frac{mT_c}{T})\\] where \\(T_c=qJ/k_B\\) is the critical temperature at which \\(m\\) first goes to zero.\nWe look for a solution where \\(m\\) is small (\\(\\ll 1\\)). Expanding the tanh function and replacing \\(\\beta=(k_BT)^{-1}\\) yields\n\\[m=\\frac{mT_c}{T}-\\frac{1}{3}\\left(\\frac{mT_c}{T} \\right)^3 +O(m^5)\\:.\\] Then \\(m=0\\) is one solution. The other solution is given by\n\\[m^2=3\\left(\\frac{T}{T_c} \\right)^3\\left(\\frac{T_c}{T} -1\\right)\\]\nNow, considering temperatures close to \\(T_c\\) to guarantee small \\(m\\), and employing the reduced temperature \\(t=(T-T_c)/T_c\\), one finds\n\\[m^2\\simeq -3t\\]\nHence\n\\[\\begin{aligned}\nm= 0  &    ~~~\\textrm{for } T&gt;T_c \\:\\:\\:  \\textrm{since otherwise $m$ imaginary}\\\\\nm= \\pm\\sqrt{-3t} & ~~\\textrm{ for}  \\:\\:\\: T&lt;T_c ~~\\textrm{ real}\n\\end{aligned}  \\tag{5.3}\\] This result implies that (within the mean field approximation) the critical exponent \\(\\beta=1/2\\).\n\n\n5.4.2 Finite (but small) field solution: the susceptibility exponent\nIn a finite, but small field we can expand Equation 5.2 thus:\n\\[m=\\frac{mT_c}{T}-\\frac{1}{3}\\left(\\frac{mT_c}{T} \\right)^3 +\\frac{H}{kT}\\]\nConsider now the isothermal susceptibility\n\\[\n\\begin{aligned}\n\\chi  \\equiv & \\left(\\frac{\\partial m}{\\partial H}\\right)_T\\\\\n      =     & \\frac{T_c}{T}\\chi - \\left(\\frac{T_c}{T}\\right)^3 \\chi m^2 + \\frac{1}{k_BT}  \n\\end{aligned}\n\\]\nThen\n\\[\\chi \\left[ 1-\\frac{T_c}{T} +\\left(\\frac{T_c}{T}\\right)^3m^2  \\right]=\\frac{1}{k_BT}\\]\nHence near \\(T_c\\)\n\\[\\chi=\\frac{1}{k_BT_c}\\left(\\frac{1}{t+m^2}\\right)\\]\nThen using the results of Equation 5.3\n\\[\n\\begin{aligned}\n\\chi= (k_BT_ct)^{-1} & \\textrm{ for} ~~~ T&gt; T_c \\\\\n\\chi= (-2k_BT_ct)^{-1} & \\textrm{ for}  ~~~T \\le T_c\n\\end{aligned}\n\\]\nwhere one has to take the non-zero value for \\(m\\) below \\(T_c\\) to ensure +ve \\(\\chi\\), i.e. thermodynamic stability. This result implies that (within the mean field approximation) the critical exponent \\(\\gamma=1\\).\nThe schematic behaviour of the Ising order parameter and susceptibility are shown in Figure 5.5 (a) and (b) respectively.\n\n\n\n\n\n\n\n\n\n\n\n(a) Mean field behaviour of the Ising magnetisation (schematic)\n\n\n\n\n\n\n\n\n\n\n\n(b) Mean field behaviour of the Ising susceptibility (schematic)\n\n\n\n\n\n\n\nFigure 5.4",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Mean field theory</span>"
    ]
  },
  {
    "objectID": "phase-transitions/mean-field-theory.html#sec-landau-theory",
    "href": "phase-transitions/mean-field-theory.html#sec-landau-theory",
    "title": "5  Mean field theory and perturbation schemes",
    "section": "5.5 Landau theory",
    "text": "5.5 Landau theory\nLandau theory is a slightly more general type of mean field theory than that discussed in the previous subsection because it is not based on a particular microscopic model. Its starting point is the Helmholtz free energy, which Landau asserted can be written in terms of power series expansion of the order parameter \\(\\phi\\):\n\\[\nF_(\\phi)=\\sum_{i=0}^{\\infty}a_i\\phi^i\n\\] The equilibrium value of \\(\\rho\\) is that which minimises the Landau free energy.\n\n\n\n\n\n\nA note on order parameters\n\n\n\n\n\nWe have already seen examples of these in earlier sections, e.g., for the liquid-gas transition this was \\[\n\\rho_{liq} - \\rho_{gas}: \\quad \\textrm{difference in density of two coexisting phases},\n\\] while for the Ising magnet it is the magnetisation \\(m\\). Both quantities vanish at the critical point. These are examples of scalar order parameters – a single number is required to represent the degree of order (\\(n = 1\\)).\nIn the absence of a symmetry-breaking field, the Landau free-energy density \\(f_L\\) must have symmetry \\(f_L(-\\phi) = f_L(\\phi)\\) (Ising case).\nFor some other systems, \\(n\\) component vectors are required in order to represent the order:\n\\[\n\\boldsymbol{\\phi} = (\\phi_1, \\phi_2, \\dots, \\phi_n)\n\\]\nThen \\(f_L(\\boldsymbol{\\phi})\\) should be symmetric under \\(O(n)\\) rotations in \\(n\\)-component \\(\\phi\\)-space.\nThe table below lists examples of order parameters for various physical systems.\n\n\n\n\n\n\n\n\nPhysical System\nOrder Parameter \\(\\varphi\\)\nSymmetry Group\n\n\n\n\nUniaxial (Ising) ferromagnet\nMagnetisation per spin, \\(m\\)\n\\(O(1)\\)\n\n\nFluid (liquid-gas)\nDensity difference, \\(\\rho - \\rho_c\\)\n\\(O(1)\\)\n\n\nLiquid mixtures\nConcentration difference, \\(c - c_c\\)\n\\(O(1)\\)\n\n\nBinary (AB) alloy (e.g., \\(\\beta\\)-brass)\nConcentration of one of the species, \\(c\\)\n\\(O(1)\\)\n\n\nIsotropic (vector) ferromagnet\n\\(n\\)-component magnetisation, \\(\\mathbf{m} = (m_1, m_2, \\dots, m_n)\\)\n\\(O(n)\\)\n\n\n\n\\(n = 2\\): xy model\n\\(O(2)\\)\n\n\n\n\\(n = 3\\): Heisenberg model\n\\(O(3)\\)\n\n\nSuperfluid He\\(^4\\)\nMacroscopic condensate wavefunction, \\(\\Psi\\)\n\\(O(2)\\)\n\n\nSuperconductor (s-wave)\nMacroscopic condensate wavefunction, \\(\\Psi\\)\n\\(O(2)\\)\n\n\nNematic liquid crystal\nOrientational order, \\(\\langle P_2(\\cos \\theta)\\rangle\\)\n\n\n\nSmectic A liquid crystal\n1-dimensional periodic density\n\n\n\nCrystal\n3-dimensional periodic density\n\n\n\n\nNotes:\n\nIn superfluid \\(^4He\\) the order parameter is\n\n\\[\n\\Psi = |\\Psi| e^{i\\theta},\n\\]\nthe complex wavefunction of the macroscopic condensate. Both the amplitude \\(|\\Psi|\\) and phase \\(\\theta\\) must be specified, so this corresponds to \\(n = 2\\).\nSuperconductors also correspond to \\(n = 2\\).\n\nIn a nematic liquid crystal, the orientational order parameter is\n\n\\[\n\\langle P_2(\\cos \\theta) \\rangle \\equiv \\frac{1}{2}\\langle 3\\cos^2 \\theta - 1\\rangle,\n\\]\nwhere \\(\\theta\\) is the angle a molecule makes with the average direction of the long axes of the molecules (known as the director \\(\\hat{n}\\)). Rotational symmetry is broken. For the case of an \\(n\\) component vector, the free energy should be a function of:\n\\[\n\\phi^2 \\equiv |\\boldsymbol{\\phi}|^2 = \\phi_1^2 + \\phi_2^2 + \\dots + \\phi_n^2 = \\sum_{i=1}^n \\phi_i^2\n\\] in the absence of a symmetry breaking field. Rotational symmetry is incorporated into the theory.\n\n\n\n\n\n\n\n\n\n\n\n(a) Schematic of the isotropic liquid phase of a system of elongated molcules.\n\n\n\n\n\n\n\n\n\n\n\n(b) Schematic of the nematic liquid phase of a system elongated molcules. This phase has uniaxial ordering.\n\n\n\n\n\n\n\nFigure 5.5: Isotropic and uniaxially ordered (nematic) phases of liquid crystal molecules.\n\n\n\n\n\n\nTo exemplify the approach, let us specialise to the case of a ferromagnet where \\(\\phi=m\\), the magnetisation and write the Landau free energy as\n\\[\nF(m)=F_0+a_2m^2+a_4m^4\n\\tag{5.4}\\]\nHere only the terms compatible with the order parameter symmetry are included in the expansion and we truncate the series at the 4th power because this is all that is necessary to yield the essential phenomenology. On symmetry grounds, the free energy of a ferromagnet should be invariant under a reversal of the sign of the magnetisation. Terms linear and cubic in \\(m\\) are not invariant under \\(m\\to -m\\), and so do not feature.\nOne can understand how the Landau free energy can give rise to a critical point and coexistence values of the magnetisation, by plotting \\(F(m)\\) for various values of \\(a_2\\) with \\(a_4\\) assumed positive (which ensures that the magnetisation remains bounded). This is shown in the following movie:\n\n\nThe situation is qualitatively similar to that discussed in Section 5.2. Thermodynamics tells us that the system adopts the state of lowest free energy. From the movie, we see that for \\(a_2&gt;0\\), the system will have \\(m=0\\), i.e. will be in the disordered (or paramagnetic) phase. For \\(a_2&lt;0\\), the minimum in the free energy occurs at a finite value of \\(m\\), indicating that the ordered (ferromagnetic) phase is the stable one. In fact, the physical (up-down) spin symmetry built into \\(F\\) indicates that there are two equivalent stable states at \\(m=\\pm m^\\star\\). \\(a_2=0\\) corresponds to the critical point which marks the border between the ordered and disordered phases. Note that it is an inflexion point, so has \\(\\frac{d^2F}{dm^2}=0\\).\nClearly \\(a_2\\) controls the deviation from the critical temperature, and accordingly we may write\n\\[a_2=\\tilde{a_2} t\\] where \\(t\\) is the reduced temperature. Thus we see that the trajectory of the minima as a function of \\(a_2&lt;0\\) in the above movie effective traces out the coexistence curve in the \\(m-T\\) plane.\nWe can now attempt to calculate critical exponents. Restricting ourselves first to the magnetisation exponent \\(\\beta\\) defined by \\(m=t^\\beta\\), we first find the equilibrium magnetisation, corresponding to the minimum of the Landau free energy:\n\\[\n\\frac{dF}{dm}=2\\tilde{a_2} tm+4a_4m^3=0\n\\tag{5.5}\\]\nwhich implies\n\\[m\\propto (-t)^{1/2},\\] so \\(\\beta=1/2\\), which is again a mean field result.\nLikewise we can calculate the effect of a small field \\(H\\) if we sit at the critical temperature \\(T_c\\). Since \\(a_2=0\\), we have\n\\[F(m)=F_0+a_4m^4-Hm\\]\n\\[\\frac{\\partial F}{\\partial m}=0 \\Rightarrow m(H,T_c)=\\left(\\frac{H}{4a_4}\\right)^{1/3}\\]\nor\n\\[H \\sim m^\\delta ~~~~~ \\delta=3\\] which defines a second critical exponent.\nNote that at the critical point, a small applied field causes a very big increase in magnetisation; formally, \\((\\partial m/\\partial H)_T\\) is infinite at \\(T=T_c\\).\nA third critical exponent can be defined from the magnetic susceptibility at zero field\n\\[\\chi=\\left(\\frac{\\partial m}{\\partial H}\\right)_{T,V} \\sim |T-T_c|^{-\\gamma}\\]\nExercise: Show that the Landau expansion predicts \\(\\gamma=1\\).\nFinally we define a fourth critical exponent via the variation of the heat capacity (per site or per unit volume) \\(C_H\\), in fixed external field \\(H=0\\):\n\\[C_H \\sim |T-T_c|^{-\\alpha}\\]\nBy convention, \\(\\alpha\\) is defined to be positive for systems where there is a divergence of the heat capacity at the critical point (very often the case). The heat capacity can be calculated from\n\\[C_H =-T\\frac{\\partial^2 F}{\\partial T^2}\\]\nFrom the minimization over \\(m\\) Equation 5.5 one finds (exercise: check this) \\[\n\\begin{aligned}\nF = & 0 ~~~~T&gt;T_c\\nonumber\\\\\nF = & -a_2^2/4a_4 ~~~~ T &lt; T_c\n\\end{aligned}\n\\]\nUsing the fact that \\(a_2\\) varies linearly with \\(T\\), we have\n\\[\n\\begin{aligned}\nC_H =& 0 ~~~~ T\\to T_c^+\\nonumber\\\\\nC_H =& \\frac{T\\tilde a_2^2}{2a_4} ~~~~ T \\to T_c^-\\:,\n\\end{aligned}\n\\]\nwhich is actually a step discontinuity in specific heat. Since for positive \\(\\alpha\\) the heat capacity is divergent, and for negative \\(\\alpha\\) it is continuous, this behaviour formally corresponds to \\(\\alpha=0\\)",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Mean field theory</span>"
    ]
  },
  {
    "objectID": "phase-transitions/mean-field-theory.html#shortcomings-of-mean-field-theory",
    "href": "phase-transitions/mean-field-theory.html#shortcomings-of-mean-field-theory",
    "title": "5  Mean field theory and perturbation schemes",
    "section": "5.6 Shortcomings of mean field theory",
    "text": "5.6 Shortcomings of mean field theory\nWhile mean field theories provide a useful route to understanding qualitatively the phenomenology of phase transitions, in real ferromagnets, as well as in more sophisticated theories, the critical exponents are not the simple fraction and integers found here. This failure of mean field theory to predict the correct exponents is of course traceable to their neglect of correlations. In later sections we shall start to take the first steps to including the effects of long range correlations.\n\n\n\nComparison of true Ising critical exponents with their mean field theory predictions in a number of dimensions.\n\n\n\\(\\:\\)\nMean Field\n\\(d=1\\)\n\\(d=2\\)\n\\(d=3\\)\n\n\nCritical temperature \\(k_BT/qJ\\)\n\\(1\\)\n\\(0\\)\n\\(0.5673\\)\n\\(0.754\\)\n\n\nOrder parameter exponent \\(\\beta\\)\n\\(\\frac{1}{2}\\)\n-\n\\(\\frac{1}{8}\\)\n\\(0.325 \\pm 0.001\\)\n\n\nSusceptibility exponent \\(\\gamma\\)\n\\(1\\)\n\\(\\infty\\)\n\\(\\frac{7}{4}\\)\n\\(1.24 \\pm 0.001\\)\n\n\nCorrelation length exponent \\(\\nu\\)\n\\(\\frac{1}{2}\\)\n\\(\\infty\\)\n\\(1\\)\n\\(0.63\\pm 0.001\\)",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Mean field theory</span>"
    ]
  },
  {
    "objectID": "phase-transitions/scaling.html",
    "href": "phase-transitions/scaling.html",
    "title": "6  The Static Scaling Hypothesis",
    "section": "",
    "text": "6.1 Experimental Verification of Scaling\nHistorically, the first step towards properly elucidating near-critical behaviour was taken with the static scaling hypothesis. This is essentially a plausible conjecture concerning the origin of power law behaviour which appears to be consistent with observed phenomena. According to the hypothesis, the basis for power law behaviour (and associated scale invariance or “scaling”) in near-critical systems is expressed in the claim that: in the neighbourhood of a critical point, the basic thermodynamic functions (most notably the free energy) are generalized homogeneous functions of their variables. For such functions one can always deduce a scaling law such that by an appropriate change of scale, the dependence on two variables (e.g. the temperature and applied field) can be reduced to dependence on one new variable. This claim may be warranted by the following general argument.\nA function of two variables \\(g(u,v)\\) is called a generalized homogeneous function if it has the property\n\\[g(\\lambda^au,\\lambda^bv)=\\lambda g(u,v)\\] for all \\(\\lambda\\), where the parameters \\(a\\) and \\(b\\) (known as scaling parameters) are constants. An example of such a function is \\(g(u,v)=u^3+v^2\\) with \\(a=1/3, b=1/2\\).\nNow, the arbitrary scale factor \\(\\lambda\\) can be redefined without loss of generality as \\(\\lambda^a=u^{-1}\\) giving\n\\[g(u,v)=u^{1/a}g(1,\\frac{v}{u^{b/a}})\\] A corresponding relation is obtained by choosing the rescaling to be \\(\\lambda^b=v^{-1}\\).\n\\[\\label{eq:sca2}\ng(u,v)=v^{1/b}g(\\frac{u}{v^{a/b}},1)\\]\nThis equation demonstrates that \\(g(u,v)\\) indeed satisfies a simple power law in \\(\\mathit{one}\\) variable, subject to the constraint that \\(u/v^{a/b}\\) is a constant. It should be stressed, however, that such a scaling relation specifies neither the function \\(g\\) nor the parameters \\(a\\) and \\(b\\).\nNow, the static scaling hypothesis asserts that in the critical region, the free energy \\(F\\) is a generalized homogeneous function of the (reduced) thermodynamic fields \\(t=(T-T_c)/T_c\\) and \\(h=(H-H_c)\\). Remaining with the example ferromagnet, the following scaling assumption can then be made:\n\\[F(\\lambda^a t,\\lambda^b h)=\\lambda F(t,h) \\:.\n\\label{eq:scagibbs}\\]\nWithout loss of generality, we can set \\(\\lambda^a=t^{-1}\\), implying \\(\\lambda=t^{-1/a}\\) and \\(\\lambda^b=t^{-b/a}\\).\nThen \\[F(t,h)=t^{1/a}F(1,t^{-b/a}h)\\] where our choice of \\(\\lambda\\) ensures that \\(F\\) on the rhs is now a function of a single variable \\(t^{-b/a}h\\).\nNow, as stated in Chapter 2, the free energy provides the route to all thermodynamic functions of interest. An expression for the magnetisation can be obtained simply by taking the field derivative of \\(F\\) (cf. Figure 2.1)\n\\[m(t,h)=-t^{(1-b)/a}m(1,t^{-b/a}h)\n\\tag{6.1}\\]\nIn zero applied field \\(h=0\\), this reduces to\n\\[m(t,0)=(-t)^{(1-b)/a}m(1,0)\\] where the r.h.s. is a power law in \\(t\\). Equation 3.4 then allows identification of the exponent \\(\\beta\\) in terms of the scaling parameters \\(a\\) and \\(b\\).\n\\[\\beta=\\frac{1-b}{a}\\]\nBy taking further appropriate derivatives of the free energy, other relations between scaling parameters and critical exponents may be deduced. Such calculations (Exercise: try to derive them) yield the results \\(\\delta =\nb/(1-b)\\),\\(\\gamma = (2b-1)/a\\), and \\(\\alpha =(2a-1)/a\\) . Relationships between the critical exponents themselves can be obtained trivially by eliminating the scaling parameters from these equations. The principal results (known as “scaling laws”) are:- \\[\n\\begin{aligned}\n\\alpha+\\beta(\\delta+1)=2 \\\\\n\\alpha+2\\beta+\\gamma=2\n\\end{aligned}\n\\]\nThus, provided all critical exponents can be expressed in terms of the scaling parameters \\(a\\) and \\(b\\), then only two critical exponents need be specified, for all others to be deduced. Of course these scaling laws are also expected to hold for the appropriate thermodynamic functions of analogous systems such as the liquid-gas critical point.\nThe validity of the scaling hypothesis finds startling verification in experiment. To facilitate contact with experimental data for real systems, consider again Equation 6.1. Eliminating the scaling parameters \\(a\\) and \\(b\\) in favour of the exponents \\(\\beta\\) and \\(\\delta\\) gives\n\\[\n\\frac{m(t,h)}{t^{\\beta}}=m(1,\\frac{h}{t^{\\beta\\delta}})\n\\] where the RHS of this last equation can be regarded as a function of the single scaled variable \\(\\tilde{H} \\equiv t^{-\\beta\\delta} h(t,M)\\).\nFor some particular magnetic system, one can perform an experiment in which one measures \\(m\\) vs \\(h\\) for various fixed temperatures. This allows one to draw a set of isotherms, i.e. \\(m-h\\) curves of constant \\(t\\). These can be used to demonstrate scaling by plotting the data against the scaling variables \\(M=t^{-\\beta}m(t,h)\\) and \\(\\tilde{H}=t^{-\\beta\\delta}h(t,M)\\). Under this scale transformation, it is found that all isotherms (for \\(t\\) close to zero) coincide to within experimental error. Reassuringly, similar results are found using the scaled equation of state of simple fluid systems such as He\\(^3\\) or Xe.\nIn summary, the static scaling hypothesis is remarkably successful in providing a foundation for the observation of power laws and scaling phenomena. However, it furnishes little or no guidance regarding the role of co-operative phenomena at the critical point. In particular it provides no means for calculating the values of the critical exponents appropriate to given model systems.",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The static scaling hypothesis</span>"
    ]
  },
  {
    "objectID": "phase-transitions/scaling.html#experimental-verification-of-scaling",
    "href": "phase-transitions/scaling.html#experimental-verification-of-scaling",
    "title": "6  The Static Scaling Hypothesis",
    "section": "",
    "text": "Figure 6.1: Magnetisation of CrBr\\(_3\\) in the critical region plotted in scaled form (see text). From Ho and Lister (1969).",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The static scaling hypothesis</span>"
    ]
  },
  {
    "objectID": "phase-transitions/scaling.html#sec-compsim",
    "href": "phase-transitions/scaling.html#sec-compsim",
    "title": "6  The Static Scaling Hypothesis",
    "section": "6.2 Computer simulation",
    "text": "6.2 Computer simulation\nIn seeking to employ simulation to obtain estimates of bulk critical point properties (such as the location of a critical point and the values of its associated exponents), one is immediately confronted with a difficulty. The problem is that simulations are necessarily restricted to dealing with systems of finite-size and cannot therefore accommodate the truly long ranged fluctuations that characterize the near-critical regime. As a consequence, the critical singularities in \\(C_v\\), order parameter, etc. appear rounded and shifted in a simulation study. Figure 6.2 shows a schematic example for the susceptibility of a magnet.\n\n\n\n\n\n\nFigure 6.2: Schematic of the near-critical temperature dependence of the magnet susceptibility in a finite-sized system.\n\n\n\nThus the position of the peak in a response function (such as \\(C_v\\)) measured for a finite-sized system does not provide an accurate estimate of the critical temperature. Although the degree of rounding and shifting reduces with system size, it is often the case, that computational constraints prevent access to the largest system sizes which would provide accurate estimates of critical parameters. To help deal with this difficulty, finite-size scaling (FSS) methods have been developed to allow extraction of bulk critical properties from simulations of finite size. FSS will be discussed in section 7.",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The static scaling hypothesis</span>"
    ]
  },
  {
    "objectID": "phase-transitions/rg.html",
    "href": "phase-transitions/rg.html",
    "title": "7  Universality and the Renormalisation Group Theory of Critical Phenomena",
    "section": "",
    "text": "7.1 The critical point: A many length scale problem\nOwing the the absence of a wholly appropriate textbook for the material covered in this section, I have supplied more detailed notes than used in other parts of the unit.\nThe critical region is characterised by correlated microstructure on \\(\\underline{all}\\) length-scales up to and including the correlation length.\nSuch a profusion of degrees of freedom can only be accurately characterized by a very large number of variables. Mean field theories and approximation schemes fail in the critical region because they at best incorporate interactions among only a few spins, while neglecting correlations over larger distances. Similarly, the scaling hypothesis fails to provide more than a qualitative insight into the nature of criticality because it focuses on only one length-scale, namely the correlation length itself. Evidently a fuller understanding of the critical region may only be attained by taking account of the existence of structure on all length-scales. Such a scheme is provided by the renormalisation group method, which stands today as the cornerstone of the modern theory of critical phenomena.\nA near critical system can be characterized by three important length scales, namely\nThe authentic critical region is defined by a window condition:\n\\[L_\\textrm{ max} \\gg \\xi \\gg L_\\textrm{ min}\\]\nThe physics of this regime is hard to tackle by analytic theory because it is characterized by configurational structure on all scales between \\(L_\\textrm{ min}\\) and \\(\\xi\\) (in fact it turns out that the near critical configurational patterns are fractal-like, cf. Figure 4.1 (b). Moreover different length scales are correlated with one another, giving rise to a profusion of coupled variables in any theoretical description. The window regime is also not easily accessed by computer simulation because it entails studying very large system sizes \\(L_\\textrm{\nmax}\\), often requiring considerable computing resources.\nA nice illustration of critical point scale invariance in the Ising model can be viewed here.",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Universality and renormalization group theory</span>"
    ]
  },
  {
    "objectID": "phase-transitions/rg.html#the-critical-point-a-many-length-scale-problem",
    "href": "phase-transitions/rg.html#the-critical-point-a-many-length-scale-problem",
    "title": "7  Universality and the Renormalisation Group Theory of Critical Phenomena",
    "section": "",
    "text": "The correlation length, \\(\\xi\\), ie the size of correlated microstructure.\nMinimum length scale \\(L_\\textrm{ min}\\), i.e. the smallest length in the microscopics of the problem, e.g. lattice spacing of a magnet or the particle size in a fluid.\nMacroscopic size \\(L_{max}\\) eg. size of the system.",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Universality and renormalization group theory</span>"
    ]
  },
  {
    "objectID": "phase-transitions/rg.html#sec-rgmethod",
    "href": "phase-transitions/rg.html#sec-rgmethod",
    "title": "7  Universality and the Renormalisation Group Theory of Critical Phenomena",
    "section": "7.2 Methodology of the RG",
    "text": "7.2 Methodology of the RG\nThe central idea of the renormalisation group (RG) method is a stepwise elimination of the degrees of freedom of the system on successively larger length-scales. To achieve this one introduces a fourth length scale \\(L\\). In contrast to the other three, which characterize the system itself, \\(L\\) characterises the description of the system. It may be thought of as typifying the size of the smallest resolvable detail in a description of the system’s microstructure.\nConsider the Ising model arrangements displayed in Figure 4.1. These pictures contain all the details of each configuration shown: the resolution length \\(L\\) in this case has its smallest possible value, coinciding with the lattice spacing i.e. \\(L=L_{\\min}\\). In the present context, the most detailed description is not the most useful: the essential signals with which we are concerned are hidden in a noise of relevant detail. A clue to eliminating this noise lies in the nature of the correlation length, i.e. the size of the largest droplets. The explicit form of the small scale microstructure is irrelevant to the behaviour of \\(\\xi\\). The small scale microstructure is the noise. To eliminate it, we simply select a larger value of the resolution length (or ‘coarse-graining’ length) \\(L\\).\nThere are many ways of implementing this coarse-graining procedure. We adopt a simple strategy in which we divide our sample into blocks of side \\(L\\), each of which contains \\(L^d\\) sites, with \\(d\\) the space dimensions . The centres of the blocks define a lattice of points indexed by \\(I=1,2,\\ldots,N/L^d\\). We associate with each block lattice point centre, \\(I\\), a coarse-grained or block variable \\(S_I(L)\\) defined as the spatial average of the local variables it contains:\n\\[\nS_I(L)=L^{-d}\\sum_i^Is_i\n\\tag{7.1}\\] where the sum extends over the \\(L^d\\) sites in the block \\(I\\). The set of coarse grained coordinates \\(\\{S(L)\\}\\) are the basic ingredients of a picture of the system having spatial resolution of order \\(L\\).\nThe coarse graining operation is easily implemented on a computer. In so doing one is faced with the fact that while the underlying Ising spins can only take two possible values, the block variables \\(S_I(L)\\) have \\(L^d+1\\) possible values. Accordingly in displaying the consequences of the blocking procedure, we need a more elaborate colour convention than that used in Figure 4.1. We will associate with each block a shade of grey drawn from a spectrum ranging from black to white.\n\n\n\n\n\n\n\n\n(ai)\n\n\n\n\n\n\n\n(bi)\n\n\n\n\n\n\n\n\n\n(aii)\n\n\n\n\n\n\n\n(bii)\n\n\n\n\n\n\n\n\n\n(aiii)\n\n\n\n\n\n\n\n(biii)\n\n\n\n\n\n\n\n\n\n(aiv)\n\n\n\n\n\n\n\n(biv)\n\n\n\n\n\n\nFigure 7.1: See text for details\n\n\n\nThe results of coarse-graining configurations typical of three different temperatures are shown in Figure 7.1 and Figure 7.2. Two auxiliary operations are implicit in these results. The first operation is a length scaling: the lattice spacing on each blocked lattice has been scaled to the same size as that of the original lattice, making possible the display of correspondingly larger portions of the physical system. The second operation is a variable scaling: loosely speaking, we have adjusted the scale (‘contrast’) of the block variable so as to match the spectrum of block variable values to the spectrum of shades at our disposal.\nConsider first a system marginally above its critical point at a temperature \\(T\\) chosen so that the correlation length \\(\\xi\\) is approximately 6 lattice spacing units. A typical arrangement (without coarse-graining) is shown in Figure 7.1(ai). The succeeding panels, (aii) and (aiii), show the result of coarse-graining with block sizes \\(L=4\\) and \\(L=8\\), respectively. A clear trend is apparent. The coarse-graining amplifies the consequences of the small deviation of \\(T\\) from \\(T_c\\). As \\(L\\) is increased, the ratio of the size of the largest configurational features (\\(\\xi\\)) to the size of the smallest (\\(L\\)) is reduced. The ratio \\(\\xi/L\\) provides a natural measure of how ‘critical’ is a configuration. Thus the coarse-graining operation generates a representation of the system that is effectively less critical the larger the coarse-graining length. The limit point of this trend is the effectively fully disordered arrangement shown in Figure 7.1(aiii) and in an alternative form in Figure 7.1(aiv), which shows the limiting distribution of the coarse grained variables, averaged over many realizations of the underlying configurations: the distribution is a Gaussian which is narrow (even more so the larger the \\(L\\) value) and centred on zero. This limit is easily understood. When the system is viewed on a scaled \\(L\\) larger than \\(\\xi\\), the correlated microstructure is no longer explicitly apparent; each coarse-grained variable is essentially independent of the others.\nA similar trend is apparent below the critical point. Figure 7.1(bi) show a typical arrangement at a temperature \\(T&lt;T_c\\) such that again \\(\\xi\\) is approximately \\(6\\) lattice spacings. Coarse-graining with \\(L=4\\) and \\(L=8\\) again generates representations which are effectively less critical as shown in panels (bii) and (biii)). This time the coarse-graining smoothes out the microstructure which makes the order incomplete. The limit point of this procedure is a homogeneously ordered arrangement in which the block variables have a random (Gaussian) distribution centred on the order parameter (Figure 7.1(biv)).\nConsider now the situation at the critical point. Figure 7.2(ai) shows a typical arrangement; panels (aii) and (aiii) show the results of coarse-graining with \\(L=4\\) and \\(L=8\\) respectively. Since the \\(\\xi\\) is as large as the system itself the coarse graining does not produce less critical representations of the physical system: each of the figures displays structure over all length scales between the lower limit set by \\(L\\) and the upper limit set by the size of the display itself. A limiting trend is nevertheless apparent. Although the \\(L=4\\) pattern is qualitatively quite different from the pattern of the local variables, the \\(L=4\\) and \\(L=8\\) patterns display qualitatively similar features. These similarities are more profound than is immediately apparent. A statistical analysis of the spectrum of \\(L=4\\) configurations (generated as the local variables evolve in time) shows (Figure 7.2(iv)) that it is almost identical to that of the \\(L=8\\) configurations (given the block variable scaling). The implication of this limiting behaviour is clear: the patterns formed by the ordering variable at criticality look the same (in a statistical sense) when viewed on all sufficiently large length scales.\n\n\n\n\n\n\n\n\n(ai)\n\n\n\n\n\n\n\n(bi)\n\n\n\n\n\n\n\n\n\n(aii)\n\n\n\n\n\n\n\n(bii)\n\n\n\n\n\n\n\n\n\n(aiii)\n\n\n\n\n\n\n\n(biii)\n\n\n\n\n\n\n\n\n\n(iv)\n\n\n\n\n\n\nFigure 7.2: See text for details\n\n\n\nLet us summarize. Under the coarse-graining operation there is an evolution or flow of the system’s configuration spectrum. The flow tends to a limit, or fixed point, such that the pattern spectrum does not change under further coarse-graining. These scale-invariant limits have a trivial character for \\(T&gt;T_c\\), (a perfectly disordered arrangement) and \\(T&lt; T_c\\), (a perfectly ordered arrangement). The hallmark of the critical point is the existence of a scale-invariant limit which is neither fully ordered nor fully disordered but which possesses structure on all length scales.\nA nice illustration of these points made by my former postdoc Douglas Ashton can be viewed here.",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Universality and renormalization group theory</span>"
    ]
  },
  {
    "objectID": "phase-transitions/rg.html#universality-and-scaling",
    "href": "phase-transitions/rg.html#universality-and-scaling",
    "title": "7  Universality and the Renormalisation Group Theory of Critical Phenomena",
    "section": "7.3 Universality and Scaling",
    "text": "7.3 Universality and Scaling\nEquipped with the coarse-graining technique, we now address the universality phenomenon. We aim to understand how it is that systems that are different microscopically can nevertheless display critical point behaviour which (in certain respects) is quantitatively identical.\nTo obtain initial insight we introduce a spin-1 Ising model in which the spins take on three values (\\(s_i=1,0,-1\\)), in contrast to the two values (\\(s_i=1,-1\\)) of the spin-1/2 Ising model. The two models have properties which are different: for example, \\(T_c\\) for the three-state model is some \\(30\\%\\) lower than that of the two-state model (for the same coupling \\(J\\)). However, there is abundant evidence that the two models have the same universal properties.\nLet us explore what is the same and what is different in the configurations of the two models at criticality. The configurations of the local variables \\(s_i\\) are clearly qualitatively different for the two models. Now consider the coarse-grained configurations (with \\(L=4\\) and \\(L=8\\) respectively) for the three-state model at the critical point. We have already seen that the coarse-graining operation bears the configuration spectrum of the critical two-state Ising model to a non-trivial scale-invariant limit. It is scarcely surprising that the same is true for the three-state model. What is remarkable is that the two limits are the same! This is expressed in Figure 7.2(iv), which shows the near coincidence of the distribution of block variables (grey-levels) for the two different coarse-graining lengths. Thus the coarse-graining erases the physical differences apparent in configurations where the local behaviour is resolvable, and exposes a profound configurational similarity.\n\n7.3.1 Fluid-magnet universality\nLet us now turn to fluid-magnet universality. In a magnet, the relevant configurations are those formed by the coarse-grained magnetisation (the magnetic moment averaged over a block of side \\(L\\)). In a fluid, the relevant configurations are those of the coarse-grained density (the mass averaged over a block if side \\(L\\)) or more precisely, its fluctuation from its macroscopic average (Figure 7.3). The patterns in the latter (bubbles of liquid or vapour) may be matched to pattern in the former (microdomains of the magnetisation), given appropriate scaling operations to camouflage the differences between the length scales and the differences between the variable scales.\n\n\n\n\n\n\nFigure 7.3: Schematic representation of the coarse graining operation via which the universal properties of fluids and magnets may be exposed.\n\n\n\nThe results is illustrated in Figure 7.4.\n\n\n\n\n\n\n\n\n2D critical Ising model and 2d critical Lennard-Jones fluid at small lengthscales\n\n\n\n\n\n\n\n\n\nSame models as above, but viewed at large lengthscales\n\n\n\n\n\n\nFigure 7.4: Snapshot configurations of the 2D critical Ising model (left) and the 2D critical Lennard-Jones fluid (right). When viewed on sufficiently large length scales the configurational patterns appear universal and self similar.\n\n\n\nA movie in which we progressively zoom out shows how the loss of microscopic details reveals the large lengthscale universal features.",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Universality and renormalization group theory</span>"
    ]
  },
  {
    "objectID": "phase-transitions/rg.html#near-critical-scaling",
    "href": "phase-transitions/rg.html#near-critical-scaling",
    "title": "7  Universality and the Renormalisation Group Theory of Critical Phenomena",
    "section": "7.4 Near critical scaling",
    "text": "7.4 Near critical scaling\nThe similarity of coarse-grained configurations of different systems is not restricted to the critical temperature itself. Suppose we have a two state spin model and a three state spin model each somewhat above their critical points at reduced temperature \\(t\\). The two systems will have somewhat different correlation lengths, \\(\\xi_1\\) and \\(\\xi_2\\) say. Suppose however, we choose coarse-graining lengths \\(L_1\\) for \\(L_2\\) for the two models such that \\(\\xi_1/L_1=\\xi_2/L_2\\). We adjust the scales of the block variables (our grey level control) so that the typical variable value is the same for the two systems. We adjust the length scale of the systems (stretch or shrink our snapshots) so that the sizes of the minimum-length-scale structure (set by \\(L_1\\) and \\(L_2\\)) looks the same for each system. Precisely what they look like depends upon our choice of \\(\\xi/L\\).",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Universality and renormalization group theory</span>"
    ]
  },
  {
    "objectID": "phase-transitions/rg.html#sec-unipics",
    "href": "phase-transitions/rg.html#sec-unipics",
    "title": "7  Universality and the Renormalisation Group Theory of Critical Phenomena",
    "section": "7.5 Universality classes",
    "text": "7.5 Universality classes\nCoarse graining does not erase all differences between the physical properties of critical systems. Differences in the space dimension \\(d\\) of two critical systems will lead to different universal properties such as critical exponents. Thus, for instance, the critical exponents of the 2D magnet, match those of the 2d fluid, but they are different to those of 3d magnets and fluids.\n\n\n\n\n\n\n\n\n\n\\(d=2\\)\n\\(d=3\\)\n\n\n\n\nCritical temperature\n0.5673\n0.75\n\n\nOrder parameter exponent \\(\\beta\\)\n\\(\\tfrac{1}{8}\\)\n\\(0.325 \\pm 0.001\\)\n\n\nSusceptibility exponent \\(\\gamma\\)\n\\(\\tfrac{7}{4}\\)\n\\(1.24 \\pm 0.001\\)\n\n\nCorrelation length exponent \\(\\nu\\)\n\\(1\\)\n\\(0.63 \\pm 0.001\\)\n\n\n\nIn fact the space dimension is one of a small set of qualitative features of a critical system which are sufficiently deep-seated to survive coarse graining and which together serve to define the system’s universal behaviour, or universality class. The constituents of this set are not all identifiable a priori. They include the number of components \\(n\\) of the order parameter. Up to now, we have only considered order parameters which are scalar (for a fluid the density, for a magnet the magnetisation), for which \\(n=1\\). In some ferromagnets, the order parameter may have components along two axes, or three axes, implying a vector order parameter, with \\(n=2\\) (the solcalled XY model) or \\(n=3\\) (Heisenberg model), respectively. It is clear that the order-parameter \\(n\\)-value will be reflected in the nature of the coarse-grained configurations, and thus in the universal observables they imply.\nA third important feature which can change the universality class of a critical system is the range of the interaction potential between its constituent particles. Clearly for the Ising model, interactions between spins are inherently nearest neighbour in character. Most fluids interact via dispersion forces (such as the Lennard-Jones potential) which is also short ranged owing to the \\(r^{-6}\\) attractive interaction. However some systems have much longer ranged interactions. Notable here are systems of charged particles which interact via a Coulomb potential. The long ranged nature of the Coulomb potential (which decays like \\(r^{-1}\\)) means that charged systems often do not have the same critical exponents as the Ising model and fluid.",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Universality and renormalization group theory</span>"
    ]
  },
  {
    "objectID": "phase-transitions/rg.html#critical-exponents",
    "href": "phase-transitions/rg.html#critical-exponents",
    "title": "7  Universality and the Renormalisation Group Theory of Critical Phenomena",
    "section": "7.6 Critical exponents",
    "text": "7.6 Critical exponents\nWe consider now how the critical exponents, may be computed via the coarse-graining procedure. In what follows we will refer only to the behaviour of a single typical coarse grained variable, which we shall denote \\(S(L)\\). We suppose that \\(t\\) is sufficiently small that \\(\\xi \\gg\nL_\\textrm{ min}\\). Universality and scaling may be expressed in the claim that, for any \\(L\\) and \\(t\\), scale factors \\(a(L)\\) and \\(b(L)\\) may be found such that the probability distribution \\(p(S(L),t)\\) can be written in the form\n\\[\np(S(L),t)=b(L)\\tilde{p}(b(L)S(L),a(L)t)\n\\tag{7.2}\\] where \\(\\tilde{p}\\) is a function unique to a universality class. The role of the scale factors \\(a\\) and \\(b\\) is to absorb the basic non-universal scales identified in Section 7.2. The critical exponents are implicit in the \\(L\\)-dependence of these scale factors. Specifically one finds:\n\\[\n\\begin{aligned}\na(L) & =a_0L^{1/\\nu} \\\\\nb(L) & =b_0L^{\\beta/\\nu}\n\\end{aligned}\n\\tag{7.3}\\] where the amplitudes \\(a_0\\) and \\(b_0\\) are system specific (non-universal) constants.\nThese results state that the critical exponents (in the form \\(1/\\nu\\) and \\(\\beta/\\nu\\)) characterize the ways in which the configuration spectrum evolves under coarse-graining. Consider, first the exponent ratio \\(\\beta/\\nu\\). Precisely at the critical point, there is only one way in which the coarse-grained configurations change with \\(L\\): the overall scale of the coarse-grained variable (the black-white contrast in our grey scale representation) is eroded with increasing \\(L\\). Thus the configurations of coarse-graining length \\(L_1\\) match those of a larger coarse-graining length \\(L_2\\) only if the variable scale in the latter configurations is amplified. The required amplification follows from Equation 7.2 and and Equation 7.3: it is\n\\[\n\\frac{b(L_2)}{b(L_1)}=\\left(\\frac{L_2}{L_1}\\right)^{\\beta/\\nu}\\:.\n\\] The exponent ratio \\(\\beta/\\nu\\) thus controls the rate at which the scale of the ordering variable decays with increasing coarse-graining length.\nConsider now the exponent \\(1/\\nu\\). For small but non-zero reduced temperature (large but finite \\(\\xi\\)) there is second way in which the configuration spectrum evolves with \\(L\\). As noted previously, coarse graining reduces the ratio of correlation length to coarse-graining length, and results in configurations with a less critical appearance. More precisely, we see from Equation 7.2 that increasing the coarse graining length from \\(L_1\\) to \\(L_2\\) while keeping the reduced temperature constant has the same effect on the configuration spectrum as keeping coarse-graining length constant which amplifying the reduced temperature \\(t\\) by a factor\n\\[\n\\frac{a(L_2)}{a(L_1)}=\\left(\\frac{L_2}{L_1}\\right)^{1/\\nu}\\:.\n\\] One may think of the combination \\(a(L)t\\) as a measure of the effective reduced temperature of the physical system viewed with resolution length \\(L\\). The exponent \\(1/\\nu\\) controls the rate at which the effective reduced temperature flows with increasing coarse-graining length.",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Universality and renormalization group theory</span>"
    ]
  },
  {
    "objectID": "phase-transitions/rg.html#sec-fss",
    "href": "phase-transitions/rg.html#sec-fss",
    "title": "7  Universality and the Renormalisation Group Theory of Critical Phenomena",
    "section": "7.7 Finite-size scaling",
    "text": "7.7 Finite-size scaling\nWe can exploit the fact that the scale factors \\(a(L)\\) and \\(b(L)\\) depend on critical exponents to estimate the values of these exponents using computer simulation. Consider the average of the block variable \\(S(L)\\). Consideration of Equation 7.1 shows that this is non other than the value of the order parameter \\(Q\\), measured over a block of side \\(L\\). Thus from the definition of an average\n\\[\nQ(L,t)=\\bar {S}(L,t)=\\int S(L)p(S(L),t)dS(L)\n\\] where \\(p(S(L))\\) is the probability distribution of \\(S(L)\\).\nMaking use of the representation of Equation 7.2, we then have that\n\\[Q\n(L,t) = \\int b(L)S(L)\\tilde{p}(b(L)S(L),a(L)t)dS(L)\n\\]\nTo integrate this we need to change the integration variable from \\(S(L)\\) to \\(b(L)S(L)\\). We have \\(d(b(L)S(L))=b(L)dS(L)\\) since \\(b(L)\\) does not fluctuate. Thus \\[\n\\begin{aligned}\nQ(L,t)  & =  b^{-1}(L)\\int b(L)S(L)\\tilde{p}(b(L)S(L),a(L)t)d(b(L)S(L))\\nonumber\\\\\n        & =  b^{-1}(L)f(a(L)t)\\nonumber\\\\\n       & =  b_0L^{-\\beta/\\nu}f(a_0L^{1/\\nu}t)\n\\end{aligned}\n\\]\nwhere \\(f\\) is a universal function (defined as the first moment of \\(\\tilde{p}(x,y)\\) with respect to \\(y\\)).\nThe above results provide a method for determining the critical exponent ratios \\(\\beta/\\nu\\) and \\(1/\\nu\\) via computer simulations of near critical systems. For instance, at the critical point (\\(t=0\\)) and for finite block size, \\(Q(L,0)\\) will not be zero (the \\(T\\) at which Q vanishes for finite \\(L\\) is above the true \\(T_c\\), cf. Section 6.2. However, we know that its value must vanish in the limit of infinite \\(L\\); it does so like\n\\[Q(L,0)=b_0L^{-\\beta/\\nu}f(0)\\equiv Q_0L^{-\\beta/\\nu}\\]\nThus by studying the critical point \\(L\\) dependence of \\(Q\\) we can estimate \\(\\beta/\\nu\\). A similar approach in which we study two block sizes \\(L\\), and tune \\(t\\) separately in each case so that the results for \\(QL^{\\beta/\\nu}\\) are identical provides information on the value of \\(1/\\nu\\).",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Universality and renormalization group theory</span>"
    ]
  },
  {
    "objectID": "phase-transitions/rg.html#summary-of-main-points",
    "href": "phase-transitions/rg.html#summary-of-main-points",
    "title": "7  Universality and the Renormalisation Group Theory of Critical Phenomena",
    "section": "7.8 Summary of main points",
    "text": "7.8 Summary of main points\nAs this is quite a long chapter let us summarise the main points:\n\nLimitations of conventional theories: Mean field theories and the scaling hypothesis are insufficient in the critical region due to their neglect of correlations across all relevant length scales.\nCritical region characteristics: Near-critical systems exhibit correlated microstructure on all length scales up to the correlation length. The complexity of this structure makes both analytical and computational study challenging.\nRelevant length scales:\n\nCorrelation length (\\(\\xi\\))\nMinimum microscopic scale (\\(L_\\textrm{min}\\))\nMacroscopic system size (\\(L_\\textrm{max}\\))\n\nWindow Condition for criticality: The true critical regime satisfies \\(L_\\textrm{max} \\gg \\xi \\gg L_\\textrm{min}\\), encompassing a broad range of scales where complex, often fractal-like, structures are present.\nRenormalisation Group (RG) methodology: RG involves the stepwise elimination of degrees of freedom by coarse-graining the system over increasing length scales. A fourth scale, \\(L\\), represents the resolution at which the system is described.\nEffect of coarse-graining: Coarse-graining changes the effective reduced temperature, captured by the relation \\(a(L)t\\), where \\(a(L)\\) scales with \\(L\\) as \\(L^{1/\\nu}\\). This helps describe how critical configurations evolve with resolution.\nUniversality:\n\nCoarse-graining reveals that microscopically different systems can exhibit identical critical behavior when observed at large scales.\nThe concept of universality explains why disparate systems, such as magnets and fluids, can show the same critical exponents and scaling laws.\nCritical behavior depends primarily on general features like dimensionality and symmetry, rather than microscopic details.\n\nFinite-Size scaling:\n\nThe average block variable \\(Q(L,t)\\) is related to block size \\(L\\) and reduced temperature \\(t\\) through scaling relations. Computer simulations exploit this to extract scaling functions and the values of critical exponents.",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Universality and renormalization group theory</span>"
    ]
  },
  {
    "objectID": "phase-transitions/rg.html#addendum-the-effective-coupling-viewpoint-of-the-renormalization-group-non-examinable",
    "href": "phase-transitions/rg.html#addendum-the-effective-coupling-viewpoint-of-the-renormalization-group-non-examinable",
    "title": "7  Universality and the Renormalisation Group Theory of Critical Phenomena",
    "section": "7.9 Addendum: The effective coupling viewpoint of the renormalization group (non examinable)",
    "text": "7.9 Addendum: The effective coupling viewpoint of the renormalization group (non examinable)\n\n\n\n\n\n\nNotes for those interested in a different perspective on RG theory.\n\n\n\n\n\nLet us begin by returning to our fundamental Equation 2.1, which we rewrite as\n\\[p = Z^{-1}e^{-{\\cal H}}\\] where \\({\\cal H}\\equiv E/k_BT\\).\nThe first step is then to imagine that we generate, by a computer simulation procedure for example, a sequence of configurations with relative probability \\(\\exp(-{\\cal H})\\). We next adopt some coarse-graining procedure which produces from these original configurations a set of coarse-grained configurations. We then ask the question: what is the energy function \\({\\cal H}^\\prime\\) of the coarse-grained variables which would produce these coarse-grained configurations with the correct relative probability \\(\\exp(-{\\cal H}^\\prime)\\)? Clearly the form of \\({\\cal H}^\\prime\\) depends on the form of \\({\\cal H}\\) thus we can write symbolically\n\\[{\\cal H}^\\prime=R({\\cal H})\\]\nThe operation \\(R\\), which defines the coarse-grained configurational energy in terms of the microscopic configurational energy function is known as a renormalisation group transformation (RGT). What it does is to replace a hard problem by a less hard problem. Specifically, suppose that our system is near a critical point and that we wish to calculate its large-distance properties. If we address this task by utilizing the configurational energy and appealing to the basic machinery of statistical mechanics set out in Equation 2.1 and Equation 2.2, the problem is hard. It is hard because the system has fluctuations on all the (many) length scales intermediate between the correlation length \\(\\xi\\) and the minimum length scale \\(L_\\textrm{min}\\).\nHowever, the task may instead be addressed by tackling the coarse-grained system described by the energy \\({\\cal H}^\\prime\\). The large-distance properties of this system are the same as the large-distance properties of the physical system, since coarse-graining operation preserves large-scale configurational structure. In this representation the problem is a little easier: while the \\(\\xi\\) associated with \\({\\cal H}^\\prime\\) is the same as the \\(\\xi\\) associated with \\({\\cal H}\\), the minimum length scale of \\({\\cal H}^\\prime\\) is bigger than that of \\({\\cal H}\\). Thus the statistical mechanics of \\({\\cal H}^\\prime\\) poses a not-quite-so-many-length-scale problem, a problem which is effectively a little less critical and is thus a little easier to solve. The benefits accruing from this procedure may be amplified by repeating it. Repeated application of \\(R\\) will eventually result in a coarse- grained energy function describing configurations in which the \\(\\xi\\) is no bigger than the minimum length scale. The associated system is far from criticality and its properties may be reliably computed by any of a wide variety of approximation schemes. These properties are the desired large-distance properties of the physical system. As explicit reference to fluctuations of a given scale is eliminated by coarse-graining, their effects are carried forward implicitly in the parameters of the coarse-grained energy.\nIn order to setup the framework for a simple illustrative example, let is return to the lattice Ising model for which the energy function depended only on the product of nearest neighbour spins. The coefficient of this product in the energy is the exchange coupling, \\(J\\). In principle, however, other kinds of interactions are also allowed; for example, we may have a product of second neighbour spins with strength \\(J_2\\) or, perhaps, a product of four spins (at sites forming a square whose side is the lattice spacing), with strength \\(J_3\\). Such interactions in a real magnet have their origin in the quantum mechanics of the atoms and electrons and clearly depend upon the details of the system. For generality therefore we will allow a family of exchange couplings \\(J_1\\),\\(J_2\\),\\(J_3,\\dots\\), or \\(J_a, a =\n1,2,\\dots\\) In reduced units, the equivalent coupling strengths are \\(K_a =J_a/k_BT\\). Their values determine uniquely the energy for any given configuration.\n\nWe note that it is not only useful to allow for arbitrary kinds of interactions: if we wish to repeat the transformation several (indeed many) times, it is also necessary because even if we start with only the nearest neighbour coupling in \\({\\cal H}\\) the transformation will in general produce others in \\({\\cal H}^\\prime\\).\n\nNow consider the coarse-graining procedure. Let us suppose that this procedure takes the form of a ‘majority rule’ operation in which the new spins are assigned values \\(+1\\) or \\(-1\\) according to the signs of the magnetic moments of the blocks with which they are associated. The new energy function \\({\\cal H}^\\prime\\) will be expressible in terms of some new coupling strengths \\(K^\\prime\\) describing the interactions amongst the new spin variables (and thus, in effect, the interactions between blocks of the original spin variables). The RGT simply states that these new couplings depend on the old couplings: \\(K_1^\\prime\\) is some function \\(f_1\\) of all the original couplings, and generally\n\\[K^\\prime_a=f_a(K_1,K_2,\\dots) =f_a(\\mathbf {K}),\\quad a= 1, 2,\\dots\n\\tag{7.4}\\] where K is shorthand for the set \\(K_1, K_2,\\dots\\)\n\n7.9.1 A simple example\nThis example illustrates how one can perform the RG transformation Equation 7.4 directly, without recourse to a ‘sequence of typical configurations’. The calculation involves a very crude approximation which has the advantage that it simplifies the subsequent analysis.\n\n\n\n\n\n\nFigure 7.5: Coarse graining by decimation. The spins on the original lattice are divided into two sets \\(\\{s^\\prime\\}\\) and \\(\\{\\tilde{s}\\}\\). The \\(\\{s^\\prime\\}\\) spins occupy a lattice whose spacing is twice that of the original. The effective coupling interaction between the \\(\\{s^\\prime\\}\\) spins is obtained by performing the configurational average over the \\(\\{\\tilde{s}\\}\\)\n\n\n\nConsider an Ising model in two dimensions, with only nearest neighbour interactions as shown in Figure 7.5. We have divided the spins into two sets, the spins \\(\\{s^\\prime\\}\\) form a square lattice of spacing \\(2\\), the others being denoted by \\(\\{\\tilde{s}\\}\\). One then defines an effective energy function \\({\\cal H^\\prime}\\) for the \\(s^\\prime\\) spins by performing an average over all the possible arrangements of the \\(\\tilde{s}\\) spins\n\\[\n\\exp(-{\\cal H}^\\prime)=\\sum_{\\{\\tilde {s}\\}} \\exp(-{\\cal H}).\n\\tag{7.5}\\]\nThis particular coarse-graining scheme is called ‘decimation’ because a certain fraction (not necessarily one-tenth!) of spins on the lattice is eliminated. This formulation of a new energy function realizes two basic aims of the RG method: the long-distance physics of the ‘original’ system, described by \\({\\cal H}\\), is contained in that of the ‘new’ system, described by \\({\\cal H}^\\prime\\) (indeed the partition functions are the same as one can see by summing both sides over \\(s^\\prime\\)) and the new system is further from critically because the ratio of \\(\\xi\\) to lattice spacing (‘minimum length scale’) has been reduced by a factor of \\(1/2\\) (the ratio of the lattice spacings of the two systems). We must now face the question of how to perform the configuration sum in Equation 7.5. This cannot in general be done exactly, so we must resort to some approximation scheme. The particular approximation which we invoke is the high temperature series expansion. In its simplest mathematical form, since \\({\\cal H}\\) contains a factor \\(1/k_BT\\), it involves the expansion of \\(\\exp(-{\\cal H})\\) as a power series:\n\\[\\exp(-{\\cal H}/k_BT)=1-{\\cal H}/k_BT +\\frac{1}{2!}({\\cal H}/k_BT)^2+.....\\]\nWe substitute this expansion into the right hand side of Equation 7.5 and proceed to look for terms which depend on the \\(s^\\prime\\) spins after the sum over the possible arrangements of the \\(\\tilde{s}\\) spins is performed. This sum extends over all the possible (\\(\\pm 1\\)) values of all the \\(\\tilde{s}\\) spins. The first term (the 1) in the expansion of the exponential is clearly independent of the values of the \\(s^\\prime\\) spins. The second term (\\({\\cal H}\\)) is a function of the \\(s^\\prime\\) spins, but gives zero when the sum over the \\(s^\\prime\\) spins is performed because only a single factor of any \\(s^\\prime\\) ever appears, and \\(+ 1 - 1 = 0\\). The third term (\\({\\cal H}^2/2\\)) does contribute. If one writes out explicitly the form of \\({\\cal H}^2/2\\) one finds terms of the form \\(K^2s_1^\\prime\\tilde{s}\\tilde{s}s_2^\\prime=K^2s_1^\\prime s_2^\\prime\\), where \\(s_1^\\prime\\) and \\(s_2^\\prime\\) denote two spins at nearest neighbour sites on the lattice of \\(s^\\prime\\) spins and \\(\\tilde{s}\\) is the spin (in the other set) which lies between them. Now, in the corresponding expansion of the left hand side of Equation 7.5, we find terms of the form \\(K^\\prime s_1^\\prime s_2^\\prime\\), where \\(K^\\prime\\) is the nearest neighbour coupling for the \\(s^\\prime\\) spins. We conclude (with a little more thought than we detail here) that\n\\[\nK^\\prime=K^2\n\\tag{7.6}\\]\nOf course many other terms and couplings are generated by the higher orders of the high temperature expansion and it is necssary to include these if one wishes reliable values for the critical temperature and exponents, However, our aim here is to use this simple calculation to illustrate the RG method. Let us therefore close our eyes, forget about the higher order terms and show how the RGT Equation 7.6 can be used to obtain information on the phase transition.\n\n\n\n\n\n\nFigure 7.6: Coupling flow under the decimation transformation described in the text.\n\n\n\nThe first point to note is that that mathematically Equation 7.6 has the fixed point \\(K^*= 1\\); if \\(K= 1\\) then the new effective coupling \\(K^\\prime\\) has the same value \\(1\\). Further, if \\(K\\) is just larger than \\(1\\), then \\(K^\\prime\\) is larger than \\(K\\), i.e. further away from \\(1\\). Similarly, if \\(K\\) is less than \\(1\\), \\(K^\\prime\\) is less than \\(K\\). We say that the fixed point is unstable: the flow of couplings under repeated iteration of Equation 7.6 is away from the fixed point, as illustrated in Figure 7.6. The physical significance of this is as follows: suppose that the original system is at its critical point so that the ratio of \\(\\xi\\) to lattice spacing is infinite. After one application of the decimation transformation, the effective lattice spacing has increased by a factor of two, but this ratio remains infinite; the new system is therefore also at its critical point. Within the approximations inherent in Equation 7.6, the original system is an Ising model with nearest neighbour coupling \\(K\\) and the new system is an Ising model with nearest neighbour coupling \\(K^\\prime\\). If these two systems are going to be at a common critically, we must identify \\(K^\\prime=\nK\\). The fixed point \\(K^*= 1\\) is therefore a candidate for the critical point \\(K_c\\), where the phase transition occurs. This interpretation is reinforced by considering the case where the original system is close to, but not at, criticality. Then \\(\\xi\\) is finite and the new system is further from critically because the ratio of \\(\\xi\\) to lattice spacing is reduced by a factor of two. This instability of a fixed point to deviations of \\(K\\) from \\(K^*\\) is a further necessary condition for its interpretation as a critical point of the system. In summary then we make the prediction\n\\[\nK_c=J/k_BT_c=1\n\\tag{7.7}\\]\nWe can obtain further information about the behaviour of the system close to its critical point. In order to do so, we rewrite the transformation (Equation 7.6) in terms of the deviation of the coupling from its fixed point value. A Taylor expansion of the function \\(K^\\prime=K^2\\) yields\n\\[\n\\begin{aligned}\nK^\\prime =& (K^*)^2 +(K-K^*)\\left.\\frac{\\partial K^\\prime}{\\partial K}\\right|_{K=K^*}+\\frac{1}{2}(K-K^*)^2\\left.\\frac{\\partial^2 K^\\prime}{\\partial K^2}\\right|_{K=K^*}+\\ldots\\nonumber\\\\\nK^\\prime - K^* =& 2 (K - K^*)+ (K - K^*)^2\n\\end{aligned}\n\\]\nwhere in the second line we have used the fact that the first derivative evaluates to \\(2K^*=2\\) and \\((K^*)^2=K^*\\).\nFor a system sufficiently close to its critical temperature the final term can be neglected. The deviation of the coupling from its fixed point (critical) value is thus bigger for the new system than it is for the old by a factor of two. This means that the reduced temperature is also bigger by a factor of two:\n\\[t^\\prime= 2t\\]\nBut \\(\\xi\\) (in units of the appropriate lattice spacing) is smaller by a factor of \\(1/2\\):\n\\[\\xi^\\prime= \\xi/2\\]\nThus, when we double \\(t\\), we halve \\(\\xi\\), implying that\n\\[\\xi\\propto t^{-1}\\]\nfor \\(T\\) close to \\(T_c\\). Thus we see that the RGT predicts scaling behaviour with calculable critical exponents. In this simple calculation we estimate the critical exponent \\(\\nu=1\\) for the square lattice Ising model. This prediction is actually in agreement with the exactly established value. The agreement is fortuitous- the prediction in Eq. refeq:Kc for \\(K_c\\), is larger than the exactly established value by a factor of more than two. In order to obtain reliable estimates more sophisticated and systematic methods must be used.\nThe crude approximation in the calculation above produced a transformation, Equation 7.6, involving only the nearest neighbour coupling, with the subsequent advantages of simple algebra. We pay a penalty for this simplicity in two ways: the results obtained for critical properties are in rather poor agreement with accepted values, and we gain no insight into the origin of universality.\n\n\n7.9.2 Universality and scaling\nIn order to expose how universality can arise, we should from the start allow for several different kinds of coupling \\(J_a\\), and show how the systems with different \\(J_a\\) can have the same critical behaviour.\n\n\n\n\n\n\nFigure 7.7: General flow in coupling space\n\n\n\nFigure 7.7 is a representation of the space of all coupling strengths \\(K_a\\) in the energy function \\({\\cal H}/k_BT\\). This is of course actually a space of infinite dimension, but representing three of these, as we have done, enables us to illustrate all the important aspects. First let us be clear what the points in this space represent. Suppose we have some magnetic material which is described by a given set of exchange constants \\(J_1,J_2,J_3.....\\) As the temperature \\(T\\) varies, the coupling strengths \\(K_a=J_a/k_BT\\) trace out a straight line, or ray, from the origin of the space in the direction (\\(J_1,J_2,J_3 ....\\) ). Points on this ray close to the origin represent this magnet at high temperatures, and conversely points far from the origin represent the magnet at low temperatures. The critical point of the magnet is represented by a specific point on this ray, \\(K_a=\nJ_a/k_BT, a= 1,2,\\dots\\) The set of critical points on all of the possible rays forms a surface, the critical surface. Formally, it is defined by the set of all possible models (of the Ising type) which have infinite \\(\\xi\\). It is shown schematically as the shaded surface in Figure 7.7. (In the figure it is a two-dimensional surface; more generally it has one dimension less than the full coupling constant space, dividing all models into high and low temperature phases.)\nOur immediate goal then is to understand how the RGT can explain why different physical systems near this critical surface have the same behaviour. Let us turn now to the schematic representation of the RG flow in Figure 7.7. Suppose we start with a physical system, with coupling strengths \\(K_a,  a= 1,2, \\dots\\). What the RGT does is generate a new point in the figure, at the coupling strengths \\(K_a^{(1)}=f_a(\\mathbf {K})\\); these are the couplings appearing in the effective energy function describing the coarse-grained system. If we repeat the transformation, the new energy function has coupling strengths \\(K_a^{(2)}=f_a(\\mathbf {K})\\). Thus repeated application of the transformation generates a flow of points in the figure: \\(\\mathbf{K}\\to\nK^{(1)}\\to\\dots\\to K^{(n)}\\) where the superscript (\\(n\\)) labels the effective couplings after \\(n\\) coarse-graining steps. if the change in coarse-graining scale is \\(b\\) (\\(&gt; 1\\)) at each step, the total change in coarse-graining scale is \\(b^n\\) after \\(n\\) steps. In the process, therefore, the ratio of \\(\\xi\\) to coarse-graining scale is reduced by a factor of \\(b^{-n}\\). The dots in Figure 7.7 identify three lines of RG flow starting from three systems differing only in their temperature. (The flow lines are schematic but display the essential features revealed in detailed calculations.)\nConsider first the red dots which start from the nearest neighbour Ising model at its critical point. The ratio of \\(\\xi\\) to coarse-graining scale is reduced by a factor b at each step, but, since it starts infinite, it remains infinite after any finite number of steps. In this case we can in principle generate an unbounded number of dots, \\(\\mathbf{ K^{(1)}, K^{(2)},\\dots,K^{(n)}}\\), all of which lie in the critical surface. The simplest behaviour of such a sequence as \\(n\\) increases is to tend to a limit, \\(K^*\\), say. In such a case\n\\[K^*_a=f_a(K^*)~~~~ a= 1,2 .....\\]\nThis point \\(\\mathbf{K^*} \\equiv K_1^*, K_2^*, \\dots\\) is therefore a fixed point which lies in the critical surface.\nBy contrast, consider the same magnet as before, now at temperature \\(T\\) just greater than \\(T_c\\), its couplings \\(K_a\\), will be close to the first red dot (in fact they will be slightly smaller) and so will the effective couplings \\(K_a^{(1)},K_2^{(2)},\\dots\\) of the corresponding coarse-grained systems. The new flow will therefore appear initially to follow the red dots towards the same fixed point. However, the flow must eventually move away from the fixed point because each coarse-graining now produces a model further from criticality. The resulting flow is represented schematically by one set of black dots. The other set of black dots shows the expected flow starting from the same magnet slightly below its critical temperature.\nWe are now in a position to understand both universality and scaling within this framework. We will suppose that there exists a single fixed point in the critical surface which sucks in all flows starting from a point in that surface. Then any system at its critical point will exhibit large-length scale physics (large-block spin behaviour) described by the single set of fixed point coupling constants. The uniqueness of this limiting set of coupling constants is the essence of critical point universality. It is, of course, the algebraic counterpart of the unique limiting spectrum of coarse-grained configurations, discussed in Section 7.5. Similarly the scale-invariance of the critical point configuration spectrum (viewed on large enough length scales) is expressed in the invariance of the couplings under iteration of the transformation (after a number of iterations large enough to secure convergence to the fixed point).\nTo understand the behaviour of systems near but not precisely at critically we must make a further assumption (again widely justified by explicit studies). The flow line stemming from any such system will, we have argued, be borne towards the fixed point before ultimately deviating from it after a number of iterations large enough to expose the system’s noncritical character. We assume that (as indicated schematically in the streams of red and blue lines in Figure 7.7 the deviations lie along a single line through the fixed point, the direction followed along this line differing according to the sign of the temperature deviation \\(T-T_c\\). Since any two sets of coupling constants on the line (on the same side of the fixed point) are related by a suitable coarse-graining operation, this picture implies that the large-length-scale physics of all near- critical systems differs only in the matter of a length scale. This is the essence of near-critical point universality.",
    "crumbs": [
      "Unifying concepts",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Universality and renormalization group theory</span>"
    ]
  },
  {
    "objectID": "phase-transitions/precourse-reading.html",
    "href": "phase-transitions/precourse-reading.html",
    "title": "Tools for understanding complex disordered matter",
    "section": "",
    "text": "Ensembles and free energies\nComplex disordered systems are composed of an enormous number of interacting components—typically on the order of \\(\\sim 10^{23}\\). These interactions can lead to fascinating emergent behaviour, but they also render the systems analytically intractable; it is clearly impossible to solve Newton’s equations for such vast numbers of particles. To address this difficulty, we turn to Statistical Mechanics, which you first encountered in your second year. Statistical Mechanics provides the essential framework for connecting the microscopic behaviour of individual constituents with the macroscopic thermodynamic and dynamical properties of the system as a whole.\nIn this section, we will revisit and expand upon key concepts relevant to our discussion, with particular emphasis on the free energy—a central quantity that captures the balance between energy minimisation and entropy maximisation in determining the system’s equilibrium state. If any of these ideas feel unfamiliar, you may find it useful to revise the Statistical Mechanics material from your Year 2 Thermal Physics course notes.\nStatistical mechanics can be formulated in a variety of ensembles reflecting the relationship between the system and its environment. In what follows we summarise the formalism, focussing on the case of a particle fluid. Analogous equations apply to lattice spin models (see lectures and the book by Yeomans). Key ensembles are:",
    "crumbs": [
      "Unifying concepts",
      "Precourse reading and revision"
    ]
  },
  {
    "objectID": "phase-transitions/precourse-reading.html#ensembles-and-free-energies",
    "href": "phase-transitions/precourse-reading.html#ensembles-and-free-energies",
    "title": "Tools for understanding complex disordered matter",
    "section": "",
    "text": "Microcanonical ensemble\nApplies to a system of \\(N\\) particles (or spins) in a fixed volume \\(V\\) having adiabatic walls so that the internal energy \\(E\\) is constant. Denoted as constant-\\(NVE\\). Let \\(\\Omega\\) be the number of (micro)states having the prescribed energy:\n\\[\n\\Omega=\\sum_\\textrm{all states having energy E}\n\\]\nThermodynamically, the states favored in the canonical ensemble are those that maximise the entropy:\n\\[\nS=k_B\\ln \\Omega\\: .\n\\]\nwhere \\(k_B\\) is Boltzmann’s constant The microcanonical ensemble is useful for defining the entropy, but is little used in practice.\n\n\nCanonical ensemble\nApplies to a system of \\(N\\) particles in a fixed volume \\(V\\) and coupled to a heat bath at temperature \\(T\\). Denoted as constant-\\(NVT\\). A central quantity is the partition function\n\\[\nZ_{NVT}=\\sum_\\textrm{ all states i}e^{-\\beta E_i},~~~~~\\beta=1/(k_BT)\n\\tag{1}\\] which is a weighted sum over the states. The partition function provides the normalisation constant in the probability of finding the system in a given state \\(i\\).\n\\[\nP_i=\\frac{e^{-\\beta E_i}}{Z_{NVT}}.\n\\tag{2}\\]\nThe states favored in the canonical ensemble are those that minimise the free energy:\n\\[\nF_{NVT}=-\\beta^{-1}\\ln Z_{NVT}\\:.\n\\]\n\\(F_{NVT}\\) is known as the Helmholtz free energy. Thermodynamics also supplies a relation for the Helmholtz free energy:\n\\[\nF_{NVT}=E-TS\\:,\n\\] where \\(E\\) is the average internal energy. In minimising the free energy, the system strikes a compromise between low energy and high entropy. The temperature plays the role of arbiter, favouring high entropy at high \\(T\\), and low energy at low \\(T\\). The canonical ensemble is usually used to describe systems such as magnets, or a fluid held at constant volume. It is the ensemble we shall use most in this course.\n\n\nGrand canonical ensemble\nApplies to a system with a variable number of particle in a fixed volume \\(V\\) coupled to both a heat bath at temperature \\(T\\) and a particle reservoir with chemical potential \\(\\mu\\) (which is the field conjugate to \\(N\\)). Denoted as constant-\\(\\mu VT\\).\nThe corresponding partition function is a weighted superset of the canonical one\n\\[\nZ_{\\mu VT}=\\sum_{N=0}^\\infty e^{\\beta\\mu N}Z_{NVT}\n\\] and a state probability analogous to Equation 2 holds. One can recast this in a form similar to Equation 1:\n\\[\nZ_{\\mu VT}=\\sum_{N=0}^\\infty\\:\\sum_\\textrm{all~states~i}e^{-\\beta {\\cal H}_i},\n\\tag{3}\\] where \\({\\cal H}_i=E_i-\\mu N\\) is the form of the Hamiltonian in the grand canonical ensemble.\nStatistically, the states favored in the grand canonical ensemble are those that minimise the free energy:\n\\[\nF_{\\mu VT}=-\\beta^{-1}\\ln Z_{\\mu VT}\n\\] \\(F_{\\mu VT}\\) is known as the grand potential. It can also be derived from thermodynamics, from which one finds\n\\[\nF_{\\mu VT}=E-TS-\\mu N=-pV,\n\\] where \\(p\\) is the pressure.\nThe grand canonical ensemble is usually used to describe systems such as fluid connected to a particle reservoir. Sometimes for a magnet we consider the effects of an applied magnetic field, which is analogous to working in the grand canonical ensemble: the magnetic field (which is conjugate to the magnetisation) plays a similar role to the chemical potential in a fluid.\n\n\nIsothermal-isobaric ensemble\nApplies to a system with a fixed number of particles \\(N\\) that is coupled to a heat bath at temperature \\(T\\) and a reservoir that exerts a constant pressure \\(p\\) which allows the sample volume to fluctuate. Denoted as constant-\\(NpT\\).\nThe corresponding partition function is a weighted superset of the canonical one\n\\[\nZ_{NpT}=\\int_0^\\infty dV  e^{-\\beta p V}Z_{NVT}\n\\] or \\[\nZ_{NpT}=\\int_0^\\infty dV\\:\\sum_\\textrm{i}e^{-\\beta {\\cal H}_i},\n\\tag{4}\\] where \\({\\cal H}_i=E_i+pV\\) is the form of the Hamiltonian in the constant-\\(NpT\\) ensemble. Again a state probability analogous to Equation 2 holds.\nStatistically, the states favored in the constant-\\(NpT\\) ensemble are those that minimise the free energy:\n\\[\nF_{NpT}=-\\beta^{-1}\\ln Z_{NpT}\n\\] \\(F_{NpT}\\) is known as the Gibb’s free energy (often denoted \\(G\\)). It can also be derived from thermodynamics, from which one finds\n\\[\nF_{NpT}=E-TS+pV=\\mu N\n\\]\nThe constant-\\(NpT\\) ensemble is usually used to describe systems such as a fluid subject to a variable pressure, or a magnet coupled to a magnetic field \\(H\\). In the latter case the quantity \\(HM\\) plays the role of \\(pV\\) and\n\\[\nF_{NpT}=E-TS-MH\\:,\n\\] with \\(M\\) the total magnetisation.",
    "crumbs": [
      "Unifying concepts",
      "Precourse reading and revision"
    ]
  },
  {
    "objectID": "phase-transitions/precourse-reading.html#from-free-energies-to-observables",
    "href": "phase-transitions/precourse-reading.html#from-free-energies-to-observables",
    "title": "Tools for understanding complex disordered matter",
    "section": "From free energies to observables",
    "text": "From free energies to observables\nFree energies are not directly observable quantities. However, all physical observables can be expressed in terms of derivatives of the free energy. One can derive the appropriate relations either from Thermodynamics, or the corresponding statistical mechanics (Revise your year-2 Thermal Physics notes on this if necessary). As an example let us consider a fluid in the isothermal-isobaric ensemble for which the appropriate free energy is \\(F_{NpT}=E-TS+pV\\), and where the volume fluctuates in response to the prescribed pressure. We shall seek an expression for the average volume in terms of the free energy. First lets us take the thermodynamic route. Differentiating the free energy and applying the chain rule we have:\n\\[\ndF=dE-TdS-sdT+pdV+VdP\\:.\n\\] But from the first law of thermodynamics, \\(dE=TdS-pdV\\), so\n\\[\ndF=-SdT+Vdp\\:,\n\\] and rearranging yields \\[\nV=\\left(\\frac{\\partial F}{\\partial p}\\right)_T\\:.\n\\]\nWe can now show that this result is consistent with the definition of \\(F_{NpT}\\) in terms of the partition function. Write\n\\[\nZ_{NpT}=\\int_0^\\infty dV  e^{-\\beta p V}Z_{NVT}=\\int_0^\\infty dV\\sum_{all~states~i}e^{-\\beta (p V_i+E_i)}\n\\]\nThen\n\\[\\begin{align}\n\\left(\\frac{\\partial F}{\\partial p}\\right)_T\n&= -\\frac{1}{\\beta} \\left(\\frac{\\partial \\ln Z_{NpT}}{\\partial p}\\right)_T \\\\\n&= -\\frac{1}{\\beta} \\frac{1}{Z_{NpT}} \\frac{\\partial Z_{NpT}}{\\partial p} \\\\\n&= -\\frac{1}{\\beta} \\frac{1}{Z_{NpT}} \\int_0^\\infty dV \\int_{\\text{all states}} (-\\beta V) e^{-\\beta (p V + E)} \\\\\n&= \\langle V \\rangle_T \\,.\n\\end{align}\\]\nwhere in the last step we have used the fact that the probability of a state is defined to be \\(e^{-\\beta (p V_i+E_i)}/Z_{NpT}\\).\nExercise. Repeat these manipulations to find an expression for the mean particle number \\(N\\) in the grand canonical ensemble\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIn the grand canonical ensemble (GCE), the relevant free energy is\n\\[\nF_{\\mu VT} = E - TS - \\mu N\n\\]\nFrom the first law of thermodynamics changes in the internal energy are given by:\n\\[\ndE = TdS - PdV + \\mu dN=TdS+\\mu dN\n\\] where we have used the fact that \\(V\\) is fixed in the GCE, so \\(dV=0\\).\nDifferentiating \\(F_{\\mu VT}\\):\n\\[\ndF_{\\mu VT} = dE - TdS - SdT - \\mu dN - N d\\mu\n= -S dT - N d\\mu\n\\] where for the last equality we have substitued for \\(dE\\) from above.\nThus \\[\n\\left( \\frac{\\partial F_{\\mu VT}}{\\partial \\mu} \\right)_{T, V} = -N\n\\quad \\Rightarrow \\quad\n\\langle N \\rangle = -\\left( \\frac{\\partial F_{\\mu VT}}{\\partial \\mu} \\right)_{T, V}\n\\]\nNow consider the statistical mechanics route to calculate \\(\\langle N\\rangle\\):\n\\[\nZ_{\\mu V T} = \\sum_{N=0}^{\\infty} \\sum_{\\text{states}} e^{-\\beta (E_{N,i} - \\mu N)}\n\\]\nThe grand potential (now written as \\(F_{\\mu VT}\\)) is:\n\\[\nF_{\\mu VT} = -k_B T \\ln Z_{\\mu V T}\n\\]\nWe now differentiate:\n\\[\n\\left( \\frac{\\partial F_{\\mu VT}}{\\partial \\mu} \\right)_T = -k_B T \\left( \\frac{1}{Z} \\frac{\\partial Z_{\\mu V T}}{\\partial \\mu} \\right)\n\\]\nFrom the partition function\n\\[\n\\frac{\\partial Z_{\\mu V T}}{\\partial \\mu} = \\sum_{N=0}^\\infty \\sum_{\\text{states}} \\left( \\beta N \\right) e^{-\\beta (E_{N,i} - \\mu N)}\n\\]\nSubstitute:\n\\[\n\\left( \\frac{\\partial F_{\\mu VT}}{\\partial \\mu} \\right)_T = -k_B T \\cdot \\beta \\cdot \\frac{1}{Z_{\\mu V T}} \\sum_{N=0}^\\infty \\sum_{\\text{states}} N\\, e^{-\\beta (E_{N,i} - \\mu N)} = - \\langle N \\rangle\n\\]\nwhere in the last step we have used the fact that in the GCE the Boltzmann probability of a microstate is defined to be \\(e^{-\\beta (E_{N,i}-\\mu N)}/Z_{\\mu VT}\\).",
    "crumbs": [
      "Unifying concepts",
      "Precourse reading and revision"
    ]
  },
  {
    "objectID": "phase-transitions/problems.html",
    "href": "phase-transitions/problems.html",
    "title": "Unifying concepts: Problems",
    "section": "",
    "text": "Although you should try all of these questions, some of them are deliberately quite challenging. If you don’t get very far with some, don’t worry. We’ll be going over them in problems classes, so you can just regard them as worked examples.\n\n1. Existence of a phase transition in \\(d=2\\).\nIn lectures it was argued that no long ranged order occurs at finite-temperatures in a one dimensional system because of the presence of domain walls. Were macroscopic domain walls to exist in two dimensions at finite temperature, they would similarly destroy long ranged order and prevent a phase transition. By calculating the free energy of a 2D domain wall for an Ising lattice, show that domain walls do not in fact exist for sufficiently low \\(T\\).\n(Hint: Model the domain wall as a non-reversing \\(N\\)-step random walk on the lattice and find an expression for its energy and -from the number of random walk configurations- its entropy.)\n\n\n\n2. Correlation Length\nFor a 1D Ising model, show that the correlation between the spins at sites \\(i\\) and \\(j\\), is\n\\[\\langle s_i s_j\\rangle =\\sum_m p_m(-1)^m\\] where \\(m\\) is the number of domain walls between \\(i\\) and \\(j\\) and \\(p_m\\) is the probability of finding \\(m\\) domain walls between them.\nHence show that when \\(R_{ij}=|i-j|a\\) is large (with \\(a\\) the lattice spacing) and the temperature is small, that\n\\[\\langle s_i s_j\\rangle =\\exp(-R_{ij}/\\xi)\\] with \\(\\xi=a/2p\\) and \\(p\\) the probability of finding a domain wall on a bond.\nHint: In the second part note that \\(p_m\\) is given by a binomial distribution because there is a probability \\(p\\) of each bond containing a domain wall and \\((1-p)\\) that it doesn’t. What special type of distribution does \\(p_m\\) tend to when \\(p\\) is small (as occurs at low \\(T\\))?\n\n\n\n3. A model fluid\nThe van der Waals (vdW) equation of state is essentially a mean field theory for fluids. It relates the pressure and the volume of a fluid to the temperature:\n\\[\\left(P+\\frac{a}{V^2}\\right)(V-b)=N_Ak_BT\\] where \\(a\\) and \\(b\\) are constants and \\(N_A\\) is Avogadro’s number.\nThe critical point of a fluid corresponds to the point at which the isothermal compressibility diverges, that is\n\\[\\left(\\frac{\\partial P}{\\partial V}\\right)_T=0\\] Additionally, one finds that isotherms of \\(P\\) versus \\(V\\) exhibit a point of inflection at the critical point, that is\n\\[\\left(\\frac{\\partial^2 P}{\\partial V^2}\\right)_T=0\\]\n\nUse these two requirements to show that the critical point of the vdW fluid is located at\n\\[V_c=3b, ~~~ P_c=\\frac{a}{27b^2},~~~ N_AK_BT_c=\\frac{8a}{27b}\\]\nHence show that when written in terms of reduced variables\n\\[p=\\frac{P}{P_c}, ~~~~ v=\\frac{V}{V_c} ~~~~ t=\\frac{T}{T_c}\\]\nthe equation takes the form\n\\[\\left(p+\\frac{3}{v^2}\\right)(v-\\frac{1}{3})=\\frac{8t}{3}\\]\nWrite a Python script to plot a selection of isotherms close to the critical temperature (you will need to choose suitable units for your axes). Plot also the gradient and second derivative of \\(P\\) vs \\(V\\) on the critical isotherm and confirm numerically that it exhibits a point of inflection at the critical pressure and temperature.\nObtain the value of the critical exponent \\(\\gamma\\) of the vdW model and confirm that it takes a mean-field value.\n\n\n\n\n4. Mean field theory of the Ising model heat capacity\nUsing results derived in lectures, obtain an expression for the mean energy \\(\\langle E\\rangle\\) of the Ising model in zero field, within the simplest mean field approximation \\(\\langle\n  s_is_j\\rangle=\\langle s_i\\rangle\\langle s_j\\rangle=m^2\\). Hence show that for \\(H=0\\) the heat capacity \\(\\partial \\langle E\\rangle/\\partial T\\) has the behaviour\n\\[\\begin{align*}\nC_H=& 0 \\quad T&gt;T_c\\\\\nC_H=& 3Nk_B/2 \\quad T\\le T_c\n\\end{align*}\\]\n\n\n\n5. Magnetisation and fluctuations\nA system of spins on a lattice in the presence of an applied field \\(h\\), has a Hamiltonian \\[\n{\\cal H}=E - hM\n\\] where \\(E\\) is the spin-spin interaction energy, \\(M\\) is the total magnetisation and \\(h\\) is the magnetic field. By considering the partition function \\(Z(T,h)\\) and its relationship to the free energy \\(F\\) show that in general\n\\[\n\\langle M \\rangle=-\\left(\\frac{\\partial F}{\\partial h}\\right)_T\n\\]\nShow also that the variance of the magnetisation fluctuations is\n\\[\\langle M^2\\rangle-\\langle M\\rangle^2=-k_BT\\left(\\frac{\\partial^2 F}{\\partial h^2}\\right)_T\\]\n(Hint: This is an important standard derivation found in many text books on Statistical Mechanics. You will need to differentiate \\(F\\) (twice) and use the product and chain rules.)\n\n\n\n6. Spin-1 Ising model\nA set of spins on a lattice of coordination number \\(q\\) can take values \\((-1,0,1)\\), as opposed to just \\((-1,1)\\) as in the spin-1/2 Ising model. The Hamiltonian is\n\\[{\\cal H}=-J\\sum_{&lt;ij&gt;}s_is_j - h\\sum_i s_i\\]\nFind the partition function in the mean field approximation and hence show that in the same approximation, the magnetisation per site obeys\n\\[m=\\frac{2\\sinh[\\beta(Jqm+h)]}{2\\cosh[\\beta(Jqm+h)]+1}\\]\nand find the critical temperature \\(T_c\\) at which the net magnetisation vanishes.\n\n\n\n7. Transfer Matrix.\nVerify the calculation of the free energy of the 1D periodic chain Ising model in a field outlined in lectures using the Transfer Matrix method.\nUse your results to show that the spontaneous magnetisation is:\n\\[m=\\frac{\\sinh \\beta H}{\\sqrt{\\sinh^2\\beta H+\\exp{-4\\beta J}}}\\] Comment on the value of \\(m\\) in zero field.\n(Hint: Follow the prescription given in lectures. Depending on your approach you may need to use the trigonometrical identities \\(\\cosh^2x-\\sinh^2x=1\\), \\(\\cosh(2x)=2\\cosh^2x-1\\).)\n\n\n\n8. Landau theory\nCheck and complete the Landau theory calculations, given in lectures, for the critical exponents \\(\\gamma=1\\) and \\(\\alpha=0\\) of the Ising model. For the latter, you should first prove the result\n\\[C_H =-T\\frac{\\partial^2 F}{\\partial T^2}\\] starting from the classical theormodynamics expression for changes in the free energy of a magnet \\(dF=-SdT-MdH\\).\n(Hint: If you get stuck with the proof see standard thermodynamics text books. To get the susceptibility exponent in Landau theory add a term \\(-Hm\\) to the Hamiltonian.)\n\n\n\n9. Scaling equation of state\nConsider a Landau expression for the free energy of a magnetic system having magnetisation \\(m\\):\n\\[\nF=F_0+\\tilde{a}_2tm^2+a_4m^4-Hm\\:,\n\\] where \\(t=T-T_c\\) and \\(H\\) is an applied magnetic field; \\(\\tilde{a}_2\\) and \\(a_4\\) are positive constants and \\(F_0\\) is a constant background term.\nShow that the equation of state for the model is\n\\[\nH=2\\tilde{a}_2tm+4a_4m^3\\:.\n\\]\nUse the near-critical power law behaviour of \\(m\\) to show that the equation of state may be written in the scaling form\n\\[\n\\frac{H}{m^\\delta}=g\\left(\\frac{t}{m^{1/\\beta}}\\right)\\:,\n\\] and find the (mean field) values of the critical exponents \\(\\delta\\) and \\(\\beta\\).\nDeduce that \\(g(x)=x+1\\) up to a choice of scale for \\(\\tilde{a}_2\\) and \\(a_4\\).\n\n\n\n10. Scaling laws\nUsing the generalised homogeneous form for the free energy given in lectures, take appropriate derivatives to find the relationships to the critical exponents:\n\\[\n\\beta=\\frac{1-b}{a}; ~~ \\gamma=\\frac{2b-1}{a};~~ \\delta= \\frac{b}{1-b}; ~~~ \\alpha=2-\\frac{1}{a}.\n\\]\nHence derive the scaling laws among the critical exponents:\n\\[\\begin{align*}\n\\alpha+\\beta(\\delta+1)=& 2 \\\\\n\\alpha+2\\beta+\\gamma =& 2\\\\\n%\\gamma=\\beta(\\delta-1)\n\\end{align*}\\]\n(Hint: For the heat capacity exponent \\(\\alpha\\) use the result from problem 8: \\(C_H=-T\\left(\\frac{\\partial^2F}{\\partial T^2}\\right)_{h=0}\\))\n\n\n\n11. Classical nucleation theory\nA supercooled liquid metal is undergoing solidification. According to classical nucleation theory, the Gibbs free energy change \\(\\Delta G\\) for forming a spherical solid nucleus of radius \\(r\\) in the liquid is given by:\n\\[\n\\Delta G(r) = \\frac{4}{3}\\pi r^3 \\Delta G_v + 4\\pi r^2 \\gamma\n\\] where \\(\\Delta G_v &lt; 0\\) is the free energy change per unit volume due to the phase change, and \\(\\gamma &gt; 0\\) is the interfacial energy between the solid and liquid phases.\n(a) Derive the expression for the critical radius \\(r^*\\) at which the nucleus becomes stable and begins to grow.\n(b) Show that the critical energy barrier for nucleation \\(\\Delta G^*\\) is given by:\n\\[\n\\Delta G^* = \\frac{16\\pi \\gamma^3}{3 (\\Delta G_v)^2}\n\\]\n(c) Explain qualitatively how the degree of undercooling \\(\\Delta T\\) affects the rate of nucleation. You may use the fact that \\(\\Delta G_v \\propto \\Delta T\\) to support your answer.\n\n\n\n12. Colloidal diffusion\nA large colloidal particle of mass \\(M\\) moves in a fluid under the influence of a random force \\(F(t)\\) and a coefficient of Stokes friction drag \\(\\gamma\\), both per unit mass. If the solution of the corresponding Langevin equation for the velocity of the colloidal particle is given by\n\\[\nu = u_0 e^{-\\gamma t} + \\frac{e^{-\\gamma t}}{M} \\int_0^t dt' \\, e^{\\gamma t'} F(t'),\n\\]\nwhere \\(u_0\\) is the velocity at \\(t = 0\\), show that for long times the velocity of the particle satisfies the relation\n\\[\n\\langle u^2 \\rangle = \\frac{kT}{M} + \\left( u_0^2 - \\frac{kT}{M} \\right) e^{-2\\gamma t},\n\\]\nwhere \\(k\\) is the Boltzmann constant and \\(T\\) is the absolute temperature.\nState clearly any assumptions that you make.\n\n\n\n13. Einstein’s expression for the diffusion coefficient\nIn 1905, Einstein showed that the friction coefficient \\(\\gamma\\) (per unit mass) of a colloidal particle must be related to the diffusion coefficient \\(D\\) of the particle by\n\\[\nD = \\frac{kT}{\\gamma}.\n\\]\nIf a marked particle covers a distance \\(X\\) in a given time \\(t\\) (assuming a one-dimensional random walk), the diffusion coefficient is defined to be\n\\[\nD = \\lim_{t \\to \\infty} \\frac{1}{2t} \\langle [X(t) - X(0)]^2 \\rangle,\n\\]\nwhere the average \\(\\langle \\cdot \\rangle\\) is taken over an ensemble in thermal equilibrium.\nUse the fact that \\(X(t) - X(0)\n= \\int_{0}^{t} u(t')\\,\\mathrm{d}t'\\) to show that the Einstein relation may be written as\n\\[\n\\gamma = \\frac{1}{\\mu} = \\frac{D}{kT} = \\frac{1}{kT} \\int_0^\\infty \\langle u(t_0) u(t_0 + t) \\rangle \\, dt,\n\\]\nwhere \\(\\mu\\) is known as the mobility of the particle and \\(t_0\\) is any arbitrarily chosen time.\n\n\n\n14. Life in one dimension\nA particle lives on the sites of a one-dimensional lattice. At any instant it has probability \\(\\alpha\\) per unit time that it will hop to the site on its right and probability \\(\\alpha\\) per unit time of hopping to the site on its left.\nWrite down the master equation for the set of probabilities \\(p_n(t)\\) of finding the particle at the \\(n^{\\text{th}}\\) site, where \\(-\\infty &lt; n &lt; \\infty\\).\nSolve the master equation for the \\(p_n\\), subject to the initial condition that the particle was at the site \\(n = 0\\) at time \\(t = 0\\). Hence obtain the mean position \\(\\langle n \\rangle\\) and root mean square deviation from the mean, both as functions of time.\nHint: The second part of the question is most easily done by introducing the generating function\n\\[\nF(z, t) = \\sum_{n=-\\infty}^{\\infty} p_n(t) z^n.\n\\]\n\n\n\n15. Master equation\nA system of \\(N\\) atoms, each having two energy levels \\(E = \\pm \\epsilon\\), is brought into contact with a heat bath at temperature \\(T\\). The atoms do not interact with each other, but each atom interacts with the heat bath to have a probability \\(\\lambda_{-\\to+}(T)\\) per unit time of transition from lower to higher level, and a probability \\(\\lambda_{+\\to-}(T)\\) per unit time of the reverse transition.\nIf at any time \\(t\\) there are \\(n_+(t)\\) atoms at the higher level and \\(n_-(t)\\) at the lower level, then \\(n(t) = n_-(t) - n_+(t)\\) is a convenient measure of the non-equilibrium state.\nObtain the master equation for \\(n(t)\\) and hence the relaxation time \\(\\tau\\) which characterizes the exponential approach of the system to equilibrium.\n\n\n\n16. Detailed balance\n(a) Starting from the principle of detailed balance for an isolated system, show that for two groups of states within it, \\(A\\) and \\(B\\), the overall rate of transitions from group \\(A\\) to group \\(B\\) is balanced, in equilibrium, by those from \\(B\\) to \\(A\\):\n\\[\n\\lambda_{A \\to B} p^{\\text{eq}}_A = \\lambda_{B \\to A} p^{\\text{eq}}_B\n\\]\n(b) Deduce that the principle applies to microstates in the canonical ensemble, and hence that the jump rates between states of a subsystem (of fixed number of particles) connected to a heat bath must obey\n\\[\n\\frac{\\lambda_{i \\to j}}{\\lambda_{j \\to i}} = e^{-(E_j - E_i)/kT}.\n\\]\n\n\n\n17. Jump processes\nAn isolated system can occupy three possible states of the same energy. The kinetics are such that it can jump from state 1 to 2 and 2 to 3 but not directly from 1 to 3. Per unit time, there is a probability \\(\\lambda_0\\) that the system makes a jump, from the state it is in, into (each of) the other state(s) it can reach.\n(a) Show that the occupancy probabilities \\(p = (p_1, p_2, p_3)\\) of the three states obey the master equation\n\\[\n\\dot{p} = M \\cdot p\n\\]\nwhere the rate matrix is\n\\[\nM = \\lambda_0 \\begin{bmatrix}\n-1 & 1 & 0 \\\\\n1 & -2 & 1 \\\\\n0 & 1 & -1\n\\end{bmatrix}\n\\]\n(b) Confirm that an equilibrium state is \\(p = (1, 1, 1)/3\\).\n(c) Prove this equilibrium state is unique.\nHint: For part (c), consider the eigenvalues of \\(M\\).",
    "crumbs": [
      "Unifying concepts",
      "Problems"
    ]
  },
  {
    "objectID": "phase-transitions/Solutions_partial.html",
    "href": "phase-transitions/Solutions_partial.html",
    "title": "Unifying concepts: outline solutions to problems",
    "section": "",
    "text": "Here we present outline solutions to the problems.\n\n1. Existence of a phase transition in \\(d=2\\).\nConsider the simplest elementary excitation that will destroy long range order in the 2d system: a domain wall of \\(N\\) segments which divides an Ising system of \\(L\\times L\\) spins into a spin up and a spin down part.\n\n\n\n\n\n\nFigure 1: An \\(N\\)-step domain wall in an Ising lattice.\n\n\n\nThe associated energy cost is \\(2JN \\equiv \\Delta E\\).\nTo evaluate the entropy gain due to a domain wall in the system we have to estimate \\(\\Omega\\) the number of possible paths for the domain wall. If we start at the left hand side then there are \\(L\\) starting positions. At each step the domain wall can move to the right, move up or move down. This implies that the number of domain walls is approximately\n\\[\n\\Omega\\approx L3^N\n\\] Hence the entropy gain is:\n\\[\n\\Delta S=Nk_B\\ln 3+k_B\\ln L\\approx Nk_B\\ln 3  \n\\]\nAccordingly, the change in the free energy associated with inserting such a domain wall into an ordered system is\n\\[\n\\Delta F=\\Delta E-T\\Delta S= N(2J-k_BT\\ln 3)\n\\]\nFor small enough \\(T &lt;2J/(k_B\\ln 3)\\), the free energy change is positive. Thus the ordered phase is free energetically stable against formation of a wall. Accordingly there will be a non zero value for \\(T_c\\) in two dimensions.\n\n\n\n2. Correlation Length\nDenote by \\(m\\) the number of domain walls between sites \\(i\\) and \\(j\\). Then \\(s_is_j=1\\) for \\(m\\) even, and \\(s_is_j=-1\\) for \\(m\\) odd.\nHence\n\\[\n\\langle s_i s_j\\rangle =\\sum_m p_m(-1)^m\n\\] with \\(p_m\\) the probability of finding \\(m\\) domain walls between them.\nNow \\(p_m\\) is given by the binomial distribution, with the probability of a single domain wall at each bond given by\n\\[\np=\\frac{e^{-2J/k_BT}}{1+e^{-2J/k_BT}}\n\\]\nand the probability of no wall is \\(1-p\\). Now, in the regime where \\(T\\) is small, \\(p\\) is very small, and there will be few domain walls between sites \\(i\\) and \\(j\\). If additionally, \\(R_{ij}=|i-j|a\\) is large, it tranpires that the binomial distribution assumes the limiting form of a Poissonian distribution (revise this if necessary). Thus\n\\[\np_m=\\frac{\\overline{m}^me^{-\\overline{m}}}{m!}\n\\]\nwhere \\(\\overline{m}=p|j-i|=pR_{ij}/a\\) . Then\n\\[\\begin{align*}\n\\langle s_i s_j\\rangle =& e^{-\\overline {m}}\\sum_m\\frac{(-1)^m\\overline{m}^m} {m!}\\approx e^{-2\\overline{m}}\\\\\n                       =& e^{-2pR_{ij}/a}\\\\\n                       =& e^{-R_{ij}/\\xi}\n\\end{align*}\\]\nwith \\(\\xi=a/2p\\), the correlation length.\n\n\n\n3. A model fluid\nThe van der Waals (vdW) equation of state (See Sec 4.4.1 of the book by Yeomans) is essentially a mean field theory for fluids. It relates the pressure and the volume of a fluid to the temperature:\n\\[\n\\left(P+\\frac{a}{V^2}\\right)(V-b)=Nk_BT\n\\] where \\(a\\) and \\(b\\) are constants chosen to describe a specific substance and \\(N\\) is Avogadro’s number. Hence\n\\[\nP=\\frac{Nk_BT}{V-b}-\\frac{a}{V^2}\n\\tag{1}\\]\n\\[\n\\Rightarrow \\frac{\\partial P}{\\partial V}=\\frac{-Nk_BT}{(V-b)^2}+\\frac{2a}{V^3}\n\\]\n\\[\n\\Rightarrow \\frac{\\partial^2 P}{\\partial V^2}=\\frac{2Nk_BT}{(V-b)^3}-\\frac{6a}{V^4}\n\\]\nNow at criticality (ie. a continuous transition).\n\\[\n\\left(\\frac{\\partial P}{\\partial V}\\right)_T=\\left(\\frac{\\partial^2 P}{\\partial V^2}\\right)_T=0\n\\]\nThus \\[\\begin{align*}\n\\frac{Nk_BT}{(V_c-b)^2} =& \\frac{2a}{V_c^3}\\\\\n\\frac{2Nk_BT}{(V_c-b)^3} =& \\frac{6a}{V_c^4}\n\\end{align*}\\]\nsolving for \\(V_c\\) and \\(Nk_BT_c\\) yields\n\\[\\begin{align*}\nV_c =& 3b\\\\\nNk_BT_c =& \\frac{8a}{27b}\n\\end{align*}\\]\nSubstituting these two results into Equation 1 yields\n\\[\nP_c=\\frac{a}{27b^2}\n\\]\nNow let \\(P=P_c p, V=V_cv, T=T_ct\\) in the vdW eqn. (Note that in this context \\(t\\) is not the reduced temperature).\n\\[\n\\left(P_cp+\\frac{a}{(V_cv)^2}\\right)(V_cv-b)=N_Ak_BT_ct\n\\]\nSubstituting in for \\(V_c, N_Ak_BT_c\\) and \\(P_c\\)\n\\[\\begin{align*}\n\\left(p\\frac{a}{27b^2}+\\frac{a}{9b^2v^2}\\right)\\left(3bv-b\\right)=&\\frac{8a}{27b}t\\\\\n\\Rightarrow\\left(p+\\frac{3}{v^2}\\right)\\left(v-\\frac{1}{3}\\right)=&\\frac{8}{3}t\n\\end{align*}\\]\nThis expression for the equation of state in terms of reduced variables is useful because reference to the system specific parameters \\(a\\) and \\(b\\) has vanished. In this form the equation is therefore universal.\nPlotting \\(P/P_c\\) vs \\(V/V_c\\) for isotherms (values of \\(t\\)) and focussing on the region close to the critical point, one finds\n\n\n\n\n\n\nFigure 2: Isotherms of \\(p\\) versus \\(v\\) for various \\(t\\) spanning the critical temperatures\n\n\n\n\n\n\n\n\n\nFigure 3: (a) \\(\\frac{\\partial p}{\\partial v}\\) for \\(T=T_c\\). (b) \\(\\frac{\\partial^2 p}{\\partial v^2}\\) for \\(T=T_c\\).\n\n\n\nPlotting \\((\\frac{\\partial p}{\\partial v})_{t=1}\\) and \\((\\frac{\\partial^2 p}{\\partial v^2})_{t=1}\\), we see that there is indeed a point of inflexion on the critical isotherm, at \\(v=1\\), this is the critical point (ie. a continuous phase transition), Figure 3 .\nSubcritical isotherms (first order phase transition) exhibit a so called van-der Waals loop.\nTo find the compressibility critical exponent \\(\\gamma\\), we recall that\n\\[\n\\kappa_T=\\frac{-1}{V}\\left(\\frac{\\partial V}{\\partial P}\\right)_T=\\frac{-1}{p_cv}\\left(\\frac{\\partial v}{\\partial p}\\right)_t\\propto \\tilde{t}^{-\\gamma}\n\\] with \\(\\tilde{t}=(T-T_c)/T_c\\) small.\nNow from the reduced equation of state\n\\[\n\\frac{\\partial p}{\\partial v}=\\frac{-8t}{3(v-1/3)^2}+\\frac{6}{v^3}\n\\] setting \\(t=\\tilde{t}+1\\) and \\(v=1\\) gives \\(\\frac{\\partial p}{\\partial v} =-6\\tilde{t}\\), ie the compressibility diverges\n\\[\n\\kappa_T\\propto \\tilde{t}^{-1}\n\\] ie. \\(\\gamma=1\\), which is the same as the mean field result which we derived in another context of the magnetic susceptibility.\n\n\n\n4. Mean field theory of the Ising model heat capacity\nWe insert into the expression for the mean Ising energy\n\\[\n\\langle E \\rangle =-J\\sum_{&lt;i,j&gt;}\\langle s_is_j\\rangle\\:,\n\\] the simplest mean field approximation \\(\\langle s_is_j\\rangle=\\langle s_i\\rangle\\langle s_j\\rangle=m^2\\). Recalling the behaviour of the order parameter for small \\(t\\), that the number of bonds \\(=qN/2\\), and the mean field value of \\(T_c=qJ/k_B\\), we have for \\(T&lt;T_c\\)\n\\[\\begin{align*}\n\\langle E \\rangle =& \\frac{-NqJm^2}{2}\\\\\n\\:                =& \\frac{3NqJt}{2}\\\\\n\\:                =& \\frac{3Nk_B(T-T_c)}{2}\n\\end{align*}\\] while \\(\\langle E \\rangle= \\textrm{ constant}\\) for \\(T&gt;T_c\\).\nHence differentiating, we find \\[\\begin{align*}\nC_H= 0; &\\quad T&gt;T_c\\\\\nC_H= 3Nk_B/2; & \\quad T\\le T_c\n\\end{align*}\\]\nThis independence of the heat capacity on \\(t\\) corresponds to a critical exponent \\(\\alpha=0\\)\n\n\n\n5. Magnetisation and fluctuations\nThe free energy is\n\\[\nF=-k_BT\\ln Z\n\\] with the partition function\n\\[\nZ=\\sum_{{s}}\\exp[-(E-hM)/k_BT]\n\\]\nThus \\[\\begin{align*}\n-\\left(\\frac{\\partial F}{\\partial h}\\right)_T =& k_BT\\frac{1}{Z}\\left(\\frac{\\partial Z}{\\partial h}\\right)_T\\\\\n\\: =&\\frac{1}{Z}\\sum_{{s}}M \\exp[-(E-hM)/k_BT]\\\\\n   =& \\langle M\\rangle\n\\end{align*}\\] where we have used the definition of the average of an observable given in lectures.\nNow\n\\[\\begin{align*}\n\\left(\\frac{\\partial^2 F}{\\partial h^2}\\right)_T =& -k_BT\\left[\\frac{1}{Z}\\left(\\frac{\\partial^2 Z}{\\partial h^2}\\right)_T-\\left(\\frac{\\partial Z}{\\partial h}\\right)_T\\frac{1}{Z^2}\\left(\\frac{\\partial Z}{\\partial h}\\right)_T\\right]\\\\\n\\: =&\\frac{-1}{k_BT}\\left[\\frac{1}{Z}\\sum_{{s}}M^2 \\exp[-(E-hM)/k_BT]-\\langle M\\rangle^2\\right]\\\\\n\\:  =& \\frac{-1}{k_BT}\\left[\\langle M^2\\rangle-\\langle M\\rangle^2\\right]\n\\end{align*}\\]\nYou should recognise the terms in square brackets as the variance of the magnetisation distribution.\nThus the susceptibility is \\[\n\\chi_H\\equiv\\frac{\\partial \\langle M\\rangle}{\\partial h}=\\frac{1}{k_BT}\\left[\\langle M^2\\rangle-\\langle M\\rangle^2\\right]\n\\]\nIncidently, this is known as the fluctuation-dissipation theorem. It is a neat result, because it allows you to calculate the response to a perturbation from equilibrium, without actually perturbing the system! Instead one merely looks at the form of the equilibrium fluctuations. It is used extensively in computer simulations.\n\n\n\n6. Spin-1 Ising model\nAs in lectures, the mean field Hamiltonian for a single spin is\n\\[\n{\\cal H}(s_0)=-s_0\\left(qJm + h\\right)+NqJm^2/2\n\\] where here \\(h\\) is the magnetic field.\nThe probability of finding this spin with value \\(s_0\\) is \\[\\begin{align*}\np(s_0) =& \\frac{e^{-\\beta{\\cal H}(s_0)}} {\\sum_{s_0=0,\\pm 1}e^{-\\beta{\\cal H}(s_0)}}\\\\\n=&\\frac{e^{\\beta s_0(qJm+h)}}{1+e^{\\beta(qJm+h)}+e^{-\\beta(qJm+h)}}\n\\end{align*}\\]\nNow for consistency \\(\\langle s_0\\rangle=m\\), so \\[\\begin{align*}\nm =& \\sum_{s_0=0,\\pm 1}s_0p(s_0)\\\\\n\\:=& \\frac{0+e^{\\beta(qJm+h)}-e^{\\beta(qJm+h)}} {e^0+e^{\\beta(qJm+h)}+e^{-\\beta(qJm+h)}}\\\\\n\\:=&  \\frac{2\\sinh[\\beta(Jqm+h)]}{1+2\\cosh[\\beta(Jqm+h)]}\n\\end{align*}\\] To get the critical temperature, we can solve this graphically. One plots the RHS as a function of \\(m\\), for various \\(\\beta\\). On the same graph one plots the curve \\(y=m\\) (representing the LHS). \\(T_c\\) is the highest \\(T\\) for which the two curves intersect.\nAlternatively to get \\(T_c\\) analytically, set \\(h=0\\) and expand for small \\(m\\) (i.e. small \\(x=\\beta J q m\\)), we have \\[\nm \\approx \\frac{2(\\beta J q m)}{1+2} = \\frac{2}{3}\\,\\beta J q\\, m .\n\\] (I would advise looking up the expansions of \\(\\sinh(x)\\) and \\(\\cosh(x)\\) to see how this is obtained.)\nNow, a nonzero solution appears when the prefactor equals \\(1\\), i.e. when \\(m=m\\). Thus \\[\n1 = \\frac{2}{3}\\,\\beta_c J q\n\\quad \\Rightarrow \\quad\n\\beta_c = \\frac{3}{2Jq}.\n\\]\nHence the critical temperature is \\[\nk_B T_c = \\frac{2}{3}\\, J q .\n\\]\n\n\n\n7. Transfer Matrix\nThe transfer matrix is a list of the possible interactions of a pair of spins with one another and with a magnetic field. For a 1d spin-1/2 system it takes the form: \\[\n\\mathbf{V}(H)=\\begin{bmatrix}\ne^{\\beta(J+H)} & e^{-\\beta J} \\\\\ne^{-\\beta J}   & e^{\\beta(J-H)}\n\\end{bmatrix}\n\\] We need to find the eigenvalues, so we solve the characteristic equation det(\\(\\mathbf{V}-\\lambda \\mathbf{I})=0\\), i.e.\n\\[\n\\mathbf{V}(H)=\\begin{vmatrix}\ne^{\\beta(J+H)} -\\lambda & e^{-\\beta J} \\\\\ne^{-\\beta J}   & e^{\\beta(J-H)}-\\lambda\n\\end{vmatrix} =0\n\\]\nThen \\(\\lambda^2-(a+d)\\lambda+(ad-bc)=0\\). So\n\\[\\begin{align*}\n\\lambda_\\pm =& \\frac{a+d\\pm\\sqrt{(a+d)^2-4(ad-bc)}}{2}\\\\\n\\lambda_{\\pm} =& e^{\\beta J}\\cosh(\\beta H) \\pm \\frac{1}{2}\\sqrt{e^{2\\beta J}4\\cosh^2\\beta H-4(e^{2\\beta J}-e^{-2\\beta J})}\\\\\n\\lambda_{\\pm} =& e^{\\beta J}\\cosh(\\beta H) \\pm \\sqrt{e^{2\\beta J}\\sinh^2\\beta H+e^{-2\\beta J}}.\n\\end{align*}\\]\n(You’ll need the identity \\(\\cosh^2 x-\\sinh^2 x = 1\\)).\nFrom lectures, you should know that the partition function\n\\[\\begin{align}\nZ=\\textrm{Tr}(\\mathbf{V}^N)=&\\lambda_+^N+\\lambda_-^N\\\\\n\\approx & \\lambda_+^N \\hspace{5mm}\\textrm{N~large}\n\\end{align}\\]\nwhere \\(\\lambda_+\\) is the largest of the two evals.\nHence the free energy \\(F=-k_BT\\ln(Z)\\) can be written\n\\[\nF=-Nk_BT\\ln \\left[e^{\\beta J}\\cosh(\\beta H) + \\sqrt{e^{2\\beta J}\\sinh^2\\beta H+e^{-2\\beta J}}\\right].\n\\]\nNow the magnetisation per site is\n\\[\nm=-\\frac{1}{N}\\frac{\\partial F}{\\partial H}=\\frac{k_BT}{\\lambda_+}\\frac{\\partial \\lambda_+}{\\partial H}\n\\]\nYou can either be a hero here, or use a symbolic solution program like Maple or Wolfram Alpha. I did the latter to find the stated result.\n\\[\nm=\\frac{\\sinh \\beta H}{\\sqrt{\\sinh^2\\beta H+\\exp{(-4\\beta J)}}}\n\\]\nHence at zero \\(H\\), there is no spontaneous magnetisation at any \\(T\\).\n\n\n\n8. Landau theory\nIf this were an Ising model problem (ie a microscopic model) we could write down the partition function, get an explicit expression for the free energy and differentiate once (wrt \\(T\\)) to get the energy and again (wrt \\(T\\)) to get the heat capacity. But the starting point for Landau theory is the free energy itself, so we need another starting point, namely thermodynamics. The appropriate thermodynamic potential for the magnet is \\(F=E-TS-MH\\) with \\(E\\) the internal energy. Then \\[\n\\begin{align*}\ndF =& dE-TdS-SdT-MdH-HdM\\\\\n\\: =& TdS+HdM-TdS-SdT-MdH-HdM\\\\\n\\: =& -SdT-MdH\n\\end{align*}\n\\] where we have used the first law for a magnet \\(dE=TdS+HdM\\).\nThus\n\\[\\begin{align*}\n\\left(\\frac{\\partial F}{\\partial T}\\right)_H =& -S\\\\\n-T\\left(\\frac{\\partial^2 F}{\\partial T^2}\\right)_H =&T\\frac{dS}{dT}=\\frac{dQ}{dT}\\\\ C_H=-T\\left(\\frac{\\partial^2 F}{\\partial T^2}\\right)_H\n\\end{align*}\\]\nwhere \\(C_H\\) is the specific heat at constant field and we have used the fact that \\(dS=dQ/T\\).\nNow from lectures, the equilibrium magnetisation in the Landau free energy is given by\n\\[\nm^2=\\frac{-a_2}{2a_4}\n\\] for \\(T&lt;T_c\\) and zero otherwise. Substituting this into the Landau free energy \\(F=F_0+a_2m^2+a_4m^4\\) gives\n\\[\\begin{align*}\nF = F_0 & \\quad T&gt;T_c\\\\\nF = -a_2^2/4a_4 & \\quad T &lt; T_c\n\\end{align*}\\]\nUsing the fact that \\(a_2=\\tilde{a_2} t\\), with \\(t=(T-T_c)/T_c\\) and differentiating wrt \\(T\\) twice, to get the heat capacity, we find\n\\[\\begin{align*}\nC_H =  0; & \\quad T\\to T_c^+\\\\\nC_H = \\frac{T\\tilde a_2^2}{2a_4T_c^2}; & \\quad T \\to T_c^-\\:,\n\\end{align*}\\] The jump discontinuity rather that a divergence in the specific heat at \\(T=T_c\\) formally corresponds to a critical exponent \\(\\alpha=0\\).\nTo get the susceptibility exponent, we add a magnetic field to the free energy\n\\[\nF(m)=F_0+a_2m^2+a_4m^4-Hm\n\\]\nThen the equilibrium magnetisation satisfies\n\\[\\begin{align*}\n\\frac{dF}{dm} =&2\\tilde{a_2} tm+4a_4m^3-H=0\\\\\n\\Rightarrow H =&2\\tilde{a_2} tm+4a_4m^3\\\\\n\\Rightarrow \\left(\\frac{\\partial H}{\\partial m}\\right )_T =&2\\tilde{a_2} t+12a_4m^2\n\\end{align*}\\] Now using the results that \\(m^2=0\\) for \\(t&gt;0\\) and \\(m^2=-\\tilde{a_2}t/(2a_4)\\) for \\(t&lt;0\\), we have that in both cases\n\\[\n\\left(\\frac{\\partial H}{\\partial m}\\right )_T\\propto t\n\\]\nHence\n\\[\n\\left(\\frac{\\partial m}{\\partial H}\\right )_T\\propto t^{-1}\n\\] so \\(\\gamma=1\\).\n\n\n\n9. Scaling equation of state\nThe equilibrium state corresponds to the minimum of the free energy \\(\\partial F/\\partial M=0\\). This gives the equation of state\n\\[\nH=2\\tilde{a_2}tm+4a_4m^3\n\\] (Note that we ignore the solution \\(H=m=0\\) which corresponds to a maximum of the free energy.)\nThe near critical power law scaling of the magnetisation is \\(m\\propto t^\\beta\\) and \\(m\\propto H^{1/\\delta}\\). To find a scaling form for the equation of state we need to transform to scaled variables \\(H/m^\\delta\\) and \\(t/m^{1/\\beta}\\). We can get a scaling equation in terms of these variables by dividing through the equation of state by \\(m^3\\), so that\n\\[\n\\frac{H}{m^{3}}=\\frac{2\\tilde{a_2}t}{m^2}+4a_4\n\\]\nHence \\(\\delta=3\\) and \\(\\beta=1/2\\).\nThe choice of scale \\(a_4=1/4\\) and \\(\\tilde{a_2}=1/2\\) yields the given form of the scaling function.\n\n\n\n10. Scaling laws\nFirst of all recall the definition of the critical exponents: \\[\\begin{align*}\nm       \\propto  t^{\\beta};& \\quad (h=0) \\\\\n\\chi_T  \\propto  t^{-\\gamma};&\\quad (h=0) \\\\\nC_H  \\propto  t^{-\\alpha};& \\quad (h=0) \\\\\nm  \\propto  h^{1/\\delta}.& \\quad (t=0) \\\\\n\\end{align*}\\]\nThe free energy in generalised homogeneous form is\n\\[\nF(\\lambda^a t,\\lambda^b h)=\\lambda F(t,h)\n\\]\nThe first of the scaling relations to be derived was covered in lectures: Let \\(\\lambda^a=1/t\\), so that \\(\\lambda=t^{-1/a}\\). Then\n\\[\\begin{align*}\nF(t,h)=&t^{1/a}F(1,t^{-b/a}h)\\\\\nm(t,h)=&-\\left(\\frac{\\partial F}{\\partial h}\\right)_t= -t^{(1-b)/a} \\left.\\frac{\\partial F(1,y)}{\\partial y}\\right|_{ht^{-b/a}}=t^{(1-b)/a}m(1,ht^{-b/a})\n\\end{align*}\\]\nso when \\(h=0\\), we have \\(m(1,t^{-b/a}h)=m(1,0)=\\textrm{ const}\\) and hence we can identify \\(\\boxed{\\beta=(1-b)/a}\\).\nWe also have for the isothermal susceptibility\n\\[\n\\chi=\\left(\\frac{\\partial m}{\\partial h}\\right)_t=-t^{(1-2b)/a}\\left.\\frac{\\partial^2 F(1,y)}{\\partial y^2}\\right|_{ht^{-b/a}},\n\\] so taking again \\(h=0\\), we find \\(\\boxed{\\gamma=(2b-1)/a}\\).\nFor the specific heat at constant (zero) field, we have the definition: \\[\nC_H = \\left(\\frac{\\partial E}{\\partial T}\\right)_{h=0}=-T\\left(\\frac{\\partial^2F}{\\partial T^2}\\right)_{h=0}\\:,\n\\] where in the last step have used \\(E=-\\partial (\\beta F)/\\partial\\beta\\), with \\(\\beta=(k_BT)^{-1}\\) (see fig 2.1 in notes). Alternatively one can use the thermodynamic derivation of this relation given in an earlier problem on Landau theory. Transforming from \\(T\\) to \\(t=(T-T_c)/T_c\\) and inserting the generalised homogeneous form for \\(F\\) gives:\n\\[\\begin{align*}\nC_H =& -\\frac{T}{T_c^2}\\frac{\\partial^2}{\\partial t^2}[t^{1/a}F(1,t^{-b/a}h)]\\\\\nC_H \\approx& -\\frac{1}{T_c}\\frac{\\partial^2}{\\partial t^2}[t^{1/a}F(1,t^{-b/a}h)]\\\\\nC_H =& -\\frac{1}{T_c}\\frac{1}{a}(\\frac{1}{a}-1)t^{(1/a-2)}F(1,0)\n\\end{align*}\\] Here we have neglected all derivatives of \\(F\\) since they are multiplied by at least one power of \\(h\\) which is zero. Hence \\(\\boxed{\\alpha=2-1/a}\\).\nFinally, if we let \\(\\lambda^b=1/h\\), so that \\(\\lambda=h^{-1/b}\\) and consider the critical isotherm \\(t=0\\). Then\n\\[\\begin{align*}\nF(t,h)=&h^{1/b}F(h^{-a/b}t,1)\\\\\n\\Rightarrow m(t,h)=& \\frac{ta}{b}h^{(1-a-b)/b}\\left.\\frac{\\partial F(x,1)}{\\partial x}\\right|_{h^{-a/b}t}-\\frac{1}{b}h^{1/b-1}F(h^{-a/b}t,1).\n\\end{align*}\\] so when \\(t=0\\), we get \\(m(0,h)\\) and can identify \\(\\boxed{\\delta=b/(1-b)}\\).\nTo derive the relationships (``scaling laws’’) among the critical exponents, we eliminate \\(a\\) and \\(b\\) from the boxed scaling relations. Setting \\(a=(2-\\alpha)^{-1}\\) in the first scaling relation, we find \\(b=1-\\beta/(2-\\alpha)\\). Substituting this into the second scaling relation gives the second of the two scaling laws quoted in the notes. Substituting into the 4th scaling relation gives the first scaling law.",
    "crumbs": [
      "Unifying concepts",
      "Solutions to problems"
    ]
  }
]